{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: Brazilian_E_Commerce\nQuestion: Please identify the top three customers, based on their customer_unique_id, who have the highest number of delivered orders, and provide the average payment value, city, and state for each of these customers."}, {"role": "assistant", "content": "WITH customer_orders AS (\n    SELECT\n        c.customer_unique_id,\n        COUNT(o.order_id) AS Total_Orders_By_Customers,\n        AVG(p.payment_value) AS Average_Payment_By_Customer,\n        c.customer_city,\n        c.customer_state\n    FROM olist_customers c\n    JOIN olist_orders o ON c.customer_id = o.customer_id\n    JOIN olist_order_payments p ON o.order_id = p.order_id\n    WHERE o.order_status = 'delivered'\n    GROUP BY c.customer_unique_id, c.customer_city, c.customer_state\n)\n\nSELECT \n    Average_Payment_By_Customer,\n    customer_city,\n    customer_state\nFROM customer_orders\nORDER BY Total_Orders_By_Customers DESC\nLIMIT 3;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: Pagila\nQuestion: Could you help me determine which actor starred most frequently in English-language children's category films that were rated either G or PG, had a running time of 120 minutes or less, and were released between 2000 and 2010? Please provide the actor's full name."}, {"role": "assistant", "content": "SELECT\n    actor.first_name || ' ' || actor.last_name AS full_name\nFROM\n    actor\nINNER JOIN film_actor ON actor.actor_id = film_actor.actor_id\nINNER JOIN film ON film_actor.film_id = film.film_id\nINNER JOIN film_category ON film.film_id = film_category.film_id\nINNER JOIN category ON film_category.category_id = category.category_id\n-- Join with the language table\nINNER JOIN language ON film.language_id = language.language_id\nWHERE\n    category.name = 'Children' AND\n    film.release_year BETWEEN 2000 AND 2010 AND\n    film.rating IN ('G', 'PG') AND\n    language.name = 'English' AND\n    film.length <= 120\nGROUP BY\n    actor.actor_id, actor.first_name, actor.last_name\nORDER BY\n    COUNT(film.film_id) DESC\nLIMIT 1;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: Pagila\nQuestion: Please help me find the film category with the highest total rental hours in cities where the city's name either starts with \"A\" or contains a hyphen. "}, {"role": "assistant", "content": "SELECT\n    category.name\nFROM\n    category\nINNER JOIN film_category USING (category_id)\nINNER JOIN film USING (film_id)\nINNER JOIN inventory USING (film_id)\nINNER JOIN rental USING (inventory_id)\nINNER JOIN customer USING (customer_id)\nINNER JOIN address USING (address_id)\nINNER JOIN city USING (city_id)\nWHERE\n    LOWER(city.city) LIKE 'a%' OR city.city LIKE '%-%'\nGROUP BY\n    category.name\nORDER BY\n    SUM(CAST((julianday(rental.return_date) - julianday(rental.rental_date)) * 24 AS INTEGER)) DESC\nLIMIT\n    1;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: education_business\nQuestion: Can you provide a list of hardware product segments along with their unique product counts for 2020 in the output, ordered by the highest percentage increase in unique fact sales products from 2020 to 2021?"}, {"role": "assistant", "content": "WITH UniqueProducts2020 AS (\n    SELECT\n        dp.segment,\n        COUNT(DISTINCT fsm.product_code) AS unique_products_2020\n    FROM\n        hardware_fact_sales_monthly fsm\n    JOIN\n        hardware_dim_product dp ON fsm.product_code = dp.product_code\n    WHERE\n        fsm.fiscal_year = 2020\n    GROUP BY\n        dp.segment\n),\nUniqueProducts2021 AS (\n    SELECT\n        dp.segment,\n        COUNT(DISTINCT fsm.product_code) AS unique_products_2021\n    FROM\n        hardware_fact_sales_monthly fsm\n    JOIN\n        hardware_dim_product dp ON fsm.product_code = dp.product_code\n    WHERE\n        fsm.fiscal_year = 2021\n    GROUP BY\n        dp.segment\n)\nSELECT\n    spc.segment,\n    spc.unique_products_2020 AS product_count_2020\nFROM\n    UniqueProducts2020 spc\nJOIN\n    UniqueProducts2021 fup ON spc.segment = fup.segment\nORDER BY\n    ((fup.unique_products_2021 - spc.unique_products_2020) * 100.0) / (spc.unique_products_2020) DESC;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: modern_data\nQuestion: Based on our customer pizza order information, summarize the total quantity of each ingredient used in the pizzas we delivered. Output the name and quantity for each ingredient."}, {"role": "assistant", "content": "WITH cte_cleaned_customer_orders AS (\n    SELECT\n        *,\n        ROW_NUMBER() OVER () AS original_row_number\n    FROM \n        pizza_clean_customer_orders\n),\nsplit_regular_toppings AS (\n    SELECT\n        pizza_id,\n        TRIM(SUBSTR(toppings, 1, INSTR(toppings || ',', ',') - 1)) AS topping_id,\n        SUBSTR(toppings || ',', INSTR(toppings || ',', ',') + 1) AS remaining_toppings\n    FROM \n        pizza_recipes\n    UNION ALL\n    SELECT\n        pizza_id,\n        TRIM(SUBSTR(remaining_toppings, 1, INSTR(remaining_toppings, ',') - 1)) AS topping_id,\n        SUBSTR(remaining_toppings, INSTR(remaining_toppings, ',') + 1) AS remaining_toppings\n    FROM \n        split_regular_toppings\n    WHERE\n        remaining_toppings <> ''\n),\ncte_base_toppings AS (\n    SELECT\n        t1.order_id,\n        t1.customer_id,\n        t1.pizza_id,\n        t1.order_time,\n        t1.original_row_number,\n        t2.topping_id\n    FROM \n        cte_cleaned_customer_orders AS t1\n    LEFT JOIN \n        split_regular_toppings AS t2\n    ON \n        t1.pizza_id = t2.pizza_id\n),\nsplit_exclusions AS (\n    SELECT\n        order_id,\n        customer_id,\n        pizza_id,\n        order_time,\n        original_row_number,\n        TRIM(SUBSTR(exclusions, 1, INSTR(exclusions || ',', ',') - 1)) AS topping_id,\n        SUBSTR(exclusions || ',', INSTR(exclusions || ',', ',') + 1) AS remaining_exclusions\n    FROM \n        cte_cleaned_customer_orders\n    WHERE \n        exclusions IS NOT NULL\n    UNION ALL\n    SELECT\n        order_id,\n        customer_id,\n        pizza_id,\n        order_time,\n        original_row_number,\n        TRIM(SUBSTR(remaining_exclusions, 1, INSTR(remaining_exclusions, ',') - 1)) AS topping_id,\n        SUBSTR(remaining_exclusions, INSTR(remaining_exclusions, ',') + 1) AS remaining_exclusions\n    FROM \n        split_exclusions\n    WHERE\n        remaining_exclusions <> ''\n),\nsplit_extras AS (\n    SELECT\n        order_id,\n        customer_id,\n        pizza_id,\n        order_time,\n        original_row_number,\n        TRIM(SUBSTR(extras, 1, INSTR(extras || ',', ',') - 1)) AS topping_id,\n        SUBSTR(extras || ',', INSTR(extras || ',', ',') + 1) AS remaining_extras\n    FROM \n        cte_cleaned_customer_orders\n    WHERE \n        extras IS NOT NULL\n    UNION ALL\n    SELECT\n        order_id,\n        customer_id,\n        pizza_id,\n        order_time,\n        original_row_number,\n        TRIM(SUBSTR(remaining_extras, 1, INSTR(remaining_extras, ',') - 1)) AS topping_id,\n        SUBSTR(remaining_extras, INSTR(remaining_extras, ',') + 1) AS remaining_extras\n    FROM \n        split_extras\n    WHERE\n        remaining_extras <> ''\n),\ncte_combined_orders AS (\n    SELECT \n        order_id,\n        customer_id,\n        pizza_id,\n        order_time,\n        original_row_number,\n        topping_id\n    FROM \n        cte_base_toppings\n    WHERE topping_id NOT IN (SELECT topping_id FROM split_exclusions WHERE split_exclusions.order_id = cte_base_toppings.order_id)\n    UNION ALL\n    SELECT \n        order_id,\n        customer_id,\n        pizza_id,\n        order_time,\n        original_row_number,\n        topping_id\n    FROM \n        split_extras\n)\nSELECT\n    t2.topping_name,\n    COUNT(*) AS topping_count\nFROM \n    cte_combined_orders AS t1\nJOIN \n    pizza_toppings AS t2\nON \n    t1.topping_id = t2.topping_id\nGROUP BY \n    t2.topping_name\nORDER BY \n    topping_count DESC;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: modern_data\nQuestion: Calculate the total income from Meat Lovers pizzas priced at $12 and Vegetarian pizzas at $10. Include any extra toppings charged at $1 each. Ensure that canceled orders are filtered out. How much money has Pizza Runner earned in total?"}, {"role": "assistant", "content": "WITH get_extras_count AS (\n    WITH RECURSIVE split_extras AS (\n        SELECT\n            order_id,\n            TRIM(SUBSTR(extras, 1, INSTR(extras || ',', ',') - 1)) AS each_extra,\n            SUBSTR(extras || ',', INSTR(extras || ',', ',') + 1) AS remaining_extras\n        FROM\n            pizza_clean_customer_orders\n        UNION ALL\n        SELECT\n            order_id,\n            TRIM(SUBSTR(remaining_extras, 1, INSTR(remaining_extras, ',') - 1)) AS each_extra,\n            SUBSTR(remaining_extras, INSTR(remaining_extras, ',') + 1)\n        FROM\n            split_extras\n        WHERE\n            remaining_extras <> ''\n    )\n    SELECT\n        order_id,\n        COUNT(each_extra) AS total_extras\n    FROM\n        split_extras\n    GROUP BY\n        order_id\n),\ncalculate_totals AS (\n    SELECT\n        t1.order_id,\n        t1.pizza_id,\n        SUM(\n            CASE\n                WHEN pizza_id = 1 THEN 12\n                WHEN pizza_id = 2 THEN 10\n            END\n        ) AS total_price,\n        t3.total_extras\n    FROM \n        pizza_clean_customer_orders AS t1\n    JOIN\n        pizza_clean_runner_orders AS t2 \n    ON\n        t2.order_id = t1.order_id\n    LEFT JOIN\n        get_extras_count AS t3\n    ON\n        t3.order_id = t1.order_id\n    WHERE\n        t2.cancellation IS NULL\n    GROUP BY \n        t1.order_id,\n        t1.pizza_id,\n        t3.total_extras\n)\nSELECT \n    SUM(total_price) + SUM(total_extras) AS total_income\nFROM \n    calculate_totals;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: bank_sales_trading\nQuestion: Can you provide a breakdown of how many times each product was viewed, how many times they were added to the shopping cart, and how many times they were left in the cart without being purchased? Also, give me the count of actual purchases for each product. Ensure that products with a page id in (1, 2, 12, 13) are filtered out."}, {"role": "assistant", "content": "WITH product_viewed AS (\n    SELECT\n        t1.page_id,\n        SUM(CASE WHEN event_type = 1 THEN 1 ELSE 0 END) AS n_page_views,\n        SUM(CASE WHEN event_type = 2 THEN 1 ELSE 0 END) AS n_added_to_cart\n    FROM\n        shopping_cart_page_hierarchy AS t1\n    JOIN\n        shopping_cart_events AS t2\n    ON\n        t1.page_id = t2.page_id\n    WHERE\n        t1.product_id IS NOT NULL\n    GROUP BY\n        t1.page_id\n),\nproduct_purchased AS (\n    SELECT\n        t2.page_id,\n        SUM(CASE WHEN event_type = 2 THEN 1 ELSE 0 END) AS purchased_from_cart\n    FROM\n        shopping_cart_page_hierarchy AS t1\n    JOIN\n        shopping_cart_events AS t2\n    ON\n        t1.page_id = t2.page_id\n    WHERE\n        t1.product_id IS NOT NULL\n        AND EXISTS (\n            SELECT\n                visit_id\n            FROM\n                shopping_cart_events\n            WHERE\n                event_type = 3\n                AND t2.visit_id = visit_id\n        )\n        AND t1.page_id NOT IN (1, 2, 12, 13)\n    GROUP BY\n        t2.page_id\n),\nproduct_abandoned AS (\n    SELECT\n        t2.page_id,\n        SUM(CASE WHEN event_type = 2 THEN 1 ELSE 0 END) AS abandoned_in_cart\n    FROM\n        shopping_cart_page_hierarchy AS t1\n    JOIN\n        shopping_cart_events AS t2\n    ON\n        t1.page_id = t2.page_id\n    WHERE\n        t1.product_id IS NOT NULL\n        AND NOT EXISTS (\n            SELECT\n                visit_id\n            FROM\n                shopping_cart_events\n            WHERE\n                event_type = 3\n                AND t2.visit_id = visit_id\n        )\n        AND t1.page_id NOT IN (1, 2, 12, 13)\n    GROUP BY\n        t2.page_id\n)\nSELECT\n    t1.page_id,\n    t1.page_name,\n    t2.n_page_views AS 'number of product being viewed',\n    t2.n_added_to_cart AS 'number added to the cart',\n    t4.abandoned_in_cart AS 'without being purchased in cart',\n    t3.purchased_from_cart AS 'count of actual purchases'\nFROM\n    shopping_cart_page_hierarchy AS t1\nJOIN\n    product_viewed AS t2 \nON\n    t2.page_id = t1.page_id\nJOIN\n    product_purchased AS t3 \nON \n    t3.page_id = t1.page_id\nJOIN\n    product_abandoned AS t4 \nON \n    t4.page_id = t1.page_id;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: bank_sales_trading\nQuestion: Identify the top 10 and bottom 10 interest categories based on their highest composition values across all months. For each category, display the time(MM-YYYY), interest name, and the composition value"}, {"role": "assistant", "content": "WITH get_interest_rank AS (\n    SELECT\n        t1.month_year,\n        t2.interest_name,\n        t1.composition,\n        RANK() OVER (\n            PARTITION BY t2.interest_name\n            ORDER BY t1.composition DESC\n        ) AS interest_rank\n    FROM \n        interest_metrics AS t1\n    JOIN \n        interest_map AS t2\n    ON \n        t1.interest_id = t2.id\n    WHERE \n        t1.month_year IS NOT NULL\n),\nget_top_10 AS (\n    SELECT\n        month_year,\n        interest_name,\n        composition\n    FROM \n        get_interest_rank\n    WHERE \n        interest_rank = 1\n    ORDER BY \n        composition DESC\n    LIMIT 10\n),\nget_bottom_10 AS (\n    SELECT\n        month_year,\n        interest_name,\n        composition\n    FROM \n        get_interest_rank\n    WHERE \n        interest_rank = 1\n    ORDER BY \n        composition ASC\n    LIMIT 10\n)\nSELECT * \nFROM \n    get_top_10\nUNION\nSELECT * \nFROM \n    get_bottom_10\nORDER BY \n    composition DESC;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: Db-IMDB\nQuestion: I need you to look into the actor collaborations and tell me how many actors have made more films with Yash Chopra than with any other director. This will help us understand his influence on the industry better."}, {"role": "assistant", "content": "WITH YASH_CHOPRAS_PID AS (\n    SELECT\n        TRIM(P.PID) AS PID\n    FROM\n        Person P\n    WHERE\n        TRIM(P.Name) = 'Yash Chopra'\n),\nNUM_OF_MOV_BY_ACTOR_DIRECTOR AS (\n    SELECT\n        TRIM(MC.PID) AS ACTOR_PID,\n        TRIM(MD.PID) AS DIRECTOR_PID,\n        COUNT(DISTINCT TRIM(MD.MID)) AS NUM_OF_MOV\n    FROM\n        M_Cast MC\n    JOIN\n        M_Director MD ON TRIM(MC.MID) = TRIM(MD.MID)\n    GROUP BY\n        ACTOR_PID,\n        DIRECTOR_PID\n),\nNUM_OF_MOVIES_BY_YC AS (\n    SELECT\n        NM.ACTOR_PID,\n        NM.DIRECTOR_PID,\n        NM.NUM_OF_MOV AS NUM_OF_MOV_BY_YC\n    FROM\n        NUM_OF_MOV_BY_ACTOR_DIRECTOR NM\n    JOIN\n        YASH_CHOPRAS_PID YCP ON NM.DIRECTOR_PID = YCP.PID\n),\nMAX_MOV_BY_OTHER_DIRECTORS AS (\n    SELECT\n        ACTOR_PID,\n        MAX(NUM_OF_MOV) AS MAX_NUM_OF_MOV\n    FROM\n        NUM_OF_MOV_BY_ACTOR_DIRECTOR NM\n    JOIN\n        YASH_CHOPRAS_PID YCP ON NM.DIRECTOR_PID <> YCP.PID\n    GROUP BY\n        ACTOR_PID\n),\nACTORS_MOV_COMPARISION AS (\n    SELECT\n        NMY.ACTOR_PID,\n        CASE WHEN NMY.NUM_OF_MOV_BY_YC > IFNULL(NMO.MAX_NUM_OF_MOV, 0) THEN 'Y' ELSE 'N' END AS MORE_MOV_BY_YC\n    FROM\n        NUM_OF_MOVIES_BY_YC NMY\n    LEFT OUTER JOIN\n        MAX_MOV_BY_OTHER_DIRECTORS NMO ON NMY.ACTOR_PID = NMO.ACTOR_PID\n)\nSELECT\n    COUNT(DISTINCT TRIM(P.PID)) AS \"Number of actor\"\nFROM\n    Person P\nWHERE\n    TRIM(P.PID) IN (\n        SELECT\n            DISTINCT ACTOR_PID\n        FROM\n            ACTORS_MOV_COMPARISION\n        WHERE\n            MORE_MOV_BY_YC = 'Y'\n    );"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: EntertainmentAgency\nQuestion: Could you list each musical style with the number of times it appears as a 1st, 2nd, or 3rd preference in a single row per style?"}, {"role": "assistant", "content": "SELECT \n  Musical_Styles.StyleName,\n  COUNT(RankedPreferences.FirstStyle)\n    AS FirstPreference,\n  COUNT(RankedPreferences.SecondStyle)\n    AS SecondPreference,\n  COUNT(RankedPreferences.ThirdStyle)\n    AS ThirdPreference\nFROM Musical_Styles,\n (SELECT (CASE WHEN\n    Musical_Preferences.PreferenceSeq = 1\n               THEN Musical_Preferences.StyleID\n               ELSE Null END) As FirstStyle,\n         (CASE WHEN\n    Musical_Preferences.PreferenceSeq = 2\n               THEN Musical_Preferences.StyleID\n               ELSE Null END) As SecondStyle,\n         (CASE WHEN\n    Musical_Preferences.PreferenceSeq = 3\n               THEN Musical_Preferences.StyleID\n               ELSE Null END) AS ThirdStyle\n   FROM Musical_Preferences)  AS RankedPreferences\nWHERE Musical_Styles.StyleID =\n         RankedPreferences.FirstStyle\n  OR Musical_Styles.StyleID =\n         RankedPreferences.SecondStyle\n  OR Musical_Styles.StyleID =\n         RankedPreferences.ThirdStyle\nGROUP BY StyleID, StyleName\nHAVING COUNT(FirstStyle) > 0\n     OR     COUNT(SecondStyle) > 0\n     OR     COUNT(ThirdStyle) > 0\nORDER BY FirstPreference DESC,\n        SecondPreference DESC,\n        ThirdPreference DESC, StyleID;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: education_business\nQuestion: Which university faculty members' salaries are closest to the average salary for their respective ranks? Please provide the ranks, first names, last names, and salaries.university"}, {"role": "assistant", "content": "WITH AvgSalaries AS (\n    SELECT \n        facrank AS FacRank,\n        AVG(facsalary) AS AvSalary\n    FROM \n        university_faculty\n    GROUP BY \n        facrank\n),\nSalaryDifferences AS (\n    SELECT \n        university_faculty.facrank AS FacRank, \n        university_faculty.facfirstname AS FacFirstName, \n        university_faculty.faclastname AS FacLastName, \n        university_faculty.facsalary AS Salary, \n        ABS(university_faculty.facsalary - AvgSalaries.AvSalary) AS Diff\n    FROM \n        university_faculty\n    JOIN \n        AvgSalaries ON university_faculty.facrank = AvgSalaries.FacRank\n),\nMinDifferences AS (\n    SELECT \n        FacRank, \n        MIN(Diff) AS MinDiff\n    FROM \n        SalaryDifferences\n    GROUP BY \n        FacRank\n)\nSELECT \n    s.FacRank, \n    s.FacFirstName, \n    s.FacLastName, \n    s.Salary\nFROM \n    SalaryDifferences s\nJOIN \n    MinDifferences m ON s.FacRank = m.FacRank AND s.Diff = m.MinDiff;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: sqlite-sakila\nQuestion: Among our top 10 paying customers, can you identify the largest change in payment amounts from one month to the immediately following month? Specifically, please determine for which customer and during which month this maximum month-over-month difference occurred, and provide the difference rounded to two decimal places."}, {"role": "assistant", "content": "WITH result_table AS (\n  SELECT \n    strftime('%m', pm.payment_date) AS pay_mon, \n    customer_id,\n    COUNT(pm.amount) AS pay_countpermon, \n    SUM(pm.amount) AS pay_amount \n  FROM \n    payment AS pm \n  GROUP BY \n    pay_mon, \n    customer_id\n), \ntop10_customer AS (\n  SELECT \n    customer_id,\n    SUM(tb.pay_amount) AS total_payments \n  FROM \n    result_table AS tb \n  GROUP BY \n    customer_id\n  ORDER BY \n    SUM(tb.pay_amount) DESC \n  LIMIT \n    10\n), \ndifference_per_mon AS (\n  SELECT \n    pay_mon AS month_number, \n    pay_mon AS month, \n    tb.pay_countpermon, \n    tb.pay_amount, \n    ABS(tb.pay_amount - LAG(tb.pay_amount) OVER (PARTITION BY tb.customer_id)) AS diff \n  FROM \n    result_table tb \n    JOIN top10_customer top ON top.customer_id = tb.customer_id\n) \nSELECT \n  month, \n  ROUND(max_diff, 2) AS max_diff \nFROM (\n  SELECT \n    month, \n    diff, \n    month_number, \n    MAX(diff) OVER (PARTITION BY month) AS max_diff \n  FROM \n    difference_per_mon\n) AS max_per_mon \nWHERE \n  diff = max_diff \nORDER BY \n  max_diff DESC \nLIMIT \n  1;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: sqlite-sakila\nQuestion: Can you identify the year and month with the highest rental orders created by the store's staff for each store? Please list the store ID, the year, the month, and the total rentals for those dates."}, {"role": "assistant", "content": "WITH result_table AS (\n  SELECT \n    strftime('%Y', RE.RENTAL_DATE) AS YEAR, \n    strftime('%m', RE.RENTAL_DATE) AS RENTAL_MONTH, \n    ST.STORE_ID, \n    COUNT(RE.RENTAL_ID) AS count \n  FROM \n    RENTAL RE \n    JOIN STAFF ST ON RE.STAFF_ID = ST.STAFF_ID \n  GROUP BY \n    YEAR, \n    RENTAL_MONTH, \n    ST.STORE_ID \n), \nmonthly_sales AS (\n  SELECT \n    YEAR, \n    RENTAL_MONTH, \n    STORE_ID, \n    SUM(count) AS total_rentals \n  FROM \n    result_table \n  GROUP BY \n    YEAR, \n    RENTAL_MONTH, \n    STORE_ID\n),\nstore_max_sales AS (\n  SELECT \n    STORE_ID, \n    YEAR, \n    RENTAL_MONTH, \n    total_rentals, \n    MAX(total_rentals) OVER (PARTITION BY STORE_ID) AS max_rentals \n  FROM \n    monthly_sales\n)\nSELECT \n  STORE_ID, \n  YEAR, \n  RENTAL_MONTH, \n  total_rentals \nFROM \n  store_max_sales \nWHERE \n  total_rentals = max_rentals\nORDER BY \n  STORE_ID;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: delivery_center\nQuestion: Can you identify the hubs that saw more than a 20% increase in finished orders from February to March?"}, {"role": "assistant", "content": "WITH february_orders AS (\n    SELECT\n        h.hub_name AS hub_name,\n        COUNT(*) AS orders_february\n    FROM \n        orders o \n    LEFT JOIN\n        stores s ON o.store_id = s.store_id \n    LEFT JOIN \n        hubs h ON s.hub_id = h.hub_id \n    WHERE o.order_created_month = 2 AND o.order_status = 'FINISHED'\n    GROUP BY\n        h.hub_name\n),\nmarch_orders AS (\n    SELECT\n        h.hub_name AS hub_name,\n        COUNT(*) AS orders_march\n    FROM \n        orders o \n    LEFT JOIN\n        stores s ON o.store_id = s.store_id \n    LEFT JOIN \n        hubs h ON s.hub_id = h.hub_id \n    WHERE o.order_created_month = 3 AND o.order_status = 'FINISHED'\n    GROUP BY\n        h.hub_name\n)\nSELECT\n    fo.hub_name\nFROM\n    february_orders fo\nLEFT JOIN \n    march_orders mo ON fo.hub_name = mo.hub_name\nWHERE \n    fo.orders_february > 0 AND \n    mo.orders_march > 0 AND\n    (CAST((mo.orders_march - fo.orders_february) AS REAL) / CAST(fo.orders_february AS REAL)) > 0.2  -- Filter for hubs with more than a 20% increase"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: EU_soccer\nQuestion: In each league, considering all seasons, which single team has the fewest total match wins based on comparing home and away goals, including teams with zero wins, ensuring that if multiple teams tie for the fewest wins, only one team is returned for each league?"}, {"role": "assistant", "content": "WITH match_view AS(\nSELECT\n    M.id,\n    L.name AS league,\n    M.season,\n    M.match_api_id,\n    T.team_long_name AS home_team,\n    TM.team_long_name AS away_team,\n    M.home_team_goal,\n    M.away_team_goal,\n    P1.player_name AS home_gk,\n    P2.player_name AS home_center_back_1,\n    P3.player_name AS home_center_back_2,\n    P4.player_name AS home_right_back,\n    P5.player_name AS home_left_back,\n    P6.player_name AS home_midfield_1,\n    P7.player_name AS home_midfield_2,\n    P8.player_name AS home_midfield_3,\n    P9.player_name AS home_midfield_4,\n    P10.player_name AS home_second_forward,\n    P11.player_name AS home_center_forward,\n    P12.player_name AS away_gk,\n    P13.player_name AS away_center_back_1,\n    P14.player_name AS away_center_back_2,\n    P15.player_name AS away_right_back,\n    P16.player_name AS away_left_back,\n    P17.player_name AS away_midfield_1,\n    P18.player_name AS away_midfield_2,\n    P19.player_name AS away_midfield_3,\n    P20.player_name AS away_midfield_4,\n    P21.player_name AS away_second_forward,\n    P22.player_name AS away_center_forward,\n    M.goal,\n    M.card\nFROM\n    match M\nLEFT JOIN\n    league L ON M.league_id = L.id\nLEFT JOIN\n    team T ON M.home_team_api_id = T.team_api_id\nLEFT JOIN\n    team TM ON M.away_team_api_id = TM.team_api_id\nLEFT JOIN\n    player P1 ON M.home_player_1 = P1.player_api_id\nLEFT JOIN\n    player P2 ON M.home_player_2 = P2.player_api_id\nLEFT JOIN\n    player P3 ON M.home_player_3 = P3.player_api_id\nLEFT JOIN\n    player P4 ON M.home_player_4 = P4.player_api_id\nLEFT JOIN\n    player P5 ON M.home_player_5 = P5.player_api_id\nLEFT JOIN\n    player P6 ON M.home_player_6 = P6.player_api_id\nLEFT JOIN\n    player P7 ON M.home_player_7 = P7.player_api_id\nLEFT JOIN\n    player P8 ON M.home_player_8 = P8.player_api_id\nLEFT JOIN\n    player P9 ON M.home_player_9 = P9.player_api_id\nLEFT JOIN\n    player P10 ON M.home_player_10 = P10.player_api_id\nLEFT JOIN\n    player P11 ON M.home_player_11 = P11.player_api_id\nLEFT JOIN\n    player P12 ON M.away_player_1 = P12.player_api_id\nLEFT JOIN\n    player P13 ON M.away_player_2 = P13.player_api_id\nLEFT JOIN\n    player P14 ON M.away_player_3 = P14.player_api_id\nLEFT JOIN\n    player P15 ON M.away_player_4 = P15.player_api_id\nLEFT JOIN\n    player P16 ON M.away_player_5 = P16.player_api_id\nLEFT JOIN\n    player P17 ON M.away_player_6 = P17.player_api_id\nLEFT JOIN\n    player P18 ON M.away_player_7 = P18.player_api_id\nLEFT JOIN\n    player P19 ON M.away_player_8 = P19.player_api_id\nLEFT JOIN\n    player P20 ON M.away_player_9 = P20.player_api_id\nLEFT JOIN\n    player P21 ON M.away_player_10 = P21.player_api_id\nLEFT JOIN\n    player P22 ON M.away_player_11 = P22.player_api_id\n),\nmatch_score AS\n(\n    SELECT  -- Displaying teams and their goals as home_team\n        id,\n        home_team AS team,\n        CASE\n            WHEN home_team_goal > away_team_goal THEN 1 ELSE 0 END AS Winning_match\n    FROM\n        match_view\n\n    UNION ALL\n\n    SELECT  -- Displaying teams and their goals as away_team\n        id,\n        away_team AS team,\n        CASE\n            WHEN away_team_goal > home_team_goal THEN 1 ELSE 0 END AS Winning_match\n    FROM\n        match_view\n),\nwinning_matches AS\n(\n    SELECT  -- Displaying total match wins for each team\n        MV.league,\n        M.team,\n        COUNT(CASE WHEN M.Winning_match = 1 THEN 1 END) AS wins,\n        ROW_NUMBER() OVER(PARTITION BY MV.league ORDER BY COUNT(CASE WHEN M.Winning_match = 1 THEN 1 END) ASC) AS rn\n    FROM\n        match_score M\n    JOIN\n        match_view MV\n    ON\n        M.id = MV.id\n    GROUP BY\n        MV.league,\n        team\n    ORDER BY\n        league,\n        wins ASC\n)\nSELECT\n    league,\n    team\nFROM\n    winning_matches\nWHERE\n    rn = 1  -- Getting the team with the least number of wins in each league\nORDER BY\n    league;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: bank_sales_trading\nQuestion: For weekly-sales data, I need an analysis of our sales performance around mid-June for the years 2018, 2019, and 2020. Specifically, calculate the percentage change in sales between the four weeks leading up to June 15 and the four weeks following June 15 for each year."}, {"role": "assistant", "content": "SELECT \n    before_effect,\n    after_effect,\n    after_effect - before_effect AS change_amount,\n    ROUND(((after_effect * 1.0 / before_effect) - 1) * 100, 2) AS percent_change,\n    '2018' AS year\nFROM (\n    SELECT \n        SUM(CASE WHEN delta_weeks BETWEEN 1 AND 4 THEN sales END) AS after_effect,\n        SUM(CASE WHEN delta_weeks BETWEEN -3 AND 0 THEN sales END) AS before_effect\n    FROM (\n        SELECT \n            week_date,\n            ROUND((JULIANDAY(week_date) - JULIANDAY('2018-06-15')) / 7.0) + 1 AS delta_weeks,\n            sales \n        FROM cleaned_weekly_sales\n    ) add_delta_weeks\n) AS add_before_after\nUNION ALL\nSELECT \n    before_effect,\n    after_effect,\n    after_effect - before_effect AS change_amount,\n    ROUND(((after_effect * 1.0 / before_effect) - 1) * 100, 2) AS percent_change,\n    '2019' AS year\nFROM (\n    SELECT \n        SUM(CASE WHEN delta_weeks BETWEEN 1 AND 4 THEN sales END) AS after_effect,\n        SUM(CASE WHEN delta_weeks BETWEEN -3 AND 0 THEN sales END) AS before_effect\n    FROM (\n        SELECT \n            week_date,\n            ROUND((JULIANDAY(week_date) - JULIANDAY('2019-06-15')) / 7.0) + 1 AS delta_weeks,\n            sales \n        FROM cleaned_weekly_sales\n    ) add_delta_weeks\n) AS add_before_after\nUNION ALL\nSELECT \n    before_effect,\n    after_effect,\n    after_effect - before_effect AS change_amount,\n    ROUND(((after_effect * 1.0 / before_effect) - 1) * 100, 2) AS percent_change,\n    '2020' AS year\nFROM (\n    SELECT \n        SUM(CASE WHEN delta_weeks BETWEEN 1 AND 4 THEN sales END) AS after_effect,\n        SUM(CASE WHEN delta_weeks BETWEEN -3 AND 0 THEN sales END) AS before_effect\n    FROM (\n        SELECT \n            week_date,\n            ROUND((JULIANDAY(week_date) - JULIANDAY('2020-06-15')) / 7.0) + 1 AS delta_weeks,\n            sales \n        FROM cleaned_weekly_sales\n    ) add_delta_weeks\n) AS add_before_after\nORDER BY year;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: f1\nQuestion: For each year, which driver and which constructor scored the most points? I want the full name of each driver."}, {"role": "assistant", "content": "with year_points as (\n    select races.year,\n           drivers.forename || ' ' || drivers.surname as driver,\n           constructors.name as constructor,\n           sum(results.points) as points\n    from results\n    left join races on results.race_id = races.race_id  -- Ensure these columns exist in your schema\n    left join drivers on results.driver_id = drivers.driver_id  -- Ensure these columns exist in your schema\n    left join constructors on results.constructor_id = constructors.constructor_id  -- Ensure these columns exist in your schema\n    group by races.year, driver\n    union\n    select races.year,\n           null as driver,\n           constructors.name as constructor,\n           sum(results.points) as points\n    from results\n    left join races on results.race_id = races.race_id  -- Ensure these columns exist in your schema\n    left join drivers on results.driver_id = drivers.driver_id  -- Ensure these columns exist in your schema\n    left join constructors on results.constructor_id = constructors.constructor_id  -- Ensure these columns exist in your schema\n    group by races.year, constructor\n),\nmax_points as (\n    select year,\n           max(case when driver is not null then points else null end) as max_driver_points,\n           max(case when constructor is not null then points else null end) as max_constructor_points\n    from year_points\n    group by year\n)\nselect max_points.year,\n       drivers_year_points.driver,\n       constructors_year_points.constructor\nfrom max_points\nleft join year_points as drivers_year_points on\n    max_points.year = drivers_year_points.year and\n    max_points.max_driver_points = drivers_year_points.points and\n    drivers_year_points.driver is not null\nleft join year_points as constructors_year_points on\n    max_points.year = constructors_year_points.year and\n    max_points.max_constructor_points = constructors_year_points.points and\n    constructors_year_points.constructor is not null\norder by max_points.year;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: GLOBAL_WEATHER__CLIMATE_DATA_FOR_BI\nQuestion: Assuming today is April 1, 2024, I would like to know the daily snowfall amounts greater than 6 inches for each U.S. postal code during the week ending after the first two full weeks of the previous year. Show the postal code, date, and snowfall amount."}, {"role": "assistant", "content": "WITH timestamps AS\n(   \n    SELECT\n        DATE_TRUNC(year,DATEADD(year,-1,DATE '2024-08-29')) AS ref_timestamp,\n        LAST_DAY(DATEADD(week,2 + CAST(WEEKISO(ref_timestamp) != 1 AS INTEGER),ref_timestamp),week) AS end_week,\n        DATEADD(day, day_num - 7, end_week) AS date_valid_std\n    FROM\n    (   \n        SELECT\n            ROW_NUMBER() OVER (ORDER BY SEQ1()) AS day_num\n        FROM\n            TABLE(GENERATOR(rowcount => 7))\n    ) \n)\nSELECT\n    country,\n    postal_code,\n    date_valid_std,\n    tot_snowfall_in \nFROM \n    GLOBAL_WEATHER__CLIMATE_DATA_FOR_BI.standard_tile.history_day\nNATURAL INNER JOIN\n    timestamps\nWHERE\n    country='US' AND\n    tot_snowfall_in > 6.0 \nORDER BY \n    postal_code,date_valid_std\n;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: FINANCE__ECONOMICS\nQuestion: As of December 31, 2022, list the top 10 active banks with assets exceeding $10 billion, ranked by the highest percentage of uninsured assets, where the percentage is calculated as one minus the value of the '% Insured (Estimated)' variable from quarterly estimates. Provide the names of these banks and their respective percentages of uninsured assets."}, {"role": "assistant", "content": "WITH big_banks AS (\n    SELECT id_rssd\n    FROM FINANCE__ECONOMICS.CYBERSYN.financial_institution_timeseries\n    WHERE variable = 'ASSET'\n      AND date = '2022-12-31'\n      AND value > 1E10\n)\nSELECT name\nFROM FINANCE__ECONOMICS.CYBERSYN.financial_institution_timeseries AS ts\nINNER JOIN FINANCE__ECONOMICS.CYBERSYN.financial_institution_attributes AS att ON (ts.variable = att.variable)\nINNER JOIN FINANCE__ECONOMICS.CYBERSYN.financial_institution_entities AS ent ON (ts.id_rssd = ent.id_rssd)\nINNER JOIN big_banks ON (big_banks.id_rssd = ts.id_rssd)\nWHERE ts.date = '2022-12-31'\n  AND att.variable_name = '% Insured (Estimated)'\n  AND att.frequency = 'Quarterly'\n  AND ent.is_active = True\nORDER BY (1 - value) DESC\nLIMIT 10;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: FINANCE__ECONOMICS\nQuestion: What was the percentage change in post-market close prices for the Magnificent 7 tech companies from January 1 to June 30, 2024?"}, {"role": "assistant", "content": "WITH ytd_performance AS (\n  SELECT\n    ticker,\n    MIN(date) OVER (PARTITION BY ticker) AS start_of_year_date,\n    FIRST_VALUE(value) OVER (PARTITION BY ticker ORDER BY date ASC ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS start_of_year_price,\n    MAX(date) OVER (PARTITION BY ticker) AS latest_date,\n    LAST_VALUE(value) OVER (PARTITION BY ticker ORDER BY date ASC ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS latest_price\n  FROM FINANCE__ECONOMICS.CYBERSYN.stock_price_timeseries\n  WHERE\n    ticker IN ('AAPL', 'MSFT', 'AMZN', 'GOOGL', 'META', 'TSLA', 'NVDA')\n    AND date BETWEEN DATE '2024-01-01' AND DATE '2024-06-30'  -- Adjusted to cover only from the start of 2024 to the end of June 2024\n    AND variable_name = 'Post-Market Close'\n)\nSELECT\n  ticker,\n  (latest_price - start_of_year_price) / start_of_year_price * 100 AS percentage_change_ytd\nFROM\n  ytd_performance\nGROUP BY\n  ticker, start_of_year_date, start_of_year_price, latest_date, latest_price\nORDER BY percentage_change_ytd DESC;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: WEATHER__ENVIRONMENT\nQuestion: Using data from the FEMA National Flood Insurance Program Claim Index, for each year from 2010 through 2019, what were the total building damage amounts and total contents damage amounts reported under the National Flood Insurance Program for the NFIP community named 'City Of New York,' grouped by each year of loss?"}, {"role": "assistant", "content": "SELECT \n    YEAR(claims.date_of_loss)               AS year_of_loss,\n    claims.nfip_community_name,\n    SUM(claims.building_damage_amount) AS total_building_damage_amount,\n    SUM(claims.contents_damage_amount) AS total_contents_damage_amount\nFROM WEATHER__ENVIRONMENT.CYBERSYN.fema_national_flood_insurance_program_claim_index claims\nWHERE \n    claims.nfip_community_name = 'City Of New York' \n    AND year_of_loss >=2010 AND year_of_loss <=2019\nGROUP BY year_of_loss, claims.nfip_community_name\nORDER BY year_of_loss, claims.nfip_community_name;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: BRAZE_USER_EVENT_DEMO_DATASET\nQuestion: Examine user engagement with push notifications within a specified one-hour window on June 1, 2023.\n\nExternal Knowledge: PushNotificationAnalysis.md"}, {"role": "assistant", "content": "WITH push_send AS (\n    SELECT\n        id,\n        app_group_id,\n        user_id,\n        campaign_id,\n        message_variation_id,\n        platform,\n        ad_tracking_enabled,\n        TO_TIMESTAMP(TIME) AS \"TIME\",\n        'Send' AS \"EVENT_TYPE\"\n    FROM\n        BRAZE_USER_EVENT_DEMO_DATASET.PUBLIC.USERS_MESSAGES_PUSHNOTIFICATION_SEND_VIEW\n    WHERE\n        TO_TIMESTAMP(TIME) BETWEEN '2023-06-01 08:00:00' AND '2023-06-01 09:00:00'\n),\npush_bounce AS (\n    SELECT\n        id,\n        app_group_id,\n        user_id,\n        campaign_id,\n        message_variation_id,\n        platform,\n        ad_tracking_enabled,\n        TO_TIMESTAMP(TIME) AS \"TIME\",\n        'Bounce' AS \"EVENT_TYPE\"\n    FROM\n        BRAZE_USER_EVENT_DEMO_DATASET.PUBLIC.USERS_MESSAGES_PUSHNOTIFICATION_BOUNCE_VIEW\n    WHERE\n        TO_TIMESTAMP(TIME) BETWEEN '2023-06-01 08:00:00' AND '2023-06-01 09:00:00'\n),\npush_open AS (\n    SELECT\n        id,\n        app_group_id,\n        user_id,\n        campaign_id,\n        message_variation_id,\n        platform,\n        ad_tracking_enabled,\n        TO_TIMESTAMP(TIME) AS \"TIME\",\n        'Open' AS \"EVENT_TYPE\",\n        carrier,\n        browser,\n        device_model\n    FROM\n        BRAZE_USER_EVENT_DEMO_DATASET.PUBLIC.USERS_MESSAGES_PUSHNOTIFICATION_OPEN_VIEW\n    WHERE\n        TO_TIMESTAMP(TIME) BETWEEN '2023-06-01 08:00:00' AND '2023-06-01 09:00:00'\n),\npush_open_influence AS (\n    SELECT\n        id,\n        app_group_id,\n        user_id,\n        campaign_id,\n        message_variation_id,\n        platform,\n        TO_TIMESTAMP(TIME) AS \"TIME\",\n        'Influenced Open' AS \"EVENT_TYPE\",\n        carrier,\n        browser,\n        device_model\n    FROM\n        BRAZE_USER_EVENT_DEMO_DATASET.PUBLIC.USERS_MESSAGES_PUSHNOTIFICATION_INFLUENCEDOPEN_VIEW\n    WHERE\n        TO_TIMESTAMP(TIME) BETWEEN '2023-06-01 08:00:00' AND '2023-06-01 09:00:00'\n)\nSELECT\n    ps.app_group_id,\n    ps.campaign_id,\n    ps.user_id,\n    ps.time,\n    po.time push_open_time,\n    ps.message_variation_id,\n    ps.platform,\n    ps.ad_tracking_enabled,\n    po.carrier,\n    po.browser,\n    po.device_model,\n    COUNT(\n        DISTINCT ps.id\n    ) push_notification_sends,\n    COUNT(\n        DISTINCT ps.user_id\n    ) unique_push_notification_sends,\n    COUNT(\n        DISTINCT pb.id\n    ) push_notification_bounced,\n    COUNT(\n        DISTINCT pb.user_id\n    ) unique_push_notification_bounced,\n    COUNT(\n        DISTINCT po.id\n    ) push_notification_open,\n    COUNT(\n        DISTINCT po.user_id\n    ) unique_push_notification_opened,\n    COUNT(\n        DISTINCT poi.id\n    ) push_notification_influenced_open,\n    COUNT(\n        DISTINCT poi.user_id\n    ) unique_push_notification_influenced_open\nFROM\n    push_send ps\n    LEFT JOIN push_bounce pb\n    ON ps.message_variation_id = pb.message_variation_id\n    AND ps.user_id = pb.user_id\n    AND ps.app_group_id = pb.app_group_id\n    LEFT JOIN push_open po\n    ON ps.message_variation_id = po.message_variation_id\n    AND ps.user_id = po.user_id\n    AND ps.app_group_id = po.app_group_id\n    LEFT JOIN push_open_influence poi\n    ON ps.message_variation_id = poi.message_variation_id\n    AND ps.user_id = poi.user_id\n    AND ps.app_group_id = poi.app_group_id\nGROUP BY\n    1,2,3,4,5,6,7,8,9,10,11;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: US_ADDRESSES__POI\nQuestion: Find the top 10 northernmost addresses in Florida's largest zip code area. What are their address numbers, street names, and types?"}, {"role": "assistant", "content": "WITH zip_areas AS (\n    SELECT\n        geo.geo_id,\n        geo.geo_name AS zip,\n        states.related_geo_name AS state,\n        countries.related_geo_name AS country,\n        ST_AREA(TRY_TO_GEOGRAPHY(value)) AS area\n    FROM US_ADDRESSES__POI.CYBERSYN.geography_index AS geo\n    JOIN US_ADDRESSES__POI.CYBERSYN.geography_relationships AS states\n        ON (geo.geo_id = states.geo_id AND states.related_level = 'State')\n    JOIN US_ADDRESSES__POI.CYBERSYN.geography_relationships AS countries\n        ON (geo.geo_id = countries.geo_id AND countries.related_level = 'Country')\n    JOIN US_ADDRESSES__POI.CYBERSYN.geography_characteristics AS chars\n        ON (geo.geo_id = chars.geo_id AND chars.relationship_type = 'coordinates_geojson')\n    WHERE geo.level = 'CensusZipCodeTabulationArea'\n),\n\nzip_area_ranks AS (\n    SELECT\n        *,\n        ROW_NUMBER() OVER (PARTITION BY country, state ORDER BY area DESC, geo_id) AS zip_area_rank\n    FROM zip_areas\n)\n\nSELECT addr.number, addr.street, addr.street_type\nFROM US_ADDRESSES__POI.CYBERSYN.us_addresses AS addr\nJOIN zip_area_ranks AS areas\n    ON (addr.id_zip = areas.geo_id)\nWHERE addr.state = 'FL' AND areas.country = 'United States' AND areas.zip_area_rank = 1\nORDER BY LATITUDE DESC\nLIMIT 10;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: CENSUS_GALAXY__ZIP_CODE_TO_BLOCK_GROUP_SAMPLE\nQuestion: Determine the population distribution within each block group relative to its census tract in New York State using 2021 ACS data. Include block group ID, census value, state county tract ID, total tract population, and the population ratio of each block group."}, {"role": "assistant", "content": "WITH TractPop AS (\n    SELECT\n        CG.\"BlockGroupID\",\n        FCV.\"CensusValue\",\n        CG.\"StateCountyTractID\",\n        CG.\"BlockGroupPolygon\"\n    FROM\n        CENSUS_GALAXY__ZIP_CODE_TO_BLOCK_GROUP_SAMPLE.PUBLIC.\"Dim_CensusGeography\" CG\n    JOIN\n        CENSUS_GALAXY__ZIP_CODE_TO_BLOCK_GROUP_SAMPLE.PUBLIC.\"Fact_CensusValues_ACS2021\" FCV\n        ON CG.\"BlockGroupID\" = FCV.\"BlockGroupID\"\n    WHERE\n        CG.\"StateAbbrev\" = 'NY'\n        AND FCV.\"MetricID\" = 'B01003_001E'\n),\n\nTractGroup AS (\n    SELECT\n        CG.\"StateCountyTractID\",\n        SUM(FCV.\"CensusValue\") AS \"TotalTractPop\"\n    FROM\n        CENSUS_GALAXY__ZIP_CODE_TO_BLOCK_GROUP_SAMPLE.PUBLIC.\"Dim_CensusGeography\" CG\n    JOIN\n        CENSUS_GALAXY__ZIP_CODE_TO_BLOCK_GROUP_SAMPLE.PUBLIC.\"Fact_CensusValues_ACS2021\" FCV\n        ON CG.\"BlockGroupID\" = FCV.\"BlockGroupID\"\n    WHERE\n        CG.\"StateAbbrev\" = 'NY'\n        AND FCV.\"MetricID\" = 'B01003_001E'\n    GROUP BY\n        CG.\"StateCountyTractID\"\n)\n\nSELECT\n    TP.\"BlockGroupID\",\n    TP.\"CensusValue\",\n    TP.\"StateCountyTractID\",\n    TG.\"TotalTractPop\",\n    CASE WHEN TG.\"TotalTractPop\" <> 0 THEN TP.\"CensusValue\" / TG.\"TotalTractPop\" ELSE 0 END AS \"BlockGroupRatio\"\nFROM\n    TractPop TP\nJOIN\n    TractGroup TG\n    ON TP.\"StateCountyTractID\" = TG.\"StateCountyTractID\";"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: CENSUS_GALAXY__AIML_MODEL_DATA_ENRICHMENT_SAMPLE\nQuestion: What is the New York State ZIP code with the highest number of commuters traveling over one hour, according to 2021 ACS data? Include the zip code, the total commuters, state benchmark for this duration, and state population."}, {"role": "assistant", "content": "WITH Commuters AS (\n    SELECT\n        GE.\"ZipCode\",\n        SUM(CASE WHEN M.\"MetricID\" = 'B08303_013E' THEN F.\"CensusValueByZip\" ELSE 0 END +\n            CASE WHEN M.\"MetricID\" = 'B08303_012E' THEN F.\"CensusValueByZip\" ELSE 0 END) AS \"Num_Commuters_1Hr_Travel_Time\"\n    FROM\n        CENSUS_GALAXY__AIML_MODEL_DATA_ENRICHMENT_SAMPLE.PUBLIC.\"LU_GeographyExpanded\" GE\n    JOIN\n        CENSUS_GALAXY__AIML_MODEL_DATA_ENRICHMENT_SAMPLE.PUBLIC.\"Fact_CensusValues_ACS2021_ByZip\" F\n        ON GE.\"ZipCode\" = F.\"ZipCode\"\n    JOIN\n        CENSUS_GALAXY__AIML_MODEL_DATA_ENRICHMENT_SAMPLE.PUBLIC.\"Dim_CensusMetrics\" M\n        ON F.\"MetricID\" = M.\"MetricID\"\n    WHERE\n        GE.\"PreferredStateAbbrev\" = 'NY'\n        AND (M.\"MetricID\" = 'B08303_013E' OR M.\"MetricID\" = 'B08303_012E') -- Metric IDs for commuters with 1+ hour travel time\n    GROUP BY\n        GE.\"ZipCode\"\n),\n\nStateBenchmark AS (\n    SELECT\n        SB.\"StateAbbrev\",\n        SUM(SB.\"StateBenchmarkValue\") AS \"StateBenchmark_Over1HrTravelTime\",\n        SB.\"TotalStatePopulation\"\n    FROM\n        CENSUS_GALAXY__AIML_MODEL_DATA_ENRICHMENT_SAMPLE.PUBLIC.\"Fact_StateBenchmark_ACS2021\" SB\n    WHERE\n        SB.\"MetricID\" IN ('B08303_013E', 'B08303_012E')\n        AND SB.\"StateAbbrev\" = 'NY'\n    GROUP BY\n        SB.\"StateAbbrev\", SB.\"TotalStatePopulation\"\n)\n\nSELECT\n    C.\"ZipCode\",\n    SUM(C.\"Num_Commuters_1Hr_Travel_Time\") AS \"Total_Commuters_1Hr_Travel_Time\",\n    SB.\"StateBenchmark_Over1HrTravelTime\",\n    SB.\"TotalStatePopulation\",\nFROM\n    Commuters C\nCROSS JOIN\n    StateBenchmark SB\nGROUP BY\n    C.\"ZipCode\", SB.\"StateBenchmark_Over1HrTravelTime\", SB.\"TotalStatePopulation\"\nORDER BY\n    \"Total_Commuters_1Hr_Travel_Time\" DESC\nLIMIT 1;"}]}
