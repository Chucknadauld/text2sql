{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: ga4\nQuestion: How many distinct pseudo users had positive engagement time  in the 7-day period ending on January 7, 2021 at 23:59:59, but had no positive engagement time in the 2-day period ending on the same date (January 7, 2021 at 23:59:59) ?\n\nExternal Knowledge: ga4_obfuscated_sample_ecommerce.events.md"}, {"role": "assistant", "content": "SELECT\n  COUNT(DISTINCT MDaysUsers.user_pseudo_id) AS n_day_inactive_users_count\nFROM\n  (\n    SELECT\n      user_pseudo_id\n    FROM\n      `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*` AS T\n    CROSS JOIN\n      UNNEST(T.event_params) AS event_params\n    WHERE\n      event_params.key = 'engagement_time_msec' AND event_params.value.int_value > 0\n      AND event_timestamp > UNIX_MICROS(TIMESTAMP_SUB(TIMESTAMP('2021-01-07 23:59:59'), INTERVAL 7 DAY))\n      AND _TABLE_SUFFIX BETWEEN '20210101' AND '20210107'\n  ) AS MDaysUsers\nLEFT JOIN\n  (\n    SELECT\n      user_pseudo_id\n    FROM\n      `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*` AS T\n    CROSS JOIN\n      UNNEST(T.event_params) AS event_params\n    WHERE\n      event_params.key = 'engagement_time_msec' AND event_params.value.int_value > 0\n      AND event_timestamp > UNIX_MICROS(TIMESTAMP_SUB(TIMESTAMP('2021-01-07 23:59:59'), INTERVAL 2 DAY))\n      AND _TABLE_SUFFIX BETWEEN '20210105' AND '20210107'\n  ) AS NDaysUsers\nON MDaysUsers.user_pseudo_id = NDaysUsers.user_pseudo_id\nWHERE\n  NDaysUsers.user_pseudo_id IS NULL;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: ga360\nQuestion: Find the top-selling product among customers who bought 'Youtube Men\u2019s Vintage Henley' in July 2017, excluding itself.\n\nExternal Knowledge: google_analytics_sample.ga_sessions.md"}, {"role": "assistant", "content": "WITH GET_CUS_ID AS (\n    SELECT \n        DISTINCT fullVisitorId as Henley_CUSTOMER_ID\n    FROM \n        `bigquery-public-data.google_analytics_sample.ga_sessions_201707*`,\n        UNNEST(hits) AS hits,\n        UNNEST(hits.product) as product\n    WHERE\n        product.v2ProductName = \"YouTube Men's Vintage Henley\"\n        AND product.productRevenue IS NOT NULL\n    )\n\nSELECT\n    product.v2ProductName AS other_purchased_products\nFROM\n    `bigquery-public-data.google_analytics_sample.ga_sessions_201707*` TAB_A \n    RIGHT JOIN GET_CUS_ID\n    ON GET_CUS_ID.Henley_CUSTOMER_ID=TAB_A.fullVisitorId,\n    UNNEST(hits) AS hits,\n    UNNEST(hits.product) as product\nWHERE\n    TAB_A.fullVisitorId IN (\n        SELECT * FROM GET_CUS_ID\n    )\n    AND product.v2ProductName <> \"YouTube Men's Vintage Henley\"\n    AND product.productRevenue IS NOT NULL\nGROUP BY\n    product.v2ProductName\nORDER BY\n    SUM(product.productQuantity) DESC\nLIMIT 1;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: ga360\nQuestion: Which traffic source has the highest total transaction revenue for the year 2017, and what is the difference in millions (rounded to two decimal places) between the highest and lowest monthly total transaction revenue for that traffic source?\n\nExternal Knowledge: google_analytics_sample.ga_sessions.md"}, {"role": "assistant", "content": "WITH MONTHLY_REVENUE AS (\n    SELECT \n        FORMAT_DATE(\"%Y%m\", PARSE_DATE(\"%Y%m%d\", date)) AS month,\n        trafficSource.source AS source,\n        ROUND(SUM(totals.totalTransactionRevenue) / 1000000, 2) AS revenue\n    FROM `bigquery-public-data.google_analytics_sample.ga_sessions_2017*`\n    GROUP BY 1, 2\n),\n\nYEARLY_REVENUE AS (\n    SELECT\n        source,\n        SUM(revenue) AS total_revenue\n    FROM MONTHLY_REVENUE\n    GROUP BY source\n),\n\nTOP_SOURCE AS (\n    SELECT \n        source\n    FROM YEARLY_REVENUE\n    ORDER BY total_revenue DESC\n    LIMIT 1\n),\n\nSOURCE_MONTHLY_REVENUE AS (\n    SELECT\n        month,\n        source,\n        revenue\n    FROM MONTHLY_REVENUE\n    WHERE source IN (SELECT source FROM TOP_SOURCE)\n),\n\nREVENUE_DIFF AS (\n    SELECT \n        source,\n        ROUND(MAX(revenue), 2) AS max_revenue,\n        ROUND(MIN(revenue), 2) AS min_revenue,\n        ROUND(MAX(revenue) - MIN(revenue), 2) AS diff_revenue\n    FROM SOURCE_MONTHLY_REVENUE\n    GROUP BY source\n)\n\nSELECT \n    source,\n    diff_revenue\nFROM REVENUE_DIFF;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: ga360\nQuestion: For each visitor who made at least one transaction in February 2017, how many days elapsed between the date of their first visit in February and the date of their first transaction in February, and on what type of device did they make that first transaction?\n\nExternal Knowledge: google_analytics_sample.ga_sessions.md"}, {"role": "assistant", "content": "DECLARE start_date STRING DEFAULT '20170201';\nDECLARE end_date STRING DEFAULT '20170228';\n\nWITH visit AS (\n    SELECT\n        fullvisitorid,\n        MIN(date) AS date_first_visit\n    FROM\n        `bigquery-public-data.google_analytics_sample.ga_sessions_*`\n    WHERE\n       _TABLE_SUFFIX BETWEEN start_date AND end_date\n    GROUP BY fullvisitorid\n),\n\ntransactions AS (\n    SELECT\n        fullvisitorid,\n        MIN(date) AS date_transactions\n    FROM\n        `bigquery-public-data.google_analytics_sample.ga_sessions_*` AS ga,\n        UNNEST(ga.hits) AS hits\n    WHERE\n        hits.transaction.transactionId IS NOT NULL\n        AND\n        _TABLE_SUFFIX BETWEEN start_date AND end_date\n    GROUP BY fullvisitorid\n),\n\ndevice_transactions AS (\n    SELECT DISTINCT\n        fullvisitorid,\n        date,\n        device.deviceCategory\n    FROM\n        `bigquery-public-data.google_analytics_sample.ga_sessions_*` AS ga,\n        UNNEST(ga.hits) AS hits\n    WHERE\n        hits.transaction.transactionId IS NOT NULL\n        AND\n        _TABLE_SUFFIX BETWEEN start_date AND end_date\n),\n\nvisits_transactions AS (\n    SELECT\n        visit.fullvisitorid,\n        date_first_visit,\n        date_transactions,\n        device_transactions.deviceCategory AS device_transaction\n    FROM\n        visit\n        JOIN transactions\n        ON visit.fullvisitorid = transactions.fullvisitorid\n        JOIN device_transactions\n        ON visit.fullvisitorid = device_transactions.fullvisitorid \n        AND transactions.date_transactions = device_transactions.date\n)\n\nSELECT\n       fullvisitorid,\n       DATE_DIFF(PARSE_DATE('%Y%m%d', date_transactions), PARSE_DATE('%Y%m%d', date_first_visit), DAY) AS time,\n       device_transaction\nFROM visits_transactions\nORDER BY fullvisitorid;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: ga360\nQuestion: During the first half of 2017,  focusing on hits product revenue, which traffic source generated the highest total product revenue, and what were the maximum daily, weekly, and monthly product revenues (in millions) for that top-performing source over this period?\n\nExternal Knowledge: google_analytics_sample.ga_sessions.md"}, {"role": "assistant", "content": "DECLARE start_date STRING DEFAULT '20170101';\nDECLARE end_date STRING DEFAULT '20170630';\n\nWITH daily_revenue AS (\n    SELECT\n        trafficSource.source AS source,\n        date,\n        SUM(productRevenue) / 1000000 AS revenue\n    FROM\n        `bigquery-public-data.google_analytics_sample.ga_sessions_*`,\n        UNNEST (hits) AS hits,\n        UNNEST (hits.product) AS product\n    WHERE\n        _table_suffix BETWEEN start_date AND end_date\n    GROUP BY\n        source, date\n),\nweekly_revenue AS (\n    SELECT\n        source,\n        CONCAT(EXTRACT(YEAR FROM (PARSE_DATE('%Y%m%d', date))), 'W', EXTRACT(WEEK FROM (PARSE_DATE('%Y%m%d', date)))) AS week,\n        SUM(revenue) AS revenue\n    FROM daily_revenue\n    GROUP BY source, week\n),\nmonthly_revenue AS (\n    SELECT\n        source,\n        CONCAT(EXTRACT(YEAR FROM (PARSE_DATE('%Y%m%d', date))),'0', EXTRACT(MONTH FROM (PARSE_DATE('%Y%m%d', date)))) AS month,\n        SUM(revenue) AS revenue\n    FROM daily_revenue\n    GROUP BY source, month\n),\n\ntop_source AS (\n    SELECT source, SUM(revenue) AS total_revenue\n    FROM daily_revenue\n    GROUP BY source\n    ORDER BY total_revenue DESC\n    LIMIT 1\n),\n\nmax_revenues AS (\n    (\n      SELECT\n        'Daily' AS time_type,\n        date AS time,\n        source,\n        MAX(revenue) AS max_revenue\n      FROM daily_revenue\n      WHERE source = (SELECT source FROM top_source)\n      GROUP BY source, date\n      ORDER BY max_revenue DESC\n      LIMIT 1\n    )\n\n    UNION ALL\n\n    (\n      SELECT\n        'Weekly' AS time_type,\n        week AS time,\n        source,\n        MAX(revenue) AS max_revenue\n      FROM weekly_revenue\n      WHERE source = (SELECT source FROM top_source)\n      GROUP BY source, week\n      ORDER BY max_revenue DESC\n      LIMIT 1\n    )\n\n    UNION ALL\n\n    (\n      SELECT\n          'Monthly' AS time_type,\n          month AS time,\n          source,\n          MAX(revenue) AS max_revenue\n      FROM monthly_revenue\n      WHERE source = (SELECT source FROM top_source)\n      GROUP BY source, month\n      ORDER BY max_revenue DESC\n      LIMIT 1\n    )\n)\n\nSELECT\n    max_revenue\nFROM max_revenues\nORDER BY max_revenue DESC;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: ga360\nQuestion: Between April 1 and July 31 of 2017, using the hits product revenue data along with the totals transactions to classify sessions as purchase (transactions \u2265 1 and productRevenue not null) or non-purchase (transactions null and productRevenue null), compare the average pageviews per visitor for each group by month\n\nExternal Knowledge: google_analytics_sample.ga_sessions.md"}, {"role": "assistant", "content": "WITH cte1 AS (\n    SELECT\n        CONCAT(EXTRACT(YEAR FROM (PARSE_DATE('%Y%m%d', date))), '0',\n            EXTRACT(MONTH FROM (PARSE_DATE('%Y%m%d', date)))) AS month,\n        SUM(totals.pageviews) / COUNT(DISTINCT fullVisitorId) AS avg_pageviews_non_purchase\n    FROM\n        `bigquery-public-data.google_analytics_sample.ga_sessions_2017*`,\n        UNNEST (hits) AS hits,\n        UNNEST (hits.product) AS product\n    WHERE\n        _table_suffix BETWEEN '0401' AND '0731'\n        AND totals.transactions IS NULL\n        AND product.productRevenue IS NULL\n    GROUP BY month\n),\ncte2 AS (\n    SELECT\n        CONCAT(EXTRACT(YEAR FROM (PARSE_DATE('%Y%m%d', date))), '0',\n            EXTRACT(MONTH FROM (PARSE_DATE('%Y%m%d', date)))) AS month,\n        SUM(totals.pageviews) / COUNT(DISTINCT fullVisitorId) AS avg_pageviews_purchase\n    FROM\n        `bigquery-public-data.google_analytics_sample.ga_sessions_2017*`,\n        UNNEST (hits) AS hits,\n        UNNEST (hits.product) AS product\n    WHERE\n        _table_suffix BETWEEN '0401' AND '0731'\n        AND totals.transactions >= 1\n        AND product.productRevenue IS NOT NULL\n    GROUP BY month\n)\nSELECT\n    month, avg_pageviews_purchase, avg_pageviews_non_purchase\nFROM cte1 INNER JOIN cte2\nUSING(month)\nORDER BY month;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: ga360\nQuestion: In July 2017, among all visitors who bought any YouTube-related product, which distinct product\u2014excluding those containing \u2018YouTube\u2019 in the product name\u2014had the highest total quantity purchased?\n\nExternal Knowledge: google_analytics_sample.ga_sessions.md"}, {"role": "assistant", "content": "with product_and_quatity AS (\n    SELECT \n        DISTINCT v2ProductName AS other_purchased_products,\n        SUM(productQuantity) AS quatity\n    FROM\n        `bigquery-public-data.google_analytics_sample.ga_sessions_2017*`,\n        UNNEST(hits) AS hits,\n        UNNEST(hits.product) AS product\n    WHERE\n        _table_suffix BETWEEN '0701' AND '0731'\n        AND NOT REGEXP_CONTAINS(LOWER(v2ProductName), 'youtube')\n        AND fullVisitorID IN (\n            SELECT \n            DISTINCT fullVisitorId\n            FROM\n                `bigquery-public-data.google_analytics_sample.ga_sessions_2017*`,\n                UNNEST(hits) AS hits,\n                UNNEST(hits.product) AS product\n            WHERE\n                _table_suffix BETWEEN '0701' AND '0731'\n                AND REGEXP_CONTAINS(LOWER(v2ProductName), 'youtube')\n        )\n    GROUP BY v2ProductName\n)\nSELECT other_purchased_products\nFROM product_and_quatity\nORDER BY quatity DESC\nLIMIT 1;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: ga360\nQuestion: In January 2017, among visitors whose campaign name contains 'Data Share' and who accessed any page starting with '/home', which page did they most commonly visit next, and what is the maximum time (in seconds) they spent on the '/home' page before moving on?\n\nExternal Knowledge: google_analytics_sample.ga_sessions.md"}, {"role": "assistant", "content": "with page_visit_sequence AS (\n    SELECT\n        fullVisitorID,\n        visitID,\n        pagePath,\n        LEAD(timestamp, 1) OVER (PARTITION BY fullVisitorId, visitID order by timestamp) - timestamp AS page_duration,\n        LEAD(pagePath, 1) OVER (PARTITION BY fullVisitorId, visitID order by timestamp) AS next_page,\n        RANK() OVER (PARTITION BY fullVisitorId, visitID order by timestamp) AS step_number\n    FROM (\n        SELECT\n            pages.fullVisitorID,\n            pages.visitID,\n            pages.pagePath,\n            visitors.campaign,\n            MIN(pages.timestamp) timestamp\n        FROM (\n            SELECT\n                fullVisitorId,\n                visitId,\n                trafficSource.campaign campaign\n            FROM\n                `bigquery-public-data.google_analytics_sample.ga_sessions_*`,\n                UNNEST(hits) as hits\n            WHERE\n                _TABLE_SUFFIX BETWEEN '20170101' AND '20170131'\n                AND hits.type='PAGE'\n                AND REGEXP_CONTAINS(hits.page.pagePath, r'^/home')\n                AND REGEXP_CONTAINS(trafficSource.campaign, r'Data Share')\n        ) AS visitors\n        JOIN(\n            SELECT\n                fullVisitorId,\n                visitId,\n                visitStartTime + hits.time / 1000 AS timestamp,\n                hits.page.pagePath AS pagePath\n            FROM\n                `bigquery-public-data.google_analytics_sample.ga_sessions_*`,\n                UNNEST(hits) as hits\n            WHERE\n                _TABLE_SUFFIX BETWEEN '20170101' AND '20170131'\n        ) as pages\n        ON\n            visitors.fullVisitorID = pages.fullVisitorID\n            AND visitors.visitID = pages.visitID\n        GROUP BY \n            pages.fullVisitorID, visitors.campaign, pages.visitID, pages.pagePath\n        ORDER BY \n            pages.fullVisitorID, pages.visitID, timestamp\n    )\n    ORDER BY fullVisitorId, visitID, step_number\n),\nmost_common_next_page AS (\n    SELECT\n        next_page,\n        COUNT(next_page) as page_count\n    FROM page_visit_sequence\n    WHERE\n        next_page IS NOT NULL\n        AND REGEXP_CONTAINS(pagePath, r'^/home')\n    GROUP BY next_page\n    ORDER BY page_count DESC\n    LIMIT 1\n),\nmax_page_duration AS (\n    SELECT MAX(page_duration) as max_duration\n    FROM page_visit_sequence\n    WHERE\n        page_duration IS NOT NULL\n        AND REGEXP_CONTAINS(pagePath, r'^/home')\n)\nSELECT\n    next_page,\n    max_duration\nFROM\n    most_common_next_page,\n    max_page_duration;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: ga360\nQuestion: Between June 1, 2017, and July 31, 2017, consider only sessions that have non-null pageviews. Classify each session as \u2018purchase\u2019 if it has at least one transaction, or \u2018non_purchase\u2019 otherwise. For each month, sum each visitor\u2019s total pageviews under each classification, then compute the average pageviews per visitor for both purchase and non-purchase groups in each month, and present the results side by side."}, {"role": "assistant", "content": "WITH visitor_pageviews AS (\n  SELECT\n    FORMAT_DATE('%Y%m', PARSE_DATE('%Y%m%d', date)) AS month,\n    CASE WHEN totals.transactions > 0 THEN 'purchase' ELSE 'non_purchase' END AS purchase_status,\n    fullVisitorId,\n    SUM(totals.pageviews) AS total_pageviews\n  FROM\n    `bigquery-public-data.google_analytics_sample.ga_sessions_*`\n  WHERE\n    _TABLE_SUFFIX BETWEEN '20170601' AND '20170731'\n    AND totals.pageviews IS NOT NULL\n  GROUP BY\n    month, purchase_status, fullVisitorId\n),\navg_pageviews AS (\n  SELECT\n    month,\n    purchase_status,\n    AVG(total_pageviews) AS avg_pageviews_per_visitor\n  FROM\n    visitor_pageviews\n  GROUP BY\n    month, purchase_status\n)\nSELECT\n  month,\n  MAX(CASE WHEN purchase_status = 'purchase' THEN avg_pageviews_per_visitor END) AS avg_pageviews_purchase,\n  MAX(CASE WHEN purchase_status = 'non_purchase' THEN avg_pageviews_per_visitor END) AS avg_pageviews_non_purchase\nFROM\n  avg_pageviews\nGROUP BY\n  month\nORDER BY\n  month"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: ga360\nQuestion: Identify the longest number of days between the first visit and the last recorded event (either the last visit or the first transaction) for a user, where the last recorded event is associated with a mobile device. The last recorded event could either be the last visit or the first transaction, and you should focus on users whose last recorded event occurred on a mobile device."}, {"role": "assistant", "content": "WITH \n\nvisit AS (\nSELECT fullvisitorid, MIN(date) AS date_first_visit, MAX(date) AS date_last_visit \nFROM `bigquery-public-data.google_analytics_sample.ga_sessions_*` GROUP BY fullvisitorid),\n\ndevice_visit AS (\nSELECT DISTINCT fullvisitorid, date, device.deviceCategory\nFROM `bigquery-public-data.google_analytics_sample.ga_sessions_*`),\n\ntransactions AS (\nSELECT fullvisitorid, MIN(date) AS date_transactions, 1 AS transaction\nFROM `bigquery-public-data.google_analytics_sample.ga_sessions_*` AS ga, UNNEST(ga.hits) AS hits\nWHERE  hits.transaction.transactionId IS NOT NULL GROUP BY fullvisitorid),\n\ndevice_transactions AS (\nSELECT DISTINCT fullvisitorid, date, device.deviceCategory\nFROM `bigquery-public-data.google_analytics_sample.ga_sessions_*` AS ga, UNNEST(ga.hits) AS hits\nWHERE hits.transaction.transactionId IS NOT NULL),\n\nvisits_transactions AS (\nSELECT visit.fullvisitorid, date_first_visit, date_transactions, date_last_visit , \n       device_visit.deviceCategory AS device_last_visit, device_transactions.deviceCategory AS device_transaction, \n       IFNULL(transactions.transaction,0) AS transaction\nFROM visit LEFT JOIN transactions ON visit.fullvisitorid = transactions.fullvisitorid\nLEFT JOIN device_visit ON visit.fullvisitorid = device_visit.fullvisitorid \nAND visit.date_last_visit = device_visit.date\n\nLEFT JOIN device_transactions ON visit.fullvisitorid = device_transactions.fullvisitorid \nAND transactions.date_transactions = device_transactions.date ),\n\nmortality_table AS (\nSELECT fullvisitorid, date_first_visit, \n       CASE WHEN date_transactions IS NULL THEN date_last_visit ELSE date_transactions  END AS date_event, \n       CASE WHEN device_transaction IS NULL THEN device_last_visit ELSE device_transaction END AS device, transaction\nFROM visits_transactions )\n\nSELECT DATE_DIFF(PARSE_DATE('%Y%m%d',date_event), PARSE_DATE('%Y%m%d', date_first_visit),DAY) AS time \nFROM mortality_table\nWHERE device = 'mobile'\nORDER BY DATE_DIFF(PARSE_DATE('%Y%m%d',date_event), PARSE_DATE('%Y%m%d', date_first_visit),DAY) DESC\nLIMIT 1"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: ga360\nQuestion: What were the monthly add-to-cart and purchase conversion rates, calculated as a percentage of pageviews on product details, from January to March 2017?\n\nExternal Knowledge: ga360_hits.eCommerceAction.action_type.md"}, {"role": "assistant", "content": "WITH\n  cte1 AS\n    (SELECT\n      CONCAT(EXTRACT(YEAR FROM (PARSE_DATE('%Y%m%d', date))),'0',\n                EXTRACT(MONTH FROM (PARSE_DATE('%Y%m%d', date)))) AS month,\n      COUNT(hits.eCommerceAction.action_type) AS num_product_view\n    FROM `bigquery-public-data.google_analytics_sample.ga_sessions_2017*`,\n      UNNEST(hits) AS hits\n    WHERE _table_suffix BETWEEN '0101' AND '0331'\n      AND hits.eCommerceAction.action_type = '2'\n    GROUP BY month),\n  cte2 AS\n    (SELECT\n      CONCAT(EXTRACT(YEAR FROM (PARSE_DATE('%Y%m%d', date))),'0',\n                EXTRACT(MONTH FROM (PARSE_DATE('%Y%m%d', date)))) AS month,\n      COUNT(hits.eCommerceAction.action_type) AS num_addtocart\n    FROM `bigquery-public-data.google_analytics_sample.ga_sessions_2017*`,\n      UNNEST(hits) AS hits\n    WHERE _table_suffix BETWEEN '0101' AND '0331'\n      AND hits.eCommerceAction.action_type = '3'\n    GROUP BY month),\n  cte3 AS\n    (SELECT\n      CONCAT(EXTRACT(YEAR FROM (PARSE_DATE('%Y%m%d', date))),'0',\n                EXTRACT(MONTH FROM (PARSE_DATE('%Y%m%d', date)))) AS month,\n      COUNT(hits.eCommerceAction.action_type) AS num_purchase\n    FROM `bigquery-public-data.google_analytics_sample.ga_sessions_2017*`,\n      UNNEST(hits) AS hits,\n      UNNEST(hits.product) AS product\n    WHERE _table_suffix BETWEEN '0101' AND '0331'\n      AND hits.eCommerceAction.action_type = '6'\n      AND product.productRevenue IS NOT NULL\n    GROUP BY month)\nSELECT \n  ROUND((num_addtocart/num_product_view * 100),2) AS add_to_cart_rate,\n  ROUND((num_purchase/num_product_view * 100),2) AS purchase_rate\nFROM cte1\n  LEFT JOIN cte2\n  USING(month) \n  LEFT JOIN cte3\n  USING(month)\nORDER BY month;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: ga360\nQuestion: Which visitor IDs belong to users whose first transaction occurred on a device explicitly labeled as 'mobile' on a later date than their first visit?"}, {"role": "assistant", "content": "WITH \n  visit AS (\n    SELECT fullvisitorid, MIN(date) AS date_first_visit\n    FROM `bigquery-public-data.google_analytics_sample.ga_sessions_*` \n    GROUP BY fullvisitorid\n  ),\n  \n  transactions AS (\n    SELECT fullvisitorid, MIN(date) AS date_transactions, 1 AS transaction\n    FROM `bigquery-public-data.google_analytics_sample.ga_sessions_*` AS ga, \n    UNNEST(ga.hits) AS hits \n    WHERE hits.transaction.transactionId IS NOT NULL \n    GROUP BY fullvisitorid\n  ),\n\n  device_transactions AS (\n    SELECT DISTINCT fullvisitorid, date, device.deviceCategory AS device_transaction\n    FROM `bigquery-public-data.google_analytics_sample.ga_sessions_*` AS ga, \n    UNNEST(ga.hits) AS hits \n    WHERE hits.transaction.transactionId IS NOT NULL\n  ),\n\n  visits_transactions AS (\n    SELECT visit.fullvisitorid, date_first_visit, date_transactions, device_transaction\n    FROM visit \n    LEFT JOIN transactions ON visit.fullvisitorid = transactions.fullvisitorid\n    LEFT JOIN device_transactions ON visit.fullvisitorid = device_transactions.fullvisitorid \n    AND transactions.date_transactions = device_transactions.date\n  )\n\nSELECT fullvisitorid \nFROM visits_transactions\nWHERE DATE_DIFF(PARSE_DATE('%Y%m%d', date_transactions), PARSE_DATE('%Y%m%d', date_first_visit), DAY) > 0\nAND device_transaction = \"mobile\";"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: ga360\nQuestion: Calculates the percentage of new users who, between August 1, 2016, and April 30, 2017, both stayed on the site for more than 5 minutes during their initial visit and made a purchase on a subsequent visit at any later time, relative to the total number of new users in the same period."}, {"role": "assistant", "content": "WITH initial_visits AS (\n    SELECT\n        fullVisitorId,\n        MIN(visitStartTime) AS initialVisitStartTime\n    FROM\n        `bigquery-public-data.google_analytics_sample.*`\n    WHERE\n        totals.newVisits = 1\n        AND date BETWEEN '20160801' AND '20170430'\n    GROUP BY\n        fullVisitorId\n),\nqualified_initial_visits AS (\n  SELECT\n    s.fullVisitorId,\n    s.visitStartTime AS initialVisitStartTime,\n    s.totals.timeOnSite AS time_on_site\n  FROM\n    `bigquery-public-data.google_analytics_sample.*` s\n  JOIN initial_visits i\n    ON s.fullVisitorId = i.fullVisitorId\n    AND s.visitStartTime = i.initialVisitStartTime\n  WHERE\n    s.totals.timeOnSite > 300\n),\nfiltered_data AS (\n  SELECT\n    q.fullVisitorId,\n    q.time_on_site,\n    IF(COUNTIF(s.visitStartTime > q.initialVisitStartTime AND s.totals.transactions > 0) > 0, 1, 0) AS will_buy_on_return_visit\n  FROM\n    qualified_initial_visits q\n  LEFT JOIN `bigquery-public-data.google_analytics_sample.*` s\n    ON q.fullVisitorId = s.fullVisitorId\n  GROUP BY\n    q.fullVisitorId, q.time_on_site\n),\nmatching_users AS (\n  SELECT\n    fullVisitorId\n  FROM\n    filtered_data\n  WHERE\n    time_on_site > 300 AND will_buy_on_return_visit = 1\n),\ntotal_new_users AS (\n  SELECT\n    COUNT(DISTINCT fullVisitorId) AS total_new_users\n  FROM\n    `bigquery-public-data.google_analytics_sample.*`\n  WHERE\n    totals.newVisits = 1\n    AND date BETWEEN '20160801' AND '20170430'\n),\nfinal_counts AS (\n  SELECT\n    COUNT(DISTINCT fullVisitorId) AS users_matching_criteria\n  FROM\n    matching_users\n)\nSELECT\n  (final_counts.users_matching_criteria / total_new_users.total_new_users) * 100 AS percentage_matching_criteria\nFROM\n  final_counts,\n  total_new_users;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: PATENTS\nQuestion: In which year did the assignee with the most applications in the patent category 'A61' file the most?"}, {"role": "assistant", "content": "WITH AA AS (\n    SELECT \n        FIRST_VALUE(\"assignee_harmonized\") OVER (PARTITION BY \"application_number\" ORDER BY \"application_number\") AS assignee_harmonized,\n        FIRST_VALUE(\"filing_date\") OVER (PARTITION BY \"application_number\" ORDER BY \"application_number\") AS filing_date,\n        \"application_number\"\n    FROM \n        PATENTS.PATENTS.PUBLICATIONS AS pubs\n        , LATERAL FLATTEN(input => pubs.\"cpc\") AS c\n    WHERE \n        c.value:\"code\" LIKE 'A61%'\n),\n\nPatentApplications AS (\n    SELECT \n        ANY_VALUE(assignee_harmonized) as assignee_harmonized,\n        ANY_VALUE(filing_date) as filing_date\n    FROM AA\n    GROUP BY \"application_number\"\n),\n\nAssigneeApplications AS (\nSELECT \n    COUNT(*) AS total_applications,\n    a.value::STRING AS assignee_name,\n    CAST(FLOOR(filing_date / 10000) AS INT) AS filing_year\nFROM \n    PatentApplications\n    , LATERAL FLATTEN(input => assignee_harmonized) AS a\nGROUP BY \n    a.value::STRING, filing_year\n),\n\nTotalApplicationsPerAssignee AS (\n    SELECT\n        assignee_name,\n        SUM(total_applications) AS total_applications\n    FROM \n        AssigneeApplications\n    GROUP BY \n        assignee_name\n    ORDER BY \n        total_applications DESC\n    LIMIT 1\n),\n\nMaxYearForTopAssignee AS (\n    SELECT\n        aa.assignee_name,\n        aa.filing_year,\n        aa.total_applications\n    FROM \n        AssigneeApplications aa\n    INNER JOIN\n        TotalApplicationsPerAssignee tapa ON aa.assignee_name = tapa.assignee_name\n    ORDER BY \n        aa.total_applications DESC\n    LIMIT 1\n)\n\nSELECT filing_year\nFROM \n    MaxYearForTopAssignee"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: PATENTS\nQuestion: For patent class A01B3, I want to analyze the information of the top 3 assignees based on the total number of applications. Please provide the following five pieces of information: the name of this assignee,  total number of applications, the year with the most applications, the number of applications in that year, and the country code with the most applications during that year."}, {"role": "assistant", "content": "WITH PatentApplications AS (\n   SELECT \n        \"assignee_harmonized\" AS assignee_harmonized,\n        \"filing_date\" AS filing_date,\n        \"country_code\" AS country_code,\n        \"application_number\" AS application_number\n    FROM \n        PATENTS.PATENTS.PUBLICATIONS AS pubs,\n        LATERAL FLATTEN(input => pubs.\"cpc\") AS c\n    WHERE c.value:\"code\" LIKE 'A01B3%'\n\n),\n\nAssigneeApplications AS (\n    SELECT \n        COUNT(*) AS year_country_cnt,\n        a.value:\"name\" AS assignee_name,\n        CAST(FLOOR(filing_date / 10000) AS INT) AS filing_year,\n        apps.country_code as country_code\n    FROM \n        PatentApplications as apps,\n        LATERAL FLATTEN(input => assignee_harmonized) AS a\n    GROUP BY \n        assignee_name, filing_year, country_code\n),\n\nRankedApplications AS (\n    SELECT\n        assignee_name,\n        filing_year,\n        country_code,\n        year_country_cnt,\n        SUM(year_country_cnt) OVER (PARTITION BY assignee_name, filing_year) AS total_cnt,\n        ROW_NUMBER() OVER (PARTITION BY assignee_name, filing_year ORDER BY year_country_cnt DESC) AS rn\n    FROM\n        AssigneeApplications\n),\n\nAggregatedData AS (\n    SELECT\n        total_cnt AS year_cnt,\n        assignee_name,\n        filing_year,\n        country_code\n    FROM\n        RankedApplications\n    WHERE\n        rn = 1\n)\n\n\nSELECT \n    total_count,\n    REPLACE(assignee_name, '\"', '') AS assignee_name,\n    year_cnt,\n    filing_year,\n    country_code\nFROM (\n    SELECT \n        year_cnt,\n        assignee_name,\n        filing_year,\n        country_code,\n        SUM(year_cnt) OVER (PARTITION BY assignee_name) AS total_count,\n        ROW_NUMBER() OVER (PARTITION BY assignee_name ORDER BY year_cnt DESC) AS rn\n    FROM\n        AggregatedData\n    ORDER BY assignee_name\n) sub\nWHERE rn = 1\nORDER BY total_count\nDESC\nLIMIT 3"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: PATENTS\nQuestion: How many U.S. publications related to IoT (where the abstract includes the phrase 'internet of things') were filed each month from 2008 to 2022, including months with no filings?"}, {"role": "assistant", "content": "WITH Patent_Matches AS (\n    SELECT\n      TO_DATE(CAST(ANY_VALUE(patentsdb.\"filing_date\") AS STRING), 'YYYYMMDD') AS Patent_Filing_Date,\n      patentsdb.\"application_number\" AS Patent_Application_Number,\n      MAX(abstract_info.value:\"text\") AS Patent_Title,\n      MAX(abstract_info.value:\"language\") AS Patent_Title_Language\n    FROM\n      PATENTS.PATENTS.PUBLICATIONS AS patentsdb,\n      LATERAL FLATTEN(input => patentsdb.\"abstract_localized\") AS abstract_info\n    WHERE\n      LOWER(abstract_info.value:\"text\") LIKE '%internet of things%'\n      AND patentsdb.\"country_code\" = 'US'\n    GROUP BY\n      Patent_Application_Number\n),\n\nDate_Series_Table AS (\n    SELECT\n        DATEADD(day, seq4(), DATE '2008-01-01') AS day,\n        0 AS Number_of_Patents\n    FROM\n        TABLE(\n            GENERATOR(\n                ROWCOUNT => 5479\n            )\n        )\n    ORDER BY\n        day\n)\n\nSELECT\n  TO_CHAR(Date_Series_Table.day, 'YYYY-MM') AS Patent_Date_YearMonth,\n  COUNT(Patent_Matches.Patent_Application_Number) AS Number_of_Patent_Applications\nFROM\n  Date_Series_Table\n  LEFT JOIN Patent_Matches\n    ON Date_Series_Table.day = Patent_Matches.Patent_Filing_Date\nWHERE\n    Date_Series_Table.day < DATE '2023-01-01'\nGROUP BY\n  TO_CHAR(Date_Series_Table.day, 'YYYY-MM')\nORDER BY\n  Patent_Date_YearMonth;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: PATENTS\nQuestion: Can you calculate the number of utility patents that were granted in 2010 and have exactly one forward citation within a 10-year window following their application/filing date? For this analysis, forward citations should be counted as distinct citing application numbers that cited the patent within 10 years after the patent's own filing date."}, {"role": "assistant", "content": "WITH patents_sample AS (\n    SELECT\n        t1.\"publication_number\",\n        t1.\"application_number\"\n    FROM\n        PATENTS.PATENTS.PUBLICATIONS t1\n    WHERE\n        TO_DATE(\n            CASE\n                WHEN t1.\"grant_date\" != 0 THEN TO_CHAR(t1.\"grant_date\")\n                ELSE NULL\n            END, \n            'YYYYMMDD'\n        ) BETWEEN TO_DATE('20100101', 'YYYYMMDD') AND TO_DATE('20101231', 'YYYYMMDD')\n),\nforward_citation AS (\n    SELECT\n        patents_sample.\"publication_number\",\n        COUNT(DISTINCT t3.\"citing_application_number\") AS \"forward_citations\"\n    FROM\n        patents_sample\n        LEFT JOIN (\n            SELECT\n                x2.\"publication_number\",\n                TO_DATE(\n                    CASE\n                        WHEN x2.\"filing_date\" != 0 THEN TO_CHAR(x2.\"filing_date\")\n                        ELSE NULL\n                    END,\n                    'YYYYMMDD'\n                ) AS \"filing_date\"\n            FROM\n                PATENTS.PATENTS.PUBLICATIONS x2\n            WHERE\n                x2.\"filing_date\" != 0\n        ) t2\n            ON t2.\"publication_number\" = patents_sample.\"publication_number\"\n        LEFT JOIN (\n            SELECT\n                x3.\"publication_number\" AS \"citing_publication_number\",\n                x3.\"application_number\" AS \"citing_application_number\",\n                TO_DATE(\n                    CASE\n                        WHEN x3.\"filing_date\" != 0 THEN TO_CHAR(x3.\"filing_date\")\n                        ELSE NULL\n                    END,\n                    'YYYYMMDD'\n                ) AS \"joined_filing_date\",\n                cite.value:\"publication_number\"::STRING AS \"cited_publication_number\"\n            FROM\n                PATENTS.PATENTS.PUBLICATIONS x3,\n                LATERAL FLATTEN(INPUT => x3.\"citation\") cite\n            WHERE\n                x3.\"filing_date\" != 0\n        ) t3\n            ON patents_sample.\"publication_number\" = t3.\"cited_publication_number\"\n            AND t3.\"joined_filing_date\" BETWEEN t2.\"filing_date\" AND DATEADD(YEAR, 10, t2.\"filing_date\")\n    GROUP BY\n        patents_sample.\"publication_number\"\n)\n\nSELECT\n    COUNT(*)\nFROM\n    forward_citation\nWHERE\n    \"forward_citations\" = 1;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: PATENTS\nQuestion: How many US B2 patents granted between 2008 and 2018 contain claims that do not include the word 'claim'?"}, {"role": "assistant", "content": "WITH patents_sample AS (\n  SELECT \n    t1.\"publication_number\" AS publication_number,\n    claim.value:\"text\" AS claims_text\n  FROM \n    PATENTS.PATENTS.PUBLICATIONS t1,\n    LATERAL FLATTEN(input => t1.\"claims_localized\") AS claim\n  WHERE \n    t1.\"country_code\" = 'US'\n    AND t1.\"grant_date\" BETWEEN 20080101 AND 20181231\n    AND t1.\"grant_date\" != 0\n    AND t1.\"publication_number\" LIKE '%B2%'\n),\nPublication_data AS (\n  SELECT\n    publication_number,\n    COUNT_IF(claims_text NOT LIKE '%claim%') AS nb_indep_claims\n  FROM\n    patents_sample\n  GROUP BY\n    publication_number\n)\n\nSELECT COUNT(nb_indep_claims)\nFROM Publication_data\nWHERE nb_indep_claims != 0"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: PATENTS\nQuestion: What is the most common 4-digit IPC code among US B2 utility patents granted from June to August in 2022?\n\nExternal Knowledge: patents_info.md"}, {"role": "assistant", "content": "WITH interim_table as(\nSELECT \n    t1.\"publication_number\", \n    SUBSTR(ipc_u.value:\"code\", 0, 4) as ipc4\nFROM \n    PATENTS.PATENTS.PUBLICATIONS t1,\n    LATERAL FLATTEN(input => t1.\"ipc\") AS ipc_u\nWHERE\n\"country_code\" = 'US'  \nAND \"grant_date\" between 20220601 AND 20220831\n  AND \"grant_date\" != 0\n  AND \"publication_number\" LIKE '%B2%'  \nGROUP BY \n    t1.\"publication_number\", \n    ipc4\n) \nSELECT \nipc4\nFROM \ninterim_table \nGROUP BY ipc4\nORDER BY COUNT(\"publication_number\") DESC\nLIMIT 1"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: PATENTS_GOOGLE\nQuestion: Identify the top five patents filed in the same year as `US-9741766-B2` that are most similar to it based on technological similarities. Please provide the publication numbers.\n\nExternal Knowledge: patents_info.md"}, {"role": "assistant", "content": "WITH patents_sample AS (\n    SELECT \n        \"publication_number\", \n        \"application_number\"\n    FROM\n        PATENTS_GOOGLE.PATENTS_GOOGLE.PUBLICATIONS\n    WHERE\n        \"publication_number\" = 'US-9741766-B2'\n),\nflattened_t5 AS (\n    SELECT\n        t5.\"publication_number\",\n        f.value AS element_value,\n        f.index AS pos\n    FROM\n        PATENTS_GOOGLE.PATENTS_GOOGLE.ABS_AND_EMB t5,\n        LATERAL FLATTEN(input => t5.\"embedding_v1\") AS f\n),\nflattened_t6 AS (\n    SELECT\n        t6.\"publication_number\",\n        f.value AS element_value,\n        f.index AS pos\n    FROM\n        PATENTS_GOOGLE.PATENTS_GOOGLE.ABS_AND_EMB t6,\n        LATERAL FLATTEN(input => t6.\"embedding_v1\") AS f\n),\nsimilarities AS (\n    SELECT\n        t1.\"publication_number\" AS base_publication_number,\n        t4.\"publication_number\" AS similar_publication_number,\n        SUM(ft5.element_value * ft6.element_value) AS similarity\n    FROM\n        (SELECT * FROM patents_sample LIMIT 1) t1\n    LEFT JOIN (\n        SELECT \n            x3.\"publication_number\",\n            EXTRACT(YEAR, TO_DATE(CAST(x3.\"filing_date\" AS STRING), 'YYYYMMDD')) AS focal_filing_year\n        FROM \n            PATENTS_GOOGLE.PATENTS_GOOGLE.PUBLICATIONS x3\n        WHERE \n            x3.\"filing_date\" != 0\n    ) t3 ON t3.\"publication_number\" = t1.\"publication_number\"\n    LEFT JOIN (\n        SELECT \n            x4.\"publication_number\",\n            EXTRACT(YEAR, TO_DATE(CAST(x4.\"filing_date\" AS STRING), 'YYYYMMDD')) AS filing_year\n        FROM \n            PATENTS_GOOGLE.PATENTS_GOOGLE.PUBLICATIONS x4\n        WHERE \n            x4.\"filing_date\" != 0\n    ) t4 ON\n        t4.\"publication_number\" != t1.\"publication_number\"\n        AND t3.focal_filing_year = t4.filing_year\n    LEFT JOIN flattened_t5 AS ft5 ON ft5.\"publication_number\" = t1.\"publication_number\"\n    LEFT JOIN flattened_t6 AS ft6 ON ft6.\"publication_number\" = t4.\"publication_number\"\n    AND ft5.pos = ft6.pos  -- Align vector positions\n    GROUP BY\n        t1.\"publication_number\", t4.\"publication_number\"\n)\nSELECT\n    s.similar_publication_number,\n    s.similarity\nFROM (\n    SELECT\n        s.*,\n        ROW_NUMBER() OVER (PARTITION BY s.base_publication_number ORDER BY s.similarity DESC) AS seqnum\n    FROM\n        similarities s\n) s\nWHERE\n    seqnum <= 5;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: PATENTS_GOOGLE\nQuestion: For each publication family whose earliest publication was first published in January 2015, please provide the earliest publication date, the distinct publication numbers, their country codes, the distinct CPC and IPC codes, distinct families (namely, the ids) that cite and are cited by this publication family. Please present all lists as comma-separated values, sorted alphabetically"}, {"role": "assistant", "content": "WITH fam AS (\n  SELECT DISTINCT\n    \"family_id\"\n  FROM\n    \"PATENTS_GOOGLE\".\"PATENTS_GOOGLE\".\"PUBLICATIONS\"\n),\n\ncrossover AS (\n  SELECT\n    \"publication_number\",\n    \"family_id\"\n  FROM\n    \"PATENTS_GOOGLE\".\"PATENTS_GOOGLE\".\"PUBLICATIONS\"\n),\n\npub AS (\n  SELECT\n    \"family_id\",\n    MIN(\"publication_date\") AS \"publication_date\",\n    LISTAGG(\"publication_number\", ',') WITHIN GROUP (ORDER BY \"publication_number\") AS \"publication_number\",\n    LISTAGG(\"country_code\", ',') WITHIN GROUP (ORDER BY \"country_code\") AS \"country_code\"\n  FROM\n    \"PATENTS_GOOGLE\".\"PATENTS_GOOGLE\".\"PUBLICATIONS\" AS p\n  GROUP BY\n    \"family_id\"\n),\n\ntech_class AS (\n  SELECT\n    p.\"family_id\",\n    LISTAGG(DISTINCT cpc.value:\"code\"::STRING, ',') WITHIN GROUP (ORDER BY cpc.value:\"code\"::STRING) AS \"cpc\",\n    LISTAGG(DISTINCT ipc.value:\"code\"::STRING, ',') WITHIN GROUP (ORDER BY ipc.value:\"code\"::STRING) AS \"ipc\"\n  FROM\n    \"PATENTS_GOOGLE\".\"PATENTS_GOOGLE\".\"PUBLICATIONS\" AS p\n    CROSS JOIN LATERAL FLATTEN(input => p.\"cpc\") AS cpc\n    CROSS JOIN LATERAL FLATTEN(input => p.\"ipc\") AS ipc\n  GROUP BY\n    p.\"family_id\"\n),\n\ncit AS (\n  SELECT\n    p.\"family_id\",\n    LISTAGG(crossover.\"family_id\", ',') WITHIN GROUP (ORDER BY crossover.\"family_id\" ASC) AS \"citation\"\n  FROM\n    \"PATENTS_GOOGLE\".\"PATENTS_GOOGLE\".\"PUBLICATIONS\" AS p\n    CROSS JOIN LATERAL FLATTEN(input => p.\"citation\") AS citation\n    LEFT JOIN\n      crossover\n    ON\n      citation.value:\"publication_number\"::STRING = crossover.\"publication_number\"\n  GROUP BY\n    p.\"family_id\"\n),\n\ntmp_gpr AS (\n  SELECT\n    \"family_id\",\n    LISTAGG(crossover.\"publication_number\", ',') AS \"cited_by_publication_number\"\n  FROM\n    \"PATENTS_GOOGLE\".\"PATENTS_GOOGLE\".\"ABS_AND_EMB\" AS p\n    CROSS JOIN LATERAL FLATTEN(input => p.\"cited_by\") AS cited_by\n    LEFT JOIN\n      crossover\n    ON\n      cited_by.value:\"publication_number\"::STRING = crossover.\"publication_number\"\n  GROUP BY\n    \"family_id\"\n),\n\ngpr AS (\n  SELECT\n    tmp_gpr.\"family_id\",\n    LISTAGG(crossover.\"family_id\", ',') WITHIN GROUP (ORDER BY crossover.\"family_id\" ASC) AS \"cited_by\"\n  FROM\n    tmp_gpr\n    CROSS JOIN LATERAL FLATTEN(input => SPLIT(tmp_gpr.\"cited_by_publication_number\", ',')) AS cited_by_publication_number\n    LEFT JOIN\n      crossover\n    ON\n      cited_by_publication_number.value::STRING = crossover.\"publication_number\"\n  GROUP BY\n    tmp_gpr.\"family_id\"\n)\n\nSELECT\n  fam.\"family_id\",\n  pub.\"publication_date\",\n  pub.\"publication_number\",\n  pub.\"country_code\",\n  tech_class.\"cpc\",\n  tech_class.\"ipc\",\n  cit.\"citation\",\n  gpr.\"cited_by\"\nFROM\n  fam\n  LEFT JOIN pub ON fam.\"family_id\" = pub.\"family_id\"\n  LEFT JOIN tech_class ON fam.\"family_id\" = tech_class.\"family_id\"\n  LEFT JOIN cit ON fam.\"family_id\" = cit.\"family_id\"\n  LEFT JOIN gpr ON fam.\"family_id\" = gpr.\"family_id\"\nWHERE\n  pub.\"publication_date\" BETWEEN 20150101 AND 20150131;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: PATENTS\nQuestion: Find the CPC technology areas in Germany that had the highest exponential moving average (smoothing factor 0.1) of patent filings per year, specifically for patents granted in December 2016. For each CPC group at level 4, show the full title, CPC group, and the year with the highest exponential moving average of patent filings.\n\nExternal Knowledge: sliding_windows_calculation_cpc.md"}, {"role": "assistant", "content": "WITH patent_cpcs AS (\n    SELECT\n        cd.\"parents\",\n        CAST(FLOOR(\"filing_date\" / 10000) AS INT) AS \"filing_year\"\n    FROM (\n        SELECT MAX(\"cpc\") AS \"cpc\", MAX(\"filing_date\") AS \"filing_date\"\n        FROM \"PATENTS\".\"PATENTS\".\"PUBLICATIONS\"\n        WHERE \"application_number\" != ''\n          AND \"country_code\" = 'DE'\n          AND \"grant_date\" >= 20161201\n          AND \"grant_date\" <= 20161231\n        GROUP BY \"application_number\"\n    ), LATERAL FLATTEN(INPUT => \"cpc\") AS cpcs\n    JOIN \"PATENTS\".\"PATENTS\".\"CPC_DEFINITION\" cd ON cd.\"symbol\" = cpcs.value:\"code\"\n    WHERE cpcs.value:\"first\" = TRUE\n      AND \"filing_date\" > 0\n),\nyearly_counts AS (\n    SELECT\n        \"cpc_group\",\n        \"filing_year\",\n        COUNT(*) AS \"cnt\"\n    FROM (\n        SELECT\n            cpc_parent.VALUE AS \"cpc_group\",  -- Corrected reference to flattened \"parents\"\n            \"filing_year\"\n        FROM patent_cpcs,\n             LATERAL FLATTEN(INPUT => \"parents\") AS cpc_parent  -- Corrected reference to flattened \"parents\"\n    )\n    GROUP BY \"cpc_group\", \"filing_year\"\n),\nmoving_avg AS (\n    SELECT\n        \"cpc_group\",\n        \"filing_year\",\n        \"cnt\",\n        AVG(\"cnt\") OVER (PARTITION BY \"cpc_group\" ORDER BY \"filing_year\" ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS \"moving_avg\"\n    FROM yearly_counts\n)\nSELECT \n    c.\"titleFull\",  -- Ensure correct column name (check case)\n    REPLACE(\"cpc_group\", '\"', '') AS \"cpc_group\",\n    MAX(\"filing_year\") AS \"best_filing_year\"\nFROM moving_avg\nJOIN \"PATENTS\".\"PATENTS\".\"CPC_DEFINITION\" c ON \"cpc_group\" = c.\"symbol\"\nWHERE c.\"level\" = 4\nGROUP BY c.\"titleFull\", \"cpc_group\"\nORDER BY c.\"titleFull\", \"cpc_group\" ASC;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: PATENTS\nQuestion: Identify the CPC technology areas with the highest exponential moving average of patent filings each year (with a smoothing factor of 0.2), considering only the first CPC code for each patent that has a valid filing date and a non-empty application number, and report the full CPC title along with the best year associated with the highest exponential moving average for each CPC group at level 5.\n\nExternal Knowledge: sliding_windows_calculation_cpc.md"}, {"role": "assistant", "content": "WITH patent_cpcs AS (\n    SELECT\n        cd.\"parents\",\n        CAST(FLOOR(\"filing_date\" / 10000) AS INT) AS \"filing_year\"\n    FROM (\n        SELECT\n            MAX(\"cpc\") AS \"cpc\", MAX(\"filing_date\") AS \"filing_date\"\n        FROM\n            PATENTS.PATENTS.PUBLICATIONS\n        WHERE \n            \"application_number\" != ''\n        GROUP BY\n            \"application_number\"\n    ) AS publications\n    , LATERAL FLATTEN(INPUT => \"cpc\") AS cpcs\n    JOIN\n        PATENTS.PATENTS.CPC_DEFINITION cd ON cd.\"symbol\" = cpcs.value:\"code\"\n    WHERE \n        cpcs.value:\"first\" = TRUE\n          AND \"filing_date\" > 0\n\n),\nyearly_counts AS (\n    SELECT\n        \"cpc_group\",\n        \"filing_year\",\n        COUNT(*) AS \"cnt\"\n    FROM (\n        SELECT\n            cpc_parent.value::STRING AS \"cpc_group\",\n            \"filing_year\"\n        FROM patent_cpcs,\n             LATERAL FLATTEN(input => patent_cpcs.\"parents\") AS cpc_parent\n    )\n    GROUP BY \"cpc_group\", \"filing_year\"\n),\nordered_counts AS (\n    SELECT\n        \"cpc_group\",\n        \"filing_year\",\n        \"cnt\",\n        ROW_NUMBER() OVER (PARTITION BY \"cpc_group\" ORDER BY \"filing_year\" ASC) AS rn\n    FROM yearly_counts\n),\nrecursive_ema AS (\n    -- Anchor member: first year per cpc_group\n    SELECT\n        \"cpc_group\",\n        \"filing_year\",\n        \"cnt\",\n        \"cnt\" * 0.2 + 0 * 0.8 AS \"ema\",\n        rn\n    FROM ordered_counts\n    WHERE rn = 1\n\n    UNION ALL\n\n    -- Recursive member: subsequent years\n    SELECT\n        oc.\"cpc_group\",\n        oc.\"filing_year\",\n        oc.\"cnt\",\n        oc.\"cnt\" * 0.2 + re.\"ema\" * 0.8 AS \"ema\",\n        oc.rn\n    FROM ordered_counts oc\n    JOIN recursive_ema re\n        ON oc.\"cpc_group\" = re.\"cpc_group\"\n       AND oc.rn = re.rn + 1\n),\nmax_ema AS (\n    SELECT\n        \"cpc_group\",\n        \"filing_year\",\n        \"ema\"\n    FROM recursive_ema\n),\nranked_ema AS (\n    SELECT\n        me.\"cpc_group\",\n        me.\"filing_year\",\n        me.\"ema\",\n        ROW_NUMBER() OVER (\n            PARTITION BY me.\"cpc_group\" \n            ORDER BY me.\"ema\" DESC, me.\"filing_year\" DESC\n        ) AS rn_rank\n    FROM max_ema me\n)\nSELECT \n    c.\"titleFull\",\n    REPLACE(r.\"cpc_group\", '\"', '') AS \"cpc_group\",\n    r.\"filing_year\" AS \"best_filing_year\"\nFROM ranked_ema r\nJOIN \"PATENTS\".\"PATENTS\".\"CPC_DEFINITION\" c \n    ON r.\"cpc_group\" = c.\"symbol\"\nWHERE \n    c.\"level\" = 5\n    AND r.rn_rank = 1\nORDER BY \n    c.\"titleFull\", \n    \"cpc_group\" ASC;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: PATENTS\nQuestion: Which assignees, excluding DENSO CORP itself, have cited patents assigned to DENSO CORP, and what are the titles of the primary CPC subclasses associated with these citations? Provide the name of each citing assignee (excluding DENSO CORP), the full title of the primary CPC subclass (based on the first CPC code), and the count of citations grouped by the citing assignee and the CPC subclass title. Ensure that only citations of patents with valid filing dates are considered, and focus on the first CPC code for each citing patent. The results should specifically exclude DENSO CORP as a citing assignee.\n\nExternal Knowledge: patents_info.md"}, {"role": "assistant", "content": "SELECT\n    REPLACE(citing_assignee, '\"', '') AS citing_assignee,\n    cpcdef.\"titleFull\" AS cpc_title,\n    COUNT(*) AS number\nFROM (\n    SELECT\n        pubs.\"publication_number\" AS citing_publication_number,\n        cite.value:\"publication_number\" AS cited_publication_number,\n        citing_assignee_s.value:\"name\" AS citing_assignee,\n        SUBSTR(cpcs.value:\"code\", 1, 4) AS citing_cpc_subclass\n    FROM \n        PATENTS.PATENTS.PUBLICATIONS AS pubs\n    , LATERAL FLATTEN(input => pubs.\"citation\") AS cite\n    , LATERAL FLATTEN(input => pubs.\"assignee_harmonized\") AS citing_assignee_s\n    , LATERAL FLATTEN(input => pubs.\"cpc\") AS cpcs\n    WHERE\n        cpcs.value:\"first\" = TRUE\n) AS pubs\nJOIN (\n    SELECT\n        \"publication_number\" AS cited_publication_number,\n        cited_assignee_s.value:\"name\" AS cited_assignee\n    FROM\n        PATENTS.PATENTS.PUBLICATIONS\n    , LATERAL FLATTEN(input => \"assignee_harmonized\") AS cited_assignee_s\n) AS refs\n    ON pubs.cited_publication_number = refs.cited_publication_number\nJOIN\n    PATENTS.PATENTS.CPC_DEFINITION AS cpcdef\n    ON cpcdef.\"symbol\" = pubs.citing_cpc_subclass\nWHERE\n    refs.cited_assignee = 'DENSO CORP'\n    AND pubs.citing_assignee != 'DENSO CORP'\nGROUP BY\n    citing_assignee, cpcdef.\"titleFull\""}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: PATENTSVIEW\nQuestion: Retrieve the following information for U.S. patents filed between January 1, 2014, and February 1, 2014. The patent title and abstract. The publication date of the patent. The number of backward citations for each patent (i.e., the number of patents cited by the current patent before its filing date). The number of forward citations for each patent within the first 5 years of its publication (i.e., the number of patents that cited the current patent within 5 years after its publication). For each patent, ensure the forward citations are counted only for citations within 5 years after the publication date, and backward citations are counted for citations before the filing date.\n\nExternal Knowledge: forward_backward_citation.md"}, {"role": "assistant", "content": "SELECT\n    patent.\"title\",\n    patent.\"abstract\",\n    app.\"date\" AS publication_date,\n    filterData.\"bkwdCitations\",\n    filterData.\"fwrdCitations_5\"\nFROM\n    \"PATENTSVIEW\".\"PATENTSVIEW\".\"PATENT\" AS patent\nJOIN\n    \"PATENTSVIEW\".\"PATENTSVIEW\".\"APPLICATION\" AS app\n    ON app.\"patent_id\" = patent.\"id\"\nJOIN (\n    SELECT\n        DISTINCT cpc.\"patent_id\",\n        IFNULL(citation_5.\"bkwdCitations\", 0) AS \"bkwdCitations\",\n        IFNULL(citation_5.\"fwrdCitations_5\", 0) AS \"fwrdCitations_5\"\n    FROM\n        \"PATENTSVIEW\".\"PATENTSVIEW\".\"CPC_CURRENT\" AS cpc\n    LEFT JOIN (\n        SELECT\n            b.\"patent_id\",\n            b.\"bkwdCitations\",\n            f.\"fwrdCitations_5\"\n        FROM (\n            SELECT \n                cited.\"citation_id\" AS \"patent_id\",\n                IFNULL(COUNT(*), 0) AS \"fwrdCitations_5\"\n            FROM \n                \"PATENTSVIEW\".\"PATENTSVIEW\".\"USPATENTCITATION\" AS cited\n            JOIN\n                \"PATENTSVIEW\".\"PATENTSVIEW\".\"APPLICATION\" AS apps\n                ON cited.\"citation_id\" = apps.\"patent_id\"\n            WHERE\n                apps.\"country\" = 'US'\n                AND cited.\"date\" >= apps.\"date\"\n                AND TRY_CAST(cited.\"date\" AS DATE) <= DATEADD(YEAR, 5, TRY_CAST(apps.\"date\" AS DATE)) -- 5-year citation window\n            GROUP BY \n                cited.\"citation_id\"\n        ) AS f\n        JOIN (\n            SELECT \n                cited.\"patent_id\",\n                IFNULL(COUNT(*), 0) AS \"bkwdCitations\"\n            FROM \n                \"PATENTSVIEW\".\"PATENTSVIEW\".\"USPATENTCITATION\" AS cited\n            JOIN\n                \"PATENTSVIEW\".\"PATENTSVIEW\".\"APPLICATION\" AS apps\n                ON cited.\"patent_id\" = apps.\"patent_id\"\n            WHERE\n                apps.\"country\" = 'US'\n                AND cited.\"date\" < apps.\"date\" -- backward citation count\n            GROUP BY \n                cited.\"patent_id\"\n        ) AS b\n        ON b.\"patent_id\" = f.\"patent_id\"\n        WHERE\n            b.\"bkwdCitations\" IS NOT NULL\n            AND f.\"fwrdCitations_5\" IS NOT NULL\n    ) AS citation_5 \n    ON cpc.\"patent_id\" = citation_5.\"patent_id\"\n    WHERE \n        cpc.\"subsection_id\" IN ('C05', 'C06', 'C07', 'C08', 'C09', 'C10', 'C11', 'C12', 'C13')\n        OR cpc.\"group_id\" IN ('A01G', 'A01H', 'A61K', 'A61P', 'A61Q', 'B01F', 'B01J', 'B81B', 'B82B', 'B82Y', 'G01N', 'G16H')\n) AS filterData\nON app.\"patent_id\" = filterData.\"patent_id\"\nWHERE\n    TRY_CAST(app.\"date\" AS DATE) < '2014-02-01' \n    AND TRY_CAST(app.\"date\" AS DATE) >= '2014-01-01';"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: PATENTSVIEW\nQuestion: Retrieve U.S. patents with the number of forward citations within the first 3 years after the patent application date (i.e., patents citing the current patent within 3 years). Only include patents with both backward citations within 1 year before the application date and forward citations within 1 year after the application date. The query should focus on specific CPC categories, sort results by backward citations in descending order, and return the patent with the most backward citations, limiting to one result."}, {"role": "assistant", "content": "SELECT filterData.\"fwrdCitations_3\"\nFROM\n  PATENTSVIEW.PATENTSVIEW.APPLICATION AS app\nJOIN (\n  SELECT DISTINCT \n    cpc.\"patent_id\", \n    IFNULL(citation_3.\"bkwdCitations_3\", 0) AS \"bkwdCitations_3\", \n    IFNULL(citation_3.\"fwrdCitations_3\", 0) AS \"fwrdCitations_3\"\n  FROM\n    PATENTSVIEW.PATENTSVIEW.CPC_CURRENT AS cpc\n  LEFT JOIN (\n    SELECT \n      b.\"patent_id\", \n      b.\"bkwdCitations_3\", \n      f.\"fwrdCitations_3\"\n    FROM \n      (SELECT \n         cited.\"patent_id\",\n         COUNT(*) AS \"fwrdCitations_3\"\n       FROM \n         PATENTSVIEW.PATENTSVIEW.USPATENTCITATION AS cited\n       JOIN\n         PATENTSVIEW.PATENTSVIEW.APPLICATION AS apps\n         ON cited.\"patent_id\" = apps.\"patent_id\"\n       WHERE\n         apps.\"country\" = 'US'\n         AND cited.\"date\" >= apps.\"date\"\n         AND TRY_CAST(cited.\"date\" AS DATE) <= DATEADD(YEAR, 1, TRY_CAST(apps.\"date\" AS DATE)) -- Citation within 1 year\n       GROUP BY \n         cited.\"patent_id\"\n      ) AS f\n    JOIN (\n      SELECT \n        cited.\"patent_id\",\n        COUNT(*) AS \"bkwdCitations_3\"\n      FROM \n        PATENTSVIEW.PATENTSVIEW.USPATENTCITATION AS cited\n      JOIN\n        PATENTSVIEW.PATENTSVIEW.APPLICATION AS apps\n        ON cited.\"patent_id\" = apps.\"patent_id\"\n      WHERE\n        apps.\"country\" = 'US'\n        AND cited.\"date\" < apps.\"date\"\n        AND TRY_CAST(cited.\"date\" AS DATE) >= DATEADD(YEAR, -1, TRY_CAST(apps.\"date\" AS DATE)) -- Citation within 1 year before\n      GROUP BY \n        cited.\"patent_id\"\n    ) AS b\n    ON b.\"patent_id\" = f.\"patent_id\"\n    WHERE \n      b.\"bkwdCitations_3\" IS NOT NULL\n      AND f.\"fwrdCitations_3\" IS NOT NULL\n  ) AS citation_3 \n  ON cpc.\"patent_id\" = citation_3.\"patent_id\"\n) AS filterData\nON app.\"patent_id\" = filterData.\"patent_id\"\nORDER BY filterData.\"bkwdCitations_3\" DESC\nLIMIT 1;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: PATENTSVIEW\nQuestion: Retrieve the following information for U.S. patents: The patent ID, title, and application date. The number of backward citations within 1 month before the application date (i.e., patents that cited the current patent before its application). The number of forward citations within 1 month after the application date (i.e., patents that cited the current patent after its application). The abstract text of the patent. Only include patents that belong to specific CPC categories, such as subsection 'C05' or group 'A01G'. The query should filter patents to include only those that have at least one backward citation or one forward citation in the 1-month period specified. Sort the results by application date and return all matching records."}, {"role": "assistant", "content": "SELECT\n    app.\"patent_id\" AS \"patent_id\",\n    patent.\"title\",\n    app.\"date\" AS \"application_date\",\n    filterData.\"bkwdCitations_1\",\n    filterData.\"fwrdCitations_1\",\n    summary.\"text\" AS \"summary_text\"\nFROM\n    PATENTSVIEW.PATENTSVIEW.BRF_SUM_TEXT AS summary\nJOIN\n    PATENTSVIEW.PATENTSVIEW.PATENT AS patent\n    ON summary.\"patent_id\" = patent.\"id\"\nJOIN\n    PATENTSVIEW.PATENTSVIEW.APPLICATION AS app\n    ON app.\"patent_id\" = summary.\"patent_id\"\nJOIN (\n    SELECT DISTINCT\n        cpc.\"patent_id\",\n        IFNULL(citation_1.\"bkwdCitations_1\", 0) AS \"bkwdCitations_1\",\n        IFNULL(citation_1.\"fwrdCitations_1\", 0) AS \"fwrdCitations_1\"\n    FROM\n        PATENTSVIEW.PATENTSVIEW.CPC_CURRENT AS cpc\n    JOIN (\n        SELECT\n            b.\"patent_id\",\n            b.\"bkwdCitations_1\",\n            f.\"fwrdCitations_1\"\n        FROM (\n            SELECT\n                cited.\"patent_id\",\n                COUNT(*) AS \"fwrdCitations_1\"\n            FROM\n                PATENTSVIEW.PATENTSVIEW.USPATENTCITATION AS cited\n            JOIN\n                PATENTSVIEW.PATENTSVIEW.APPLICATION AS apps\n                ON cited.\"patent_id\" = apps.\"patent_id\"\n            WHERE\n                apps.\"country\" = 'US'\n                AND cited.\"date\" >= apps.\"date\"\n                AND TRY_CAST(cited.\"date\" AS DATE) <= DATEADD(MONTH, 1, TRY_CAST(apps.\"date\" AS DATE)) -- Citation within 1 month\n            GROUP BY\n                cited.\"patent_id\"\n        ) AS f\n        JOIN (\n            SELECT\n                cited.\"patent_id\",\n                COUNT(*) AS \"bkwdCitations_1\"\n            FROM\n                PATENTSVIEW.PATENTSVIEW.USPATENTCITATION AS cited\n            JOIN\n                PATENTSVIEW.PATENTSVIEW.APPLICATION AS apps\n                ON cited.\"patent_id\" = apps.\"patent_id\"\n            WHERE\n                apps.\"country\" = 'US'\n                AND cited.\"date\" < apps.\"date\"\n                AND TRY_CAST(cited.\"date\" AS DATE) >= DATEADD(MONTH, -1, TRY_CAST(apps.\"date\" AS DATE)) -- Citation within 1 month before\n            GROUP BY\n                cited.\"patent_id\"\n        ) AS b\n        ON b.\"patent_id\" = f.\"patent_id\"\n        WHERE\n            b.\"bkwdCitations_1\" IS NOT NULL\n            AND f.\"fwrdCitations_1\" IS NOT NULL\n            AND (b.\"bkwdCitations_1\" > 0 OR f.\"fwrdCitations_1\" > 0)\n    ) AS citation_1\n    ON cpc.\"patent_id\" = citation_1.\"patent_id\"\n    WHERE\n        cpc.\"subsection_id\" = 'C05'\n        OR cpc.\"group_id\" = 'A01G'\n) AS filterData\nON app.\"patent_id\" = filterData.\"patent_id\"\nORDER BY app.\"date\";"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: GITHUB_REPOS_DATE\nQuestion: Which primary programming languages, determined by the highest number of bytes in each repository, had at least 5 PullRequestEvents on January 18, 2023 across all their repositories?"}, {"role": "assistant", "content": "WITH\n  event_data AS (\n    SELECT\n      \"type\",\n      EXTRACT(YEAR FROM TO_TIMESTAMP(\"created_at\" / 1000000)) AS \"year\",\n      EXTRACT(QUARTER FROM TO_TIMESTAMP(\"created_at\" / 1000000)) AS \"quarter\",\n      REGEXP_REPLACE(\n        \"repo\"::variant:\"url\"::string,\n        'https:\\\\/\\\\/github\\\\.com\\\\/|https:\\\\/\\\\/api\\\\.github\\\\.com\\\\/repos\\\\/',\n        ''\n      ) AS \"name\"\n    FROM GITHUB_REPOS_DATE.DAY._20230118\n  ),\n\n  repo_languages AS (\n    SELECT\n      \"repo_name\" AS \"name\",\n      \"lang\"\n    FROM (\n      SELECT\n        \"repo_name\",\n        FIRST_VALUE(\"language\") OVER (\n          PARTITION BY \"repo_name\" ORDER BY \"bytes\" DESC\n        ) AS \"lang\"\n      FROM (\n        SELECT\n          \"repo_name\",\n          \"language\".value:\"name\" AS \"language\",\n          \"language\".value:\"bytes\" AS \"bytes\"\n        FROM GITHUB_REPOS_DATE.GITHUB_REPOS.LANGUAGES,\n        LATERAL FLATTEN(INPUT => \"language\") AS \"language\"\n      )\n    )\n    WHERE \"lang\" IS NOT NULL\n    GROUP BY \"repo_name\", \"lang\"\n  ),\n\n  joined_data AS (\n    SELECT\n      a.\"type\" AS \"type\",\n      b.\"lang\" AS \"language\",\n      a.\"year\" AS \"year\",\n      a.\"quarter\" AS \"quarter\"\n    FROM event_data a\n    JOIN repo_languages b\n      ON a.\"name\" = b.\"name\"\n  ),\n\n  count_data AS (\n    SELECT\n      \"language\",\n      \"year\",\n      \"quarter\",\n      \"type\",\n      COUNT(*) AS \"count\"\n    FROM joined_data\n    GROUP BY \"type\", \"language\", \"year\", \"quarter\"\n    ORDER BY \"year\", \"quarter\", \"count\" DESC\n  )\n\nSELECT\n  REPLACE(\"language\", '\"', '') AS \"language_name\",\n  \"count\"\nFROM count_data\nWHERE \"count\" >= 5\n  AND \"type\" = 'PullRequestEvent';"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: GITHUB_REPOS_DATE\nQuestion: Which repository with an approved license in `licenses.md` had the highest combined total of forks, issues, and watches in April 2022?"}, {"role": "assistant", "content": "WITH allowed_repos AS (\n    SELECT \n        \"repo_name\",\n        \"license\"\n    FROM \n        GITHUB_REPOS_DATE.GITHUB_REPOS.LICENSES\n    WHERE \n        \"license\" IN (\n            'gpl-3.0', 'artistic-2.0', 'isc', 'cc0-1.0', 'epl-1.0', 'gpl-2.0',\n            'mpl-2.0', 'lgpl-2.1', 'bsd-2-clause', 'apache-2.0', 'mit', 'lgpl-3.0'\n        )\n),\nwatch_counts AS (\n    SELECT \n        TRY_PARSE_JSON(\"repo\"):\"name\"::STRING AS \"repo\",\n        COUNT(DISTINCT TRY_PARSE_JSON(\"actor\"):\"login\"::STRING) AS \"watches\"\n    FROM \n        GITHUB_REPOS_DATE.MONTH._202204\n    WHERE \n        \"type\" = 'WatchEvent'\n    GROUP BY \n        TRY_PARSE_JSON(\"repo\"):\"name\"\n),\nissue_counts AS (\n    SELECT \n        TRY_PARSE_JSON(\"repo\"):\"name\"::STRING AS \"repo\",\n        COUNT(*) AS \"issue_events\"\n    FROM \n        GITHUB_REPOS_DATE.MONTH._202204\n    WHERE \n        \"type\" = 'IssuesEvent'\n    GROUP BY \n        TRY_PARSE_JSON(\"repo\"):\"name\"\n),\nfork_counts AS (\n    SELECT \n        TRY_PARSE_JSON(\"repo\"):\"name\"::STRING AS \"repo\",\n        COUNT(*) AS \"forks\"\n    FROM \n        GITHUB_REPOS_DATE.MONTH._202204\n    WHERE \n        \"type\" = 'ForkEvent'\n    GROUP BY \n        TRY_PARSE_JSON(\"repo\"):\"name\"\n)\nSELECT \n    ar.\"repo_name\"\nFROM \n    allowed_repos AS ar\nINNER JOIN \n    fork_counts AS fc ON ar.\"repo_name\" = fc.\"repo\"\nINNER JOIN \n    issue_counts AS ic ON ar.\"repo_name\" = ic.\"repo\"\nINNER JOIN \n    watch_counts AS wc ON ar.\"repo_name\" = wc.\"repo\"\nORDER BY \n    (fc.\"forks\" + ic.\"issue_events\" + wc.\"watches\") DESC\nLIMIT 1;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: GITHUB_REPOS\nQuestion: Can you analyze the joined data from github repos files and github_repos contents, focusing only on files ending with '.py' or '.r', then extract Python modules from 'import' or 'from ... import' lines and R libraries from 'library(...)' lines, count their occurrences, and finally list the results sorted by language and by the number of occurrences in descending order?"}, {"role": "assistant", "content": "WITH extracted_modules AS (\nSELECT \n    el.\"file_id\" AS \"file_id\", \n    el.\"repo_name\", \n    el.\"path\" AS \"path_\", \n    REPLACE(line.value, '\"', '') AS \"line_\",\n    CASE\n        WHEN ENDSWITH(el.\"path\", '.py') THEN 'python'\n        WHEN ENDSWITH(el.\"path\", '.r') THEN 'r'\n        ELSE NULL\n    END AS \"language\",\n    CASE\n        WHEN ENDSWITH(el.\"path\", '.py') THEN\n            ARRAY_CAT(\n                ARRAY_CONSTRUCT(REGEXP_SUBSTR(line.value, '\\\\bimport\\\\s+(\\\\w+)', 1, 1, 'e')),\n                ARRAY_CONSTRUCT(REGEXP_SUBSTR(line.value, '\\\\bfrom\\\\s+(\\\\w+)', 1, 1, 'e'))\n            )\n        WHEN ENDSWITH(el.\"path\", '.r') THEN\n            ARRAY_CONSTRUCT(REGEXP_SUBSTR(line.value, 'library\\\\s*\\\\(\\\\s*([^\\\\s)]+)\\\\s*\\\\)', 1, 1, 'e'))\n        ELSE ARRAY_CONSTRUCT()\n    END AS \"modules\"\nFROM (\n    SELECT\n        ct.\"id\" AS \"file_id\", \n        fl.\"repo_name\" AS \"repo_name\", \n        fl.\"path\", \n        SPLIT(REPLACE(ct.\"content\", '\\n', ' \\n'), '\\n') AS \"lines\"\n    FROM \n        GITHUB_REPOS_DATE.GITHUB_REPOS.SAMPLE_FILES AS fl\n    JOIN \n        GITHUB_REPOS_DATE.GITHUB_REPOS.SAMPLE_CONTENTS AS ct \n        ON fl.\"id\" = ct.\"id\"\n) AS el,\nLATERAL FLATTEN(input => el.\"lines\") AS line \nWHERE\n    (\n        ENDSWITH(\"path_\", '.py') \n        AND \n        (\n            \"line_\" LIKE 'import %' \n            OR \n            \"line_\" LIKE 'from %'\n        )\n    )\n    OR\n    (\n        ENDSWITH(\"path_\", '.r') \n        AND \n        \"line_\" LIKE 'library%('\n    )\n\n),\nmodule_counts AS (\n    SELECT \n        em.\"language\",\n        f.value::STRING AS \"module\",\n        COUNT(*) AS \"occurrence_count\"\n    FROM \n        extracted_modules AS em,\n        LATERAL FLATTEN(input => em.\"modules\") AS f\n    WHERE \n        em.\"modules\" IS NOT NULL\n        AND f.value IS NOT NULL\n    GROUP BY \n        em.\"language\", \n        f.value\n),\npython AS (\n    SELECT \n        \"language\",\n        \"module\",\n        \"occurrence_count\"\n    FROM \n        module_counts\n    WHERE \n        \"language\" = 'python'\n),\nrlanguage AS (\n    SELECT \n        \"language\",\n        \"module\",\n        \"occurrence_count\"\n    FROM \n        module_counts AS mc_inner\n    WHERE \n        \"language\" = 'r'\n)\nSELECT \n    *\nFROM \n    python\nUNION ALL\nSELECT \n    *\nFROM \n    rlanguage\nORDER BY \n    \"language\", \n    \"occurrence_count\" DESC;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: GITHUB_REPOS\nQuestion: Among all repositories that do not use any programming language whose name (case-insensitively) includes the substring \"python,\" what is the proportion of files whose paths include \"readme.md\" and whose contents contain the phrase \"Copyright (c)\"?"}, {"role": "assistant", "content": "WITH requests AS (\n    SELECT \n        D.\"id\",\n        D.\"content\",\n        E.\"repo_name\",\n        E.\"path\"\n    FROM \n        (\n            SELECT \n                \"id\",\n                \"content\"\n            FROM \n                GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS\n            GROUP BY \n                \"id\", \"content\"\n        ) AS D\n    INNER JOIN \n        (\n            SELECT \n                C.\"id\",\n                C.\"repo_name\",\n                C.\"path\"\n            FROM \n                (\n                    SELECT \n                        \"id\",\n                        \"repo_name\",\n                        \"path\"\n                    FROM \n                        GITHUB_REPOS.GITHUB_REPOS.SAMPLE_FILES\n                    WHERE \n                        LOWER(\"path\") LIKE '%readme.md'\n                    GROUP BY \n                        \"path\", \"id\", \"repo_name\"\n                ) AS C\n            INNER JOIN \n                (\n                    SELECT \n                        \"repo_name\",\n                        language_struct.value:\"name\"::STRING AS \"language_name\"\n                    FROM \n                        GITHUB_REPOS.GITHUB_REPOS.LANGUAGES,\n                        LATERAL FLATTEN(input => \"language\") AS language_struct\n                    WHERE \n                        LOWER(language_struct.value:\"name\"::STRING) NOT LIKE '%python%'\n                    GROUP BY \n                        \"language_name\", \"repo_name\"\n                ) AS F\n            ON \n                C.\"repo_name\" = F.\"repo_name\"\n        ) AS E\n    ON \n        D.\"id\" = E.\"id\"\n)\nSELECT \n    (SELECT COUNT(*) FROM requests WHERE \"content\" LIKE '%Copyright (c)%') / COUNT(*) AS \"proportion\"\nFROM \n    requests;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: GITHUB_REPOS\nQuestion: Retrieve all non-empty, non-commented lines from `README.md` files in GitHub repositories, excluding lines that are comments (either starting with `#` for Markdown or `//` for code comments). For each line, calculate how often each unique line appears across all repositories and return a comma-separated list of the programming languages used in each repository containing that line, sorted alphabetically, with the results ordered by the frequency of occurrence in descending order."}, {"role": "assistant", "content": "WITH content_extracted AS (\n    SELECT \n        \"D\".\"id\" AS \"id\",\n        \"repo_name\",\n        \"path\",\n        SPLIT(\"content\", '\\n') AS \"lines\",\n        \"language_name\"\n    FROM \n        (\n            SELECT \n                \"id\",\n                \"content\"\n            FROM \n                \"GITHUB_REPOS\".\"GITHUB_REPOS\".\"SAMPLE_CONTENTS\"\n        ) AS \"D\"\n    INNER JOIN \n        (\n            SELECT \n                \"id\",\n                \"C\".\"repo_name\" AS \"repo_name\",\n                \"path\",\n                \"language_name\"\n            FROM \n                (\n                    SELECT \n                        \"id\",\n                        \"repo_name\",\n                        \"path\"\n                    FROM \n                        \"GITHUB_REPOS\".\"GITHUB_REPOS\".\"SAMPLE_FILES\"\n                    WHERE \n                        LOWER(\"path\") LIKE '%readme.md'\n                ) AS \"C\"\n            INNER JOIN \n                (\n                    SELECT \n                        \"repo_name\",\n                        \"language_struct\".value:\"name\" AS \"language_name\"\n                    FROM \n                        (\n                            SELECT \n                                \"repo_name\", \n                                \"language\"\n                            FROM \n                                \"GITHUB_REPOS\".\"GITHUB_REPOS\".\"LANGUAGES\"\n                        )\n                    CROSS JOIN \n                        LATERAL FLATTEN(INPUT => \"language\") AS \"language_struct\"\n                ) AS \"F\"\n            ON \n                \"C\".\"repo_name\" = \"F\".\"repo_name\"\n        ) AS \"E\"\n    ON \n        \"E\".\"id\" = \"D\".\"id\"\n),\nnon_empty_lines AS (\n    SELECT \n        \"line\".value AS \"line_\",\n        \"language_name\"\n    FROM \n        content_extracted,\n        LATERAL FLATTEN(INPUT => \"lines\") AS \"line\"\n    WHERE \n        TRIM(\"line\".value) != ''\n        AND NOT STARTSWITH(TRIM(\"line\".value), '#')\n        AND NOT STARTSWITH(TRIM(\"line\".value), '//')\n),\naggregated_languages AS (\n    SELECT \n        \"line_\",\n        COUNT(*) AS \"frequency\",\n        ARRAY_AGG(\"language_name\") AS \"languages\"\n    FROM \n        non_empty_lines\n    GROUP BY \n        \"line_\"\n)\n\nSELECT \n    REGEXP_REPLACE(\"line_\", '^\"|\"$', '') AS \"line\",\n    \"frequency\",\n    ARRAY_TO_STRING(ARRAY_SORT(\"languages\"), ', ') AS \"languages_sorted\"\nFROM \n    aggregated_languages\nORDER BY \n    \"frequency\" DESC;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: GITHUB_REPOS_DATE\nQuestion: Using the 2017 GitHub Archive data for watch events, which three repositories that include at least one Python file (with a .py extension) smaller than 15,000 bytes and containing the substring \"def \" in its content have the highest total number of watch events for that year?"}, {"role": "assistant", "content": "WITH watched_repos AS (\n    SELECT\n        PARSE_JSON(\"repo\"):\"name\"::STRING AS \"repo\"\n    FROM \n        GITHUB_REPOS_DATE.MONTH._201701\n    WHERE\n        \"type\" = 'WatchEvent'\n    UNION ALL\n    SELECT\n        PARSE_JSON(\"repo\"):\"name\"::STRING AS \"repo\"\n    FROM \n        GITHUB_REPOS_DATE.MONTH._201702\n    WHERE\n        \"type\" = 'WatchEvent'\n    UNION ALL\n    SELECT\n        PARSE_JSON(\"repo\"):\"name\"::STRING AS \"repo\"\n    FROM \n        GITHUB_REPOS_DATE.MONTH._201703\n    WHERE\n        \"type\" = 'WatchEvent'\n    UNION ALL\n    SELECT\n        PARSE_JSON(\"repo\"):\"name\"::STRING AS \"repo\"\n    FROM \n        GITHUB_REPOS_DATE.MONTH._201704\n    WHERE\n        \"type\" = 'WatchEvent'\n    UNION ALL\n    SELECT\n        PARSE_JSON(\"repo\"):\"name\"::STRING AS \"repo\"\n    FROM \n        GITHUB_REPOS_DATE.MONTH._201705\n    WHERE\n        \"type\" = 'WatchEvent'\n    UNION ALL\n    SELECT\n        PARSE_JSON(\"repo\"):\"name\"::STRING AS \"repo\"\n    FROM \n        GITHUB_REPOS_DATE.MONTH._201706\n    WHERE\n        \"type\" = 'WatchEvent'\n    UNION ALL\n    SELECT\n        PARSE_JSON(\"repo\"):\"name\"::STRING AS \"repo\"\n    FROM \n        GITHUB_REPOS_DATE.MONTH._201707\n    WHERE\n        \"type\" = 'WatchEvent'\n    UNION ALL\n    SELECT\n        PARSE_JSON(\"repo\"):\"name\"::STRING AS \"repo\"\n    FROM \n        GITHUB_REPOS_DATE.MONTH._201708\n    WHERE\n        \"type\" = 'WatchEvent'\n    UNION ALL\n    SELECT\n        PARSE_JSON(\"repo\"):\"name\"::STRING AS \"repo\"\n    FROM \n        GITHUB_REPOS_DATE.MONTH._201709\n    WHERE\n        \"type\" = 'WatchEvent'\n    UNION ALL\n    SELECT\n        PARSE_JSON(\"repo\"):\"name\"::STRING AS \"repo\"\n    FROM \n        GITHUB_REPOS_DATE.MONTH._201710\n    WHERE\n        \"type\" = 'WatchEvent'\n    UNION ALL\n    SELECT\n        PARSE_JSON(\"repo\"):\"name\"::STRING AS \"repo\"\n    FROM \n        GITHUB_REPOS_DATE.MONTH._201711\n    WHERE\n        \"type\" = 'WatchEvent'\n    UNION ALL\n    SELECT\n        PARSE_JSON(\"repo\"):\"name\"::STRING AS \"repo\"\n    FROM \n        GITHUB_REPOS_DATE.MONTH._201712\n    WHERE\n        \"type\" = 'WatchEvent'\n),\n\nrepo_watch_counts AS (\n    SELECT\n        \"repo\",\n        COUNT(*) AS \"watch_count\"\n    FROM\n        watched_repos\n    GROUP BY\n        \"repo\"\n)\n\nSELECT\n    REPLACE(r.\"repo\", '\"', '') AS \"repo\",\n    r.\"watch_count\"\nFROM\n    GITHUB_REPOS_DATE.GITHUB_REPOS.SAMPLE_FILES AS f\nJOIN\n    GITHUB_REPOS_DATE.GITHUB_REPOS.SAMPLE_CONTENTS AS c\n    ON f.\"id\" = c.\"id\"\nJOIN \n    repo_watch_counts AS r\n    ON f.\"repo_name\" = r.\"repo\"\nWHERE\n    f.\"path\" LIKE '%.py' \n    AND c.\"size\" < 15000 \n    AND POSITION('def ' IN c.\"content\") > 0\nGROUP BY\n    r.\"repo\", r.\"watch_count\"\nORDER BY\n    r.\"watch_count\" DESC\nLIMIT \n    3;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: GITHUB_REPOS\nQuestion: How many commit messages are there in repositories that use the 'Shell' programming language and 'apache-2.0' license, where the length of the commit message is more than 5 characters but less than 10,000 characters, and the messages do not start with the word 'merge', 'update' or 'test'?"}, {"role": "assistant", "content": "SELECT\n  COUNT(commits_table.\"message\") AS \"num_messages\"\nFROM (\n  SELECT\n    L.\"repo_name\",\n    language_struct.value:\"name\"::STRING AS \"language_name\"\n  FROM\n    GITHUB_REPOS.GITHUB_REPOS.LANGUAGES AS L,\n    LATERAL FLATTEN(input => L.\"language\") AS language_struct\n) AS lang_table\nJOIN \n  GITHUB_REPOS.GITHUB_REPOS.LICENSES AS license_table\nON \n  license_table.\"repo_name\" = lang_table.\"repo_name\"\nJOIN (\n  SELECT\n    *\n  FROM\n    GITHUB_REPOS.GITHUB_REPOS.SAMPLE_COMMITS\n) AS commits_table\nON \n  commits_table.\"repo_name\" = lang_table.\"repo_name\"\nWHERE\n  license_table.\"license\" LIKE 'apache-2.0'\n  AND lang_table.\"language_name\" LIKE 'Shell'\n  AND LENGTH(commits_table.\"message\") > 5\n  AND LENGTH(commits_table.\"message\") < 10000\n  AND LOWER(commits_table.\"message\") NOT LIKE 'update%'\n  AND LOWER(commits_table.\"message\") NOT LIKE 'test%'\n  AND LOWER(commits_table.\"message\") NOT LIKE 'merge%';"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: GITHUB_REPOS\nQuestion: Extract and count the frequency of all package names listed in the require section of JSON-formatted content"}, {"role": "assistant", "content": "WITH json_files AS (\n  SELECT\n    c.\"id\",\n    TRY_PARSE_JSON(c.\"content\"):\"require\" AS \"dependencies\"\n  FROM\n    GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS c\n),\npackage_names AS (\n  SELECT\n    f.key AS \"package_name\"\n  FROM\n    json_files,\n    LATERAL FLATTEN(input => \"dependencies\") AS f\n)\nSELECT\n  \"package_name\",\n  COUNT(*) AS \"count\"\nFROM\n  package_names\nWHERE\n  \"package_name\" IS NOT NULL\nGROUP BY\n  \"package_name\"\nORDER BY\n  \"count\" DESC;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: GITHUB_REPOS\nQuestion: List the repository names and commit counts for the top two GitHub repositories with JavaScript as the primary language and the highest number of commits."}, {"role": "assistant", "content": "WITH repositories AS (\n    SELECT\n        t2.\"repo_name\",\n        t2.\"language\"\n    FROM (\n        SELECT\n            t1.\"repo_name\",\n            t1.\"language\",\n            RANK() OVER (PARTITION BY t1.\"repo_name\" ORDER BY t1.\"language_bytes\" DESC) AS \"rank\"\n        FROM (\n            SELECT\n                l.\"repo_name\",\n                lang.value:\"name\"::STRING AS \"language\",\n                lang.value:\"bytes\"::NUMBER AS \"language_bytes\"\n            FROM\n                GITHUB_REPOS.GITHUB_REPOS.LANGUAGES AS l,\n                LATERAL FLATTEN(input => l.\"language\") AS lang\n        ) AS t1\n    ) AS t2\n    WHERE t2.\"rank\" = 1\n),\npython_repo AS (\n    SELECT\n        \"repo_name\",\n        \"language\"\n    FROM\n        repositories\n    WHERE\n        \"language\" = 'JavaScript'\n)\nSELECT \n    sc.\"repo_name\", \n    COUNT(sc.\"commit\") AS \"num_commits\"\nFROM \n    GITHUB_REPOS.GITHUB_REPOS.SAMPLE_COMMITS AS sc\nINNER JOIN \n    python_repo \nON \n    python_repo.\"repo_name\" = sc.\"repo_name\"\nGROUP BY \n    sc.\"repo_name\"\nORDER BY \n    \"num_commits\" DESC\nLIMIT 2;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: GITHUB_REPOS\nQuestion: Could you please find the name of the repository that contains the most copied non-binary Swift file in the dataset, ensuring each file is uniquely identified by its ID?"}, {"role": "assistant", "content": "WITH selected_repos AS (\n  SELECT\n    f.\"id\",\n    f.\"repo_name\" AS \"repo_name\",\n    f.\"path\" AS \"path\"\n  FROM\n    GITHUB_REPOS.GITHUB_REPOS.SAMPLE_FILES AS f\n),\ndeduped_files AS (\n  SELECT\n    f.\"id\",\n    MIN(f.\"repo_name\") AS \"repo_name\",\n    MIN(f.\"path\") AS \"path\"\n  FROM\n    selected_repos AS f\n  GROUP BY\n    f.\"id\"\n)\nSELECT\n  f.\"repo_name\"\nFROM\n  deduped_files AS f\n  JOIN GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS AS c \n  ON f.\"id\" = c.\"id\"\nWHERE\n  NOT c.\"binary\"\n  AND f.\"path\" LIKE '%.swift'\nORDER BY c.\"copies\" DESC\nLIMIT 1;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: cms_data\nQuestion: What is the most prescribed medication in each state in 2014?"}, {"role": "assistant", "content": "SELECT\n  A.state,\n  drug_name,\n  total_claim_count\nFROM (\n  SELECT\n    generic_name AS drug_name,\n    nppes_provider_state AS state,\n    ROUND(SUM(total_claim_count)) AS total_claim_count,\n    ROUND(SUM(total_day_supply)) AS day_supply,\n    ROUND(SUM(total_drug_cost)) / 1e6 AS total_cost_millions\n  FROM\n    `bigquery-public-data.cms_medicare.part_d_prescriber_2014`\n  GROUP BY\n    state,\n    drug_name) A\nINNER JOIN (\n  SELECT\n    state,\n    MAX(total_claim_count) AS max_total_claim_count\n  FROM (\n    SELECT\n      nppes_provider_state AS state,\n      ROUND(SUM(total_claim_count)) AS total_claim_count\n    FROM\n      `bigquery-public-data.cms_medicare.part_d_prescriber_2014`\n    GROUP BY\n      state,\n      generic_name)\n  GROUP BY\n    state) B\nON\n  A.state = B.state\n  AND A.total_claim_count = B.max_total_claim_count;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: cms_data\nQuestion: Can you tell me which healthcare provider incurs the highest combined average costs for both outpatient and inpatient services in 2014?"}, {"role": "assistant", "content": "SELECT\n  Provider_Name\nFROM\n(\nSELECT\n  OP.provider_state AS State,\n  OP.provider_city AS City,\n  OP.provider_id AS Provider_ID,\n  OP.provider_name AS Provider_Name,\n  ROUND(OP.average_OP_cost) AS Average_OP_Cost,\n  ROUND(IP.average_IP_cost) AS Average_IP_Cost,\n  ROUND(OP.average_OP_cost + IP.average_IP_cost) AS Combined_Average_Cost\nFROM (\n  SELECT\n    provider_state,\n    provider_city,\n    provider_id,\n    provider_name,\n    SUM(average_total_payments*outpatient_services)/SUM(outpatient_services) AS average_OP_cost\n  FROM\n    `bigquery-public-data.cms_medicare.outpatient_charges_2014`\n  GROUP BY\n    provider_state,\n    provider_city,\n    provider_id,\n    provider_name ) AS OP\nINNER JOIN (\n  SELECT\n    provider_state,\n    provider_city,\n    provider_id,\n    provider_name,\n    SUM(average_medicare_payments*total_discharges)/SUM(total_discharges) AS average_IP_cost\n  FROM\n    `bigquery-public-data.cms_medicare.inpatient_charges_2014`\n  GROUP BY\n    provider_state,\n    provider_city,\n    provider_id,\n    provider_name ) AS IP\nON\n  OP.provider_id = IP.provider_id\n  AND OP.provider_state = IP.provider_state\n  AND OP.provider_city = IP.provider_city\n  AND OP.provider_name = IP.provider_name\nORDER BY\n  combined_average_cost DESC\nLIMIT\n  1\n);"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: cms_data\nQuestion: For the drug with the highest total number of prescriptions in New York State during 2014, could you list the top five states with the highest total claim counts for this drug? Please also include their total claim counts and total drug costs. "}, {"role": "assistant", "content": "WITH ny_top_drug AS (\n  SELECT\n    drug_name AS drug_name,\n    ROUND(SUM(total_claim_count)) AS total_claim_count\n  FROM\n    `bigquery-public-data.cms_medicare.part_d_prescriber_2014`\n  WHERE\n    nppes_provider_state = 'NY'\n  GROUP BY\n    drug_name\n  ORDER BY\n    total_claim_count DESC\n  LIMIT 1\n),\ntop_5_states AS (\n  SELECT\n    nppes_provider_state AS state,\n    SUM(total_claim_count) AS total_claim_count,\n    SUM(total_drug_cost) AS total_drug_cost\n  FROM\n    `bigquery-public-data.cms_medicare.part_d_prescriber_2014`\n  WHERE\n    drug_name = (SELECT drug_name FROM ny_top_drug)\n  GROUP BY\n    state\n  ORDER BY\n    total_claim_count DESC\n  LIMIT 5\n)\nSELECT\n  state,\n  total_claim_count,\n  total_drug_cost\nFROM\n  top_5_states;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: cms_data\nQuestion: Could you provide the percentage of participants for standard acne, atopic dermatitis, psoriasis, and vitiligo as defined by the International Classification of Diseases 10-CM (ICD-10-CM), including their subcategories? Please include all related concepts mapped to the standard ICD-10-CM codes (L70 for acne, L20 for atopic dermatitis, L40 for psoriasis, and L80 for vitiligo) by utilizing concept relationships, including descendant concepts. The percentage should be calculated based on the total number of participants, considering only the standard concepts and their related descendants."}, {"role": "assistant", "content": "WITH skin_condition_ICD_concept_ids AS (\n    SELECT\n        concept_id,\n        CASE concept_code\n            WHEN 'L70' THEN 'Acne'\n            WHEN 'L20' THEN 'Atopic dermatitis'\n            WHEN 'L40' THEN 'Psoriasis'\n            ELSE 'Vitiligo'\n        END AS skin_condition\n    FROM\n        `bigquery-public-data.cms_synthetic_patient_data_omop.concept`\n    WHERE\n        concept_code IN ('L70', 'L20', 'L40', 'L80')\n        AND vocabulary_id = 'ICD10CM'\n),\nstandard_concept_ids AS (\n    SELECT\n        concept_id\n    FROM\n        `bigquery-public-data.cms_synthetic_patient_data_omop.concept`\n    WHERE\n        standard_concept = 'S'\n),\nskin_condition_standard_concept_ids AS (\n    SELECT\n        s.skin_condition,\n        r.concept_id_2 AS concept_id\n    FROM\n        skin_condition_ICD_concept_ids s\n    JOIN\n        `bigquery-public-data.cms_synthetic_patient_data_omop.concept_relationship` r\n    ON\n        s.concept_id = r.concept_id_1\n    JOIN\n        standard_concept_ids sc\n    ON\n        sc.concept_id = r.concept_id_2\n    WHERE\n        r.relationship_id = 'Maps to'\n),\nall_skin_concept_ids AS (\n    SELECT DISTINCT\n        skin_condition,\n        concept_id\n    FROM\n        skin_condition_standard_concept_ids\n),\ndescendant_concept_ids AS (\n    SELECT\n        a.skin_condition,\n        ca.descendant_concept_id AS concept_id\n    FROM\n        all_skin_concept_ids a\n    JOIN\n        `bigquery-public-data.cms_synthetic_patient_data_omop.concept_ancestor` ca\n    ON\n        a.concept_id = ca.ancestor_concept_id\n),\nparticipants_with_condition AS (\n    SELECT\n        d.skin_condition,\n        COUNT(DISTINCT co.person_id) AS nb_of_participants_with_skin_condition\n    FROM\n        `bigquery-public-data.cms_synthetic_patient_data_omop.condition_occurrence` co\n    JOIN\n        descendant_concept_ids d\n    ON\n        co.condition_concept_id = d.concept_id\n    GROUP BY\n        d.skin_condition\n),\ntotal_participants AS (\n    SELECT\n        COUNT(DISTINCT person_id) AS nb_of_participants\n    FROM\n        `bigquery-public-data.cms_synthetic_patient_data_omop.person`\n)\nSELECT\n    p.skin_condition,\n    100 * p.nb_of_participants_with_skin_condition / t.nb_of_participants AS percentage_of_participants\nFROM\n    participants_with_condition p,\n    total_participants t"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: cms_data\nQuestion: Please tell me the percentage of participants not using quinapril and related medications(Quinapril RxCUI: 35208)."}, {"role": "assistant", "content": "WITH quinapril_concept AS (\n    SELECT concept_id\n    FROM `bigquery-public-data.cms_synthetic_patient_data_omop.concept`\n    WHERE concept_code = \"35208\" AND vocabulary_id = \"RxNorm\"\n),\nquinapril_related_medications AS (\n    SELECT DISTINCT descendant_concept_id AS concept_id\n    FROM `bigquery-public-data.cms_synthetic_patient_data_omop.concept_ancestor`\n    WHERE ancestor_concept_id IN (SELECT concept_id FROM quinapril_concept)\n),\nparticipants_with_quinapril AS (\n    SELECT COUNT(DISTINCT person_id) AS count\n    FROM `bigquery-public-data.cms_synthetic_patient_data_omop.drug_exposure`\n    WHERE drug_concept_id IN (SELECT concept_id FROM quinapril_related_medications)\n),\ntotal_participants AS (\n    SELECT COUNT(DISTINCT person_id) AS count\n    FROM `bigquery-public-data.cms_synthetic_patient_data_omop.person`\n)\nSELECT\n    100 - (100 * participants_with_quinapril.count / total_participants.count) AS without_quinapril\nFROM\n    participants_with_quinapril, total_participants"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: noaa_data\nQuestion: Can you provide the latitude of the final coordinates for the hurricane that traveled the second longest distance in the North Atlantic during 2020?\n\nExternal Knowledge: functions_st_distance.md"}, {"role": "assistant", "content": "WITH hurricane_geometry AS (\n  SELECT\n    * EXCEPT (longitude, latitude),\n    ST_GEOGPOINT(longitude, latitude) AS geom,\n    MAX(usa_wind) OVER (PARTITION BY sid) AS max_wnd_speed\n  FROM\n    `bigquery-public-data.noaa_hurricanes.hurricanes`\n  WHERE\n    season = '2020'\n    AND basin = 'NA'\n    AND name != 'NOT NAMED'\n),\ndist_between_points AS (\n  SELECT\n    sid,\n    name,\n    season,\n    iso_time,\n    max_wnd_speed,\n    geom,\n    ST_DISTANCE(geom, LAG(geom, 1) OVER (PARTITION BY sid ORDER BY iso_time ASC)) / 1000 AS dist\n  FROM\n    hurricane_geometry\n),\ntotal_distances AS (\n  SELECT\n    sid,\n    name,\n    season,\n    iso_time,\n    max_wnd_speed,\n    geom,\n    SUM(dist) OVER (PARTITION BY sid ORDER BY iso_time ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_distance,\n    SUM(dist) OVER (PARTITION BY sid) AS total_dist\n  FROM\n    dist_between_points\n),\nranked_hurricanes AS (\n  SELECT\n    *,\n    DENSE_RANK() OVER (ORDER BY total_dist DESC) AS dense_rank\n  FROM\n    total_distances\n)\n\nSELECT\n  ST_Y(geom)\nFROM\n  ranked_hurricanes\nWHERE\n  dense_rank = 2\nORDER BY\ncumulative_distance\nDESC\nLIMIT 1\n;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: noaa_data\nQuestion: Please show information about the hurricane with the third longest total travel distance in the North Atlantic during 2020, including its travel coordinates, the cumulative travel distance (in kilometers) at each point, and the maximum sustained wind speed at those times.\n\nExternal Knowledge: functions_st_distance.md"}, {"role": "assistant", "content": "WITH hurricane_geometry AS (\n  SELECT\n    * EXCEPT (longitude, latitude),\n    ST_GEOGPOINT(longitude, latitude) AS geom,\n  FROM\n    `bigquery-public-data.noaa_hurricanes.hurricanes`\n  WHERE\n    season = '2020'\n    AND basin = 'NA'\n    AND name != 'NOT NAMED'\n),\ndist_between_points AS (\n  SELECT\n    sid,\n    name,\n    season,\n    iso_time,\n    usa_wind,\n    geom,\n    ST_DISTANCE(geom, LAG(geom, 1) OVER (PARTITION BY sid ORDER BY iso_time ASC)) / 1000 AS dist\n  FROM\n    hurricane_geometry\n),\ntotal_distances AS (\n  SELECT\n    sid,\n    name,\n    season,\n    iso_time,\n    usa_wind,\n    geom,\n    SUM(dist) OVER (PARTITION BY sid ORDER BY iso_time ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_distance,\n    SUM(dist) OVER (PARTITION BY sid) AS total_dist\n  FROM\n    dist_between_points\n),\nranked_hurricanes AS (\n  SELECT\n    *,\n    DENSE_RANK() OVER (ORDER BY total_dist DESC) AS dense_rank\n  FROM\n    total_distances\n)\n\nSELECT\n  geom,cumulative_distance,usa_wind\nFROM\n  ranked_hurricanes\nWHERE\n  dense_rank = 3\nORDER BY\ncumulative_distance;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: noaa_data\nQuestion: Which 5 states had the most storm events from 1980 to 1995, considering only the top 1000 states with the highest event counts each year? Please use state abbreviations."}, {"role": "assistant", "content": "WITH s80 as\n  (SELECT state, COUNT(event_id) as num_events\n  FROM `bigquery-public-data.noaa_historic_severe_storms.storms_1980` \n  GROUP BY state \n  ORDER BY num_events DESC\n  LIMIT 1000),\ns81 as\n(SELECT state, COUNT(event_id) as num_events\n  FROM `bigquery-public-data.noaa_historic_severe_storms.storms_1981` \n  GROUP BY state \n  ORDER BY num_events DESC\n  LIMIT 1000),\ns82 as\n  (SELECT state, COUNT(event_id) as num_events\n  FROM `bigquery-public-data.noaa_historic_severe_storms.storms_1982` \n  GROUP BY state \n  ORDER BY num_events DESC\n  LIMIT 1000),\n\ns83 as\n  (SELECT state, COUNT(event_id) as num_events\n  FROM `bigquery-public-data.noaa_historic_severe_storms.storms_1983` \n  GROUP BY state \n  ORDER BY num_events DESC\n  LIMIT 1000),\n\ns84 as\n  (SELECT state, COUNT(event_id) as num_events\n  FROM `bigquery-public-data.noaa_historic_severe_storms.storms_1984` \n  GROUP BY state \n  ORDER BY num_events DESC\n  LIMIT 1000),\n\ns85 as\n  (SELECT state, COUNT(event_id) as num_events\n  FROM `bigquery-public-data.noaa_historic_severe_storms.storms_1985` \n  GROUP BY state \n  ORDER BY num_events DESC\n  LIMIT 1000),\n\ns86 as\n  (SELECT state, COUNT(event_id) as num_events\n  FROM `bigquery-public-data.noaa_historic_severe_storms.storms_1986` \n  GROUP BY state \n  ORDER BY num_events DESC\n  LIMIT 1000),\n\ns87 as\n  (SELECT state, COUNT(event_id) as num_events\n  FROM `bigquery-public-data.noaa_historic_severe_storms.storms_1987` \n  GROUP BY state \n  ORDER BY num_events DESC\n  LIMIT 1000),\n\ns88 as\n  (SELECT state, COUNT(event_id) as num_events\n  FROM `bigquery-public-data.noaa_historic_severe_storms.storms_1988` \n  GROUP BY state \n  ORDER BY num_events DESC\n  LIMIT 1000),\n\ns89 as\n  (SELECT state, COUNT(event_id) as num_events\n  FROM `bigquery-public-data.noaa_historic_severe_storms.storms_1989` \n  GROUP BY state \n  ORDER BY num_events DESC\n  LIMIT 1000),\n\ns90 as\n  (SELECT state, COUNT(event_id) as num_events\n  FROM `bigquery-public-data.noaa_historic_severe_storms.storms_1990` \n  GROUP BY state \n  ORDER BY num_events DESC\n  LIMIT 1000),\n\ns91 as\n  (SELECT state, COUNT(event_id) as num_events\n  FROM `bigquery-public-data.noaa_historic_severe_storms.storms_1991` \n  GROUP BY state \n  ORDER BY num_events DESC\n  LIMIT 1000),\ns92 as\n  (SELECT state, COUNT(event_id) as num_events\n  FROM `bigquery-public-data.noaa_historic_severe_storms.storms_1992` \n  GROUP BY state \n  ORDER BY num_events DESC\n  LIMIT 1000),\n\ns93 as\n  (SELECT state, COUNT(event_id) as num_events\n  FROM `bigquery-public-data.noaa_historic_severe_storms.storms_1993` \n  GROUP BY state \n  ORDER BY num_events DESC\n  LIMIT 1000),\n\ns94 as\n  (SELECT state, COUNT(event_id) as num_events\n  FROM `bigquery-public-data.noaa_historic_severe_storms.storms_1994` \n  GROUP BY state \n  ORDER BY num_events DESC\n  LIMIT 1000),\n\ns95 as\n  (SELECT state, COUNT(event_id) as num_events\n  FROM `bigquery-public-data.noaa_historic_severe_storms.storms_1995` \n  GROUP BY state \n  ORDER BY num_events DESC\n  LIMIT 1000)\n\nSELECT s80.state, \ns80.num_events + s81.num_events +  s82.num_events +  s83.num_events +  s84.num_events +  s85.num_events +  s86.num_events +  s87.num_events + s88.num_events +  s89.num_events +  s90.num_events + s91.num_events + s92.num_events + s93.num_events + s94.num_events + s95.num_events as total_events \nFROM s80 FULL JOIN s81 ON s80.state = s81.state\nFULL JOIN s82 ON s82.state = s81.state\nFULL JOIN s83 ON s83.state = s81.state\nFULL JOIN s84 ON s84.state = s81.state\nFULL JOIN s85 ON s85.state = s81.state\nFULL JOIN s86 ON s86.state = s81.state\nFULL JOIN s87 ON s87.state = s81.state\nFULL JOIN s88 ON s88.state = s81.state\nFULL JOIN s89 ON s89.state = s81.state\nFULL JOIN s90 ON s90.state = s81.state\nFULL JOIN s91 ON s91.state = s81.state \nFULL JOIN s92 ON s92.state = s81.state\nFULL JOIN s93 ON s93.state = s81.state\nFULL JOIN s94 ON s94.state = s81.state\nFULL JOIN s95 ON s95.state = s81.state\n\nORDER BY total_events DESC\nLIMIT 5;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: NOAA_DATA_PLUS\nQuestion: What are the top 5 zip codes of the areas in the United States that have experienced the most hail storm events in the past 10 years? Don't use data from hail reports table.\n\nExternal Knowledge: functions_st_within.md"}, {"role": "assistant", "content": "SELECT\n  CONCAT(\"city\", ', ', \"state_name\") AS \"city\",\n  \"zip_code\",\n  COUNT(\"event_id\") AS \"count_storms\"\nFROM (\n    SELECT *\n    FROM NOAA_DATA_PLUS.NOAA_HISTORIC_SEVERE_STORMS.STORMS_2014\n    UNION ALL\n    SELECT *\n    FROM NOAA_DATA_PLUS.NOAA_HISTORIC_SEVERE_STORMS.STORMS_2015\n    UNION ALL\n    SELECT *\n    FROM NOAA_DATA_PLUS.NOAA_HISTORIC_SEVERE_STORMS.STORMS_2016\n    UNION ALL\n    SELECT *\n    FROM NOAA_DATA_PLUS.NOAA_HISTORIC_SEVERE_STORMS.STORMS_2017\n    UNION ALL\n    SELECT *\n    FROM NOAA_DATA_PLUS.NOAA_HISTORIC_SEVERE_STORMS.STORMS_2018\n    UNION ALL\n    SELECT *\n    FROM NOAA_DATA_PLUS.NOAA_HISTORIC_SEVERE_STORMS.STORMS_2019\n    UNION ALL\n    SELECT *\n    FROM NOAA_DATA_PLUS.NOAA_HISTORIC_SEVERE_STORMS.STORMS_2020\n    UNION ALL\n    SELECT *\n    FROM NOAA_DATA_PLUS.NOAA_HISTORIC_SEVERE_STORMS.STORMS_2021\n    UNION ALL\n    SELECT *\n    FROM NOAA_DATA_PLUS.NOAA_HISTORIC_SEVERE_STORMS.STORMS_2022\n    UNION ALL\n    SELECT *\n    FROM NOAA_DATA_PLUS.NOAA_HISTORIC_SEVERE_STORMS.STORMS_2023\n    UNION ALL\n    SELECT *\n    FROM NOAA_DATA_PLUS.NOAA_HISTORIC_SEVERE_STORMS.STORMS_2024\n) AS storms\nJOIN NOAA_DATA_PLUS.GEO_US_BOUNDARIES.ZIP_CODES\n  ON ST_WITHIN(ST_GEOGFROMWKB(storms.\"event_point\"), ST_GEOGFROMWKB(\"zip_code_geom\"))\nWHERE\n   LOWER(storms.\"event_type\") = 'hail'\nGROUP BY\n  \"zip_code\", \n  \"city\", \n  \"state_name\"\nORDER BY\n  \"count_storms\" DESC\nLIMIT 5;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: noaa_data\nQuestion: Can you help me retrieve the average temperature, average wind speed, and precipitation for LaGuardia Airport in NYC on June 12 for each year from 2011 through 2020, specifically using the station ID 725030?"}, {"role": "assistant", "content": "SELECT\n  -- Create a timestamp from the date components.\n  TIMESTAMP(CONCAT(year,\"-\",mo,\"-\",da)) AS timestamp,\n  -- Replace numerical null values with actual null\n  AVG(IF (temp=9999.9,\n      null,\n      temp)) AS temperature,\n  AVG(IF (wdsp=\"999.9\",\n      null,\n      CAST(wdsp AS Float64))) AS wind_speed,\n  AVG(IF (prcp=99.99,\n      0,\n      prcp)) AS precipitation\nFROM\n  `bigquery-public-data.noaa_gsod.gsod20*`\nWHERE\n  CAST(YEAR AS INT64) > 2010\n  AND CAST(YEAR AS INT64) < 2021\n  AND CAST(MO AS INT64) = 6\n  AND CAST(DA AS INT64) = 12\n  AND stn = \"725030\" -- La Guardia\nGROUP BY\n  timestamp\nORDER BY\n  timestamp ASC;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: noaa_data\nQuestion: What are the top 3 months between 2010 and 2014 with the smallest sum of absolute differences between the average air temperature, wet bulb temperature, dew point temperature, and sea surface temperature, including respective years and sum of differences? Please present the year and month in numerical format."}, {"role": "assistant", "content": "WITH DailyAverages AS (\n    SELECT \n        year, month, day,\n        air_temperature,\n        wetbulb_temperature,\n        dewpoint_temperature,\n        sea_surface_temp\n    FROM \n        `bigquery-public-data.noaa_icoads.icoads_core_*`\n    WHERE\n        _TABLE_SUFFIX BETWEEN '2010' AND '2014'\n),\n\nMonthlyAverages AS (\n    SELECT \n        year,\n        month,\n        AVG(air_temperature) AS avg_air_temperature,\n        AVG(wetbulb_temperature) AS avg_wetbulb_temperature,\n        AVG(dewpoint_temperature) AS avg_dewpoint_temperature,\n        AVG(sea_surface_temp) AS avg_sea_surface_temp\n    FROM \n        DailyAverages\n    WHERE\n        air_temperature IS NOT NULL\n        AND wetbulb_temperature IS NOT NULL\n        AND dewpoint_temperature IS NOT NULL\n        AND sea_surface_temp IS NOT NULL\n    GROUP BY \n        year, month\n),\n\nDifferenceSums AS (\n    SELECT\n        year,\n        month,\n        (ABS(avg_air_temperature - avg_wetbulb_temperature) +\n        ABS(avg_air_temperature - avg_dewpoint_temperature) +\n        ABS(avg_air_temperature - avg_sea_surface_temp) +\n        ABS(avg_wetbulb_temperature - avg_dewpoint_temperature) +\n        ABS(avg_wetbulb_temperature - avg_sea_surface_temp) +\n        ABS(avg_dewpoint_temperature - avg_sea_surface_temp)) AS sum_of_differences\n    FROM \n        MonthlyAverages\n)\n\nSELECT\n    year,\n    month,\n    sum_of_differences\nFROM\n    DifferenceSums\nORDER BY\n    sum_of_differences ASC\nLIMIT 3;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: noaa_data\nQuestion: What are the latitude and longitude coordinates and dates between 2005 and 2015 with the top 5 highest daily average wind speeds, excluding records with missing wind speed values? Using data from tables start with prefix \"icoads_core\"."}, {"role": "assistant", "content": "WITH DailyAverages AS (\n    SELECT \n        year, month, day, latitude, longitude,\n        AVG(wind_speed) AS avg_wind_speed,\n    FROM \n        `bigquery-public-data.noaa_icoads.icoads_core_*`\n    WHERE\n        _TABLE_SUFFIX BETWEEN '2005' AND '2015'\n    GROUP BY \n        year, month, day, latitude, longitude\n)\nSELECT \n    year, month, day, latitude, longitude,\n    avg_wind_speed,\n\nFROM \n    DailyAverages\nWHERE\n    avg_wind_speed IS NOT NULL\n\nORDER BY avg_wind_speed DESC LIMIT 5"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: noaa_data\nQuestion: Which weather stations in Washington State recorded more than 150 rainy days in 2023 but fewer rainy days compared to 2022? Defining a \u201crainy day\u201d as one having precipitation greater than zero millimeters and not equal to 99.99. Only include stations with valid precipitation data."}, {"role": "assistant", "content": "WITH WashingtonStations2023 AS \n    (\n        SELECT \n            weather.stn AS station_id,\n            ANY_VALUE(station.name) AS name\n        FROM\n            `bigquery-public-data.noaa_gsod.stations` AS station\n        INNER JOIN\n            `bigquery-public-data.noaa_gsod.gsod2023` AS weather\n        ON\n            station.usaf = weather.stn\n        WHERE\n            station.state = 'WA' \n            AND \n            station.usaf != '999999'\n        GROUP BY\n            station_id\n    ),\nprcp2023 AS (\nSELECT\n    washington_stations.name,\n    (\n        SELECT \n            COUNT(*)\n        FROM\n            `bigquery-public-data.noaa_gsod.gsod2023` AS weather\n        WHERE\n            washington_stations.station_id = weather.stn\n            AND\n            prcp > 0\n            AND\n            prcp !=99.99\n    )\n    AS rainy_days\nFROM \n    WashingtonStations2023 AS washington_stations\nORDER BY\n    rainy_days DESC\n),\nWashingtonStations2022 AS \n    (\n        SELECT \n            weather.stn AS station_id,\n            ANY_VALUE(station.name) AS name\n        FROM\n            `bigquery-public-data.noaa_gsod.stations` AS station\n        INNER JOIN\n            `bigquery-public-data.noaa_gsod.gsod2022` AS weather\n        ON\n            station.usaf = weather.stn\n        WHERE\n            station.state = 'WA' \n            AND \n            station.usaf != '999999'\n        GROUP BY\n            station_id\n    ),\nprcp2022 AS (\nSELECT\n    washington_stations.name,\n    (\n        SELECT \n            COUNT(*)\n        FROM\n            `bigquery-public-data.noaa_gsod.gsod2022` AS weather\n        WHERE\n            washington_stations.station_id = weather.stn\n            AND\n            prcp > 0\n            AND\n            prcp != 99.99\n    )\n    AS rainy_days\nFROM \n    WashingtonStations2022 AS washington_stations\nORDER BY\n    rainy_days DESC\n)\n\nSELECT prcp2023.name\nFROM prcp2023\nJOIN prcp2022\non prcp2023.name = prcp2022.name\nWHERE prcp2023.rainy_days > 150\nAND prcp2023.rainy_days < prcp2022.rainy_days"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: NEW_YORK_CITIBIKE_1\nQuestion: Can you tell me which bike trip in New York City on July 15, 2015, started and ended in ZIP Code areas with the highest average temperature for that day, as recorded by the Central Park weather station (WBAN '94728')? If there's more than one trip that meets these criteria, I'd like to know about the one that starts in the smallest ZIP Code and ends in the largest ZIP Code. Please return the starting and ending ZIP Codes of this trip.\n\nExternal Knowledge: functions_st_within.md"}, {"role": "assistant", "content": "SELECT\n    \"ZIPSTART\".\"zip_code\" AS zip_code_start,\n    \"ZIPEND\".\"zip_code\" AS zip_code_end\nFROM  \n    \"NEW_YORK_CITIBIKE_1\".\"NEW_YORK_CITIBIKE\".\"CITIBIKE_TRIPS\" AS \"TRI\"\nINNER JOIN\n    \"NEW_YORK_CITIBIKE_1\".\"GEO_US_BOUNDARIES\".\"ZIP_CODES\" AS \"ZIPSTART\"\n    ON ST_WITHIN(\n        ST_POINT(\"TRI\".\"start_station_longitude\", \"TRI\".\"start_station_latitude\"),\n        ST_GEOGFROMWKB(\"ZIPSTART\".\"zip_code_geom\")\n    )\nINNER JOIN\n    \"NEW_YORK_CITIBIKE_1\".\"GEO_US_BOUNDARIES\".\"ZIP_CODES\" AS \"ZIPEND\"\n    ON ST_WITHIN(\n        ST_POINT(\"TRI\".\"end_station_longitude\", \"TRI\".\"end_station_latitude\"),\n        ST_GEOGFROMWKB(\"ZIPEND\".\"zip_code_geom\")\n    )\nINNER JOIN\n    \"NEW_YORK_CITIBIKE_1\".\"NOAA_GSOD\".\"GSOD2015\" AS \"WEA\"\n    ON TO_DATE(TO_CHAR(\"WEA\".\"year\") || LPAD(TO_CHAR(\"WEA\".\"mo\"), 2, '0') || LPAD(TO_CHAR(\"WEA\".\"da\"), 2, '0'), 'YYYYMMDD') = DATE_TRUNC('DAY', TO_TIMESTAMP_NTZ(TO_NUMBER(\"TRI\".\"starttime\") / 1000000))\nWHERE\n    \"WEA\".\"wban\" = '94728'\n    AND DATE_TRUNC('DAY', TO_TIMESTAMP_NTZ(TO_NUMBER(\"TRI\".\"starttime\") / 1000000)) = DATE '2015-07-15'\nORDER BY \n    \"WEA\".\"temp\" DESC, \"ZIPSTART\".\"zip_code\" ASC, \"ZIPEND\".\"zip_code\" DESC\nLIMIT 1;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: noaa_data\nQuestion: Can you calculate the difference in maximum temperature, minimum temperature, and average temperature between US and UK weather stations for each day in October 2023, using the date field, and excluding records with missing or invalid temperature values?"}, {"role": "assistant", "content": "with \n\nstations_selected as (\n  select\n    usaf,\n    wban,\n    country,\n    name\n  from\n    `bigquery-public-data.noaa_gsod.stations`\n  where\n    country in ('US', 'UK')\n),\n\ndata_filtered as (\n  select\n    gsod.*,\n    stations.country\n  from\n    `bigquery-public-data.noaa_gsod.gsod2023` gsod\n  join\n    stations_selected stations\n  on\n    gsod.stn = stations.usaf\n    and gsod.wban = stations.wban\n  where\n    date(gsod.date) between '2023-10-01' and '2023-10-31'\n    and gsod.temp != 9999.9\n),\n\n-- US Metrics\nus_metrics as (\n  select\n    date(date) as metric_date,\n    avg(temp) as avg_temp_us,\n    min(temp) as min_temp_us,\n    max(temp) as max_temp_us\n  from\n    data_filtered\n  where\n    country = 'US'\n  group by\n    metric_date\n),\n\n-- UK Metrics\nuk_metrics as (\n  select\n    date(date) as metric_date,\n    avg(temp) as avg_temp_uk,\n    min(temp) as min_temp_uk,\n    max(temp) as max_temp_uk\n  from\n    data_filtered\n  where\n    country = 'UK'\n  group by\n    metric_date\n),\n\n-- Temperature Differences\ntemp_differences as (\n  select\n    us.metric_date,\n    us.max_temp_us - uk.max_temp_uk as max_temp_diff,\n    us.min_temp_us - uk.min_temp_uk as min_temp_diff,\n    us.avg_temp_us - uk.avg_temp_uk as avg_temp_diff\n  from\n    us_metrics us\n  join\n    uk_metrics uk\n  on\n    us.metric_date = uk.metric_date\n)\n\nselect \n  metric_date, \n  max_temp_diff, \n  min_temp_diff, \n  avg_temp_diff\nfrom \n  temp_differences\norder by\n  metric_date;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: noaa_data\nQuestion: Provide the daily weather data for Rochester from January 1 to March 31, 2019, including temperature (in Celsius), precipitation (in centimeters), and wind speed (in meters per second). For each variable, calculate the 8-day moving average (including the current day and the previous 7 days). Also, calculate the difference between the moving average on each day and the moving averages for the previous 1 to 8 days (i.e., lag1 to lag8). The result should include: The daily values for temperature, precipitation, and wind speed.The 8-day moving averages for each variable. The differences between the moving averages for each of the previous 1 to 8 days (e.g., the difference between today's moving average and the moving average from 1 day ago, from 2 days ago, and so on). Round all values to one decimal place. The data should be ordered by date, starting from January 9, 2019."}, {"role": "assistant", "content": "WITH transrate AS (\n    SELECT\n        DATE(CAST(year AS INT64), CAST(mo AS INT64), CAST(da AS INT64)) AS observation_date\n        , ROUND((temp - 32.0) / 1.8, 1) AS temp_mean_c -- using Celsius instead of Fahrenheit\n        , ROUND(prcp * 2.54, 1) AS prcp_cm -- from inches to centimeters\n        , ROUND(CAST(wdsp AS FLOAT64) * 1.852 / 3.6, 1) AS wdsp_ms -- from knots to meters per second\n    FROM `bigquery-public-data.noaa_gsod.gsod*`\n    WHERE _TABLE_SUFFIX = \"2019\"\n        AND CAST(mo AS INT64) <= 3\n        AND stn in (SELECT usaf FROM `bigquery-public-data.noaa_gsod.stations` WHERE name = \"ROCHESTER\")\n),\n\nmoving_avg AS (\n    SELECT\n        observation_date\n        , temp_mean_c\n        , prcp_cm\n        , wdsp_ms\n        , AVG(temp_mean_c) OVER (ORDER BY observation_date ROWS 7 PRECEDING) AS temp_moving_avg\n        , AVG(prcp_cm) OVER (ORDER BY observation_date ROWS 7 PRECEDING) AS prcp_moving_avg\n        , AVG(wdsp_ms) OVER (ORDER BY observation_date ROWS 7 PRECEDING) AS wdsp_moving_avg\n    FROM transrate\n),\n\nlag_moving_avg AS (\n    SELECT\n        observation_date\n        , temp_mean_c\n        , prcp_cm\n        , wdsp_ms\n        , LAG(temp_moving_avg, 1) OVER (ORDER BY observation_date) AS lag1_temp_moving_avg\n        , LAG(prcp_moving_avg, 1) OVER (ORDER BY observation_date) AS lag1_prcp_moving_avg\n        , LAG(wdsp_moving_avg, 1) OVER (ORDER BY observation_date) AS lag1_wdsp_moving_avg\n\n        , LAG(temp_moving_avg, 2) OVER (ORDER BY observation_date) AS lag2_temp_moving_avg\n        , LAG(prcp_moving_avg, 2) OVER (ORDER BY observation_date) AS lag2_prcp_moving_avg\n        , LAG(wdsp_moving_avg, 2) OVER (ORDER BY observation_date) AS lag2_wdsp_moving_avg\n\n        , LAG(temp_moving_avg, 3) OVER (ORDER BY observation_date) AS lag3_temp_moving_avg\n        , LAG(prcp_moving_avg, 3) OVER (ORDER BY observation_date) AS lag3_prcp_moving_avg\n        , LAG(wdsp_moving_avg, 3) OVER (ORDER BY observation_date) AS lag3_wdsp_moving_avg\n\n        , LAG(temp_moving_avg, 4) OVER (ORDER BY observation_date) AS lag4_temp_moving_avg\n        , LAG(prcp_moving_avg, 4) OVER (ORDER BY observation_date) AS lag4_prcp_moving_avg\n        , LAG(wdsp_moving_avg, 4) OVER (ORDER BY observation_date) AS lag4_wdsp_moving_avg\n\n        , LAG(temp_moving_avg, 5) OVER (ORDER BY observation_date) AS lag5_temp_moving_avg\n        , LAG(prcp_moving_avg, 5) OVER (ORDER BY observation_date) AS lag5_prcp_moving_avg\n        , LAG(wdsp_moving_avg, 5) OVER (ORDER BY observation_date) AS lag5_wdsp_moving_avg\n\n        , LAG(temp_moving_avg, 6) OVER (ORDER BY observation_date) AS lag6_temp_moving_avg\n        , LAG(prcp_moving_avg, 6) OVER (ORDER BY observation_date) AS lag6_prcp_moving_avg\n        , LAG(wdsp_moving_avg, 6) OVER (ORDER BY observation_date) AS lag6_wdsp_moving_avg\n\n        , LAG(temp_moving_avg, 7) OVER (ORDER BY observation_date) AS lag7_temp_moving_avg\n        , LAG(prcp_moving_avg, 7) OVER (ORDER BY observation_date) AS lag7_prcp_moving_avg\n        , LAG(wdsp_moving_avg, 7) OVER (ORDER BY observation_date) AS lag7_wdsp_moving_avg\n\n        , LAG(temp_moving_avg, 8) OVER (ORDER BY observation_date) AS lag8_temp_moving_avg\n        , LAG(prcp_moving_avg, 8) OVER (ORDER BY observation_date) AS lag8_prcp_moving_avg\n        , LAG(wdsp_moving_avg, 8) OVER (ORDER BY observation_date) AS lag8_wdsp_moving_avg\n    FROM moving_avg\n)\n\nSELECT\n    observation_date\n    , temp_mean_c\n    , prcp_cm\n    , wdsp_ms\n\n    , ROUND(lag1_temp_moving_avg, 1) AS lag1_temp_moving_avg\n    , ROUND(lag1_prcp_moving_avg, 1) AS lag1_prcp_moving_avg\n    , ROUND(lag1_wdsp_moving_avg, 1) AS lag1_wdsp_moving_avg\n    \n    , ROUND(lag1_temp_moving_avg - lag2_temp_moving_avg, 1) AS diff2_temp_moving_avg\n    , ROUND(lag1_prcp_moving_avg - lag2_prcp_moving_avg, 1) AS diff2_prcp_moving_avg\n    , ROUND(lag1_wdsp_moving_avg - lag2_wdsp_moving_avg, 1) AS diff2_wdsp_moving_avg\n    , ROUND(lag2_temp_moving_avg, 1) AS lag2_temp_moving_avg\n    , ROUND(lag2_prcp_moving_avg, 1) AS lag2_prcp_moving_avg\n    , ROUND(lag2_wdsp_moving_avg, 1) AS lag2_wdsp_moving_avg\n    \n    , ROUND(lag2_temp_moving_avg - lag3_temp_moving_avg, 1) AS diff3_temp_moving_avg\n    , ROUND(lag2_prcp_moving_avg - lag3_prcp_moving_avg, 1) AS diff3_prcp_moving_avg\n    , ROUND(lag2_wdsp_moving_avg - lag3_wdsp_moving_avg, 1) AS diff3_wdsp_moving_avg\n    , ROUND(lag3_temp_moving_avg, 1) AS lag3_temp_moving_avg\n    , ROUND(lag3_prcp_moving_avg, 1) AS lag3_prcp_moving_avg\n    , ROUND(lag3_wdsp_moving_avg, 1) AS lag3_wdsp_moving_avg\n    \n    , ROUND(lag3_temp_moving_avg - lag4_temp_moving_avg, 1) AS diff4_temp_moving_avg\n    , ROUND(lag3_prcp_moving_avg - lag4_prcp_moving_avg, 1) AS diff4_prcp_moving_avg\n    , ROUND(lag3_wdsp_moving_avg - lag4_wdsp_moving_avg, 1) AS diff4_wdsp_moving_avg\n    , ROUND(lag4_temp_moving_avg, 1) AS lag4_temp_moving_avg\n    , ROUND(lag4_prcp_moving_avg, 1) AS lag4_prcp_moving_avg\n    , ROUND(lag4_wdsp_moving_avg, 1) AS lag4_wdsp_moving_avg\n    \n    , ROUND(lag4_temp_moving_avg - lag5_temp_moving_avg, 1) AS diff5_temp_moving_avg\n    , ROUND(lag4_prcp_moving_avg - lag5_prcp_moving_avg, 1) AS diff5_prcp_moving_avg\n    , ROUND(lag4_wdsp_moving_avg - lag5_wdsp_moving_avg, 1) AS diff5_wdsp_moving_avg\n    , ROUND(lag5_temp_moving_avg, 1) AS lag5_temp_moving_avg\n    , ROUND(lag5_prcp_moving_avg, 1) AS lag5_prcp_moving_avg\n    , ROUND(lag5_wdsp_moving_avg, 1) AS lag5_wdsp_moving_avg\n    \n    , ROUND(lag5_temp_moving_avg - lag6_temp_moving_avg, 1) AS diff6_temp_moving_avg\n    , ROUND(lag5_prcp_moving_avg - lag6_prcp_moving_avg, 1) AS diff6_prcp_moving_avg\n    , ROUND(lag5_wdsp_moving_avg - lag6_wdsp_moving_avg, 1) AS diff6_wdsp_moving_avg\n    , ROUND(lag6_temp_moving_avg, 1) AS lag6_temp_moving_avg\n    , ROUND(lag6_prcp_moving_avg, 1) AS lag6_prcp_moving_avg\n    , ROUND(lag6_wdsp_moving_avg, 1) AS lag6_wdsp_moving_avg\n    \n    , ROUND(lag6_temp_moving_avg - lag7_temp_moving_avg, 1) AS diff7_temp_moving_avg\n    , ROUND(lag6_prcp_moving_avg - lag7_prcp_moving_avg, 1) AS diff7_prcp_moving_avg\n    , ROUND(lag6_wdsp_moving_avg - lag7_wdsp_moving_avg, 1) AS diff7_wdsp_moving_avg\n    , ROUND(lag7_temp_moving_avg, 1) AS lag7_temp_moving_avg\n    , ROUND(lag7_prcp_moving_avg, 1) AS lag7_prcp_moving_avg\n    , ROUND(lag7_wdsp_moving_avg, 1) AS lag7_wdsp_moving_avg\n    \n    , ROUND(lag7_temp_moving_avg - lag8_temp_moving_avg, 1) AS diff8_temp_moving_avg\n    , ROUND(lag7_prcp_moving_avg - lag8_prcp_moving_avg, 1) AS diff8_prcp_moving_avg\n    , ROUND(lag7_wdsp_moving_avg - lag8_wdsp_moving_avg, 1) AS diff8_wdsp_moving_avg\n    , ROUND(lag8_temp_moving_avg, 1) AS lag8_temp_moving_avg\n    , ROUND(lag8_prcp_moving_avg, 1) AS lag8_prcp_moving_avg\n    , ROUND(lag8_wdsp_moving_avg, 1) AS lag8_wdsp_moving_avg\nFROM lag_moving_avg\nWHERE\n  lag8_temp_moving_avg IS NOT NULL\nORDER BY observation_date;\n-- all result rounded to 1 decimal place"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: noaa_gsod\nQuestion: What are the top 3 dates in October 2009 with the highest average temperature for station number 723758, in the format YYYY-MM-DD?"}, {"role": "assistant", "content": "WITH\n  # FIRST CAST EACH YEAR, MONTH, DATE TO STRINGS\n  T AS (\n    SELECT\n      *,\n      CAST(year AS STRING) AS year_string,\n      CAST(mo AS STRING) AS month_string,\n      CAST(da AS STRING) AS day_string\n    FROM\n      `bigquery-public-data.noaa_gsod.gsod2009`\n    WHERE\n      stn = \"723758\"\n  ),\n\n  # SECOND, CONCAT ALL THE STRINGS TOGETHER INTO ONE COLUMN\n  TT AS (\n    SELECT\n      *,\n      CONCAT(year_string, \"-\", month_string, \"-\", day_string) AS date_string\n    FROM\n      T\n  ),\n\n  # THIRD, CAST THE DATE STRING INTO A DATE FORMAT\n  TTT AS (\n    SELECT\n      *,\n      CAST(date_string AS DATE) AS date_date\n    FROM\n      TT\n  ),\n\n  # FOURTH, CALCULATE THE MEAN TEMPERATURE FOR EACH DATE\n  Temp_Avg AS (\n    SELECT\n      date_date,\n      AVG(temp) AS avg_temp\n    FROM\n      TTT\n    WHERE\n      date_date BETWEEN '2009-10-01' AND '2009-10-31'\n    GROUP BY\n      date_date\n  )\n\n# FINAL SELECTION OF TOP 3 DATES WITH HIGHEST MEAN TEMPERATURE\nSELECT\n  date_date AS dates\nFROM\n  Temp_Avg\nORDER BY\n  avg_temp DESC\nLIMIT 3;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: NEW_YORK_CITIBIKE_1\nQuestion: I want to analyze bike trips in New York City for 2014 by linking trip data with weather information to understand how weather conditions (temperature, wind speed, and precipitation) affect bike trips between neighborhoods. For each combination of starting and ending neighborhoods, I need the following: 1. Total number of bike trips between the neighborhoods. 2. Average trip duration in minutes (rounded to 1 decimal). 3. Average temperature at the start of the trip (rounded to 1 decimal). 4. Average wind speed at the start (in meters per second, rounded to 1 decimal). 5. Average precipitation at the start (in centimeters, rounded to 1 decimal). 6. The month with the most trips (e.g., `4` for April). The data should be grouped by the starting and ending neighborhoods, with:`zip_codes` in `geo_us_boundaries` used to map the bike trip locations based on latitude and longitude. `zip_codes` in `cyclistic` used to obtain the borough and neighborhood names. Using weather data from the Central Park station for the trip date, covering all trips in 2014.\n\nExternal Knowledge: functions_st_within.md"}, {"role": "assistant", "content": "WITH data AS (\n    SELECT\n        \"ZIPSTARTNAME\".\"borough\" AS \"borough_start\",\n        \"ZIPSTARTNAME\".\"neighborhood\" AS \"neighborhood_start\",\n        \"ZIPENDNAME\".\"borough\" AS \"borough_end\",\n        \"ZIPENDNAME\".\"neighborhood\" AS \"neighborhood_end\",\n        CAST(\"TRI\".\"tripduration\" / 60 AS NUMERIC) AS \"trip_minutes\",\n        \"WEA\".\"temp\" AS \"temperature\",\n        CAST(\"WEA\".\"wdsp\" AS NUMERIC) AS \"wind_speed\",\n        \"WEA\".\"prcp\" AS \"precipitation\",\n        EXTRACT(MONTH FROM DATE(\"TRI\".\"starttime\")) AS \"start_month\"\n    FROM\n        \"NEW_YORK_CITIBIKE_1\".\"NEW_YORK_CITIBIKE\".\"CITIBIKE_TRIPS\" AS \"TRI\"\n    INNER JOIN\n        \"NEW_YORK_CITIBIKE_1\".\"GEO_US_BOUNDARIES\".\"ZIP_CODES\" AS \"ZIPSTART\"\n        ON ST_WITHIN(\n            ST_POINT(\"TRI\".\"start_station_longitude\", \"TRI\".\"start_station_latitude\"),\n            ST_GEOGFROMWKB(\"ZIPSTART\".\"zip_code_geom\")\n        )\n    INNER JOIN\n        \"NEW_YORK_CITIBIKE_1\".\"GEO_US_BOUNDARIES\".\"ZIP_CODES\" AS \"ZIPEND\"\n        ON ST_WITHIN(\n            ST_POINT(\"TRI\".\"end_station_longitude\", \"TRI\".\"end_station_latitude\"),\n            ST_GEOGFROMWKB(\"ZIPEND\".\"zip_code_geom\")\n        )\n    INNER JOIN\n        \"NEW_YORK_CITIBIKE_1\".\"NOAA_GSOD\".\"GSOD2014\" AS \"WEA\"\n        ON TO_DATE(CONCAT(\"WEA\".\"year\", LPAD(\"WEA\".\"mo\", 2, '0'), LPAD(\"WEA\".\"da\", 2, '0')), 'YYYYMMDD') = DATE(\"TRI\".\"starttime\")\n    INNER JOIN\n        \"NEW_YORK_CITIBIKE_1\".\"CYCLISTIC\".\"ZIP_CODES\" AS \"ZIPSTARTNAME\"\n        ON \"ZIPSTART\".\"zip_code\" = CAST(\"ZIPSTARTNAME\".\"zip\" AS STRING)\n    INNER JOIN\n        \"NEW_YORK_CITIBIKE_1\".\"CYCLISTIC\".\"ZIP_CODES\" AS \"ZIPENDNAME\"\n        ON \"ZIPEND\".\"zip_code\" = CAST(\"ZIPENDNAME\".\"zip\" AS STRING)\n    WHERE\n        \"WEA\".\"wban\" = (\n            SELECT \"wban\" \n            FROM \"NEW_YORK_CITIBIKE_1\".\"NOAA_GSOD\".\"STATIONS\"\n            WHERE\n                \"state\" = 'NY'\n                AND LOWER(\"name\") LIKE LOWER('%New York Central Park%')\n            LIMIT 1\n        )\n        AND EXTRACT(YEAR FROM DATE(\"TRI\".\"starttime\")) = 2014\n),\nagg_data AS (\n    SELECT\n        \"borough_start\",\n        \"neighborhood_start\",\n        \"borough_end\",\n        \"neighborhood_end\",\n        COUNT(*) AS \"num_trips\",\n        ROUND(AVG(\"trip_minutes\"), 1) AS \"avg_trip_minutes\",\n        ROUND(AVG(\"temperature\"), 1) AS \"avg_temperature\",\n        ROUND(AVG(\"wind_speed\"), 1) AS \"avg_wind_speed\",\n        ROUND(AVG(\"precipitation\"), 1) AS \"avg_precipitation\"\n    FROM data\n    GROUP BY\n        \"borough_start\",\n        \"neighborhood_start\",\n        \"borough_end\",\n        \"neighborhood_end\"\n),\nmost_common_months AS (\n    SELECT\n        \"borough_start\",\n        \"neighborhood_start\",\n        \"borough_end\",\n        \"neighborhood_end\",\n        \"start_month\",\n        ROW_NUMBER() OVER (\n            PARTITION BY \"borough_start\", \"neighborhood_start\", \"borough_end\", \"neighborhood_end\" \n            ORDER BY COUNT(*) DESC\n        ) AS \"row_num\"\n    FROM data\n    GROUP BY\n        \"borough_start\",\n        \"neighborhood_start\",\n        \"borough_end\",\n        \"neighborhood_end\",\n        \"start_month\"\n)\n\nSELECT\n    a.*,\n    m.\"start_month\" AS \"most_common_month\"\nFROM\n    agg_data a\nJOIN\n    most_common_months m\n    ON a.\"borough_start\" = m.\"borough_start\" \n    AND a.\"neighborhood_start\" = m.\"neighborhood_start\" \n    AND a.\"borough_end\" = m.\"borough_end\" \n    AND a.\"neighborhood_end\" = m.\"neighborhood_end\" \n    AND m.\"row_num\" = 1\nORDER BY \n    a.\"neighborhood_start\", \n    a.\"neighborhood_end\";"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: NOAA_GLOBAL_FORECAST_SYSTEM\nQuestion: Can you provide a daily weather summary for July 2019 within a 5 km radius of latitude 26.75 and longitude 51.5? I need the maximum, minimum, and average temperatures; total precipitation; average cloud cover between 10 AM and 5 PM; total snowfall (when average temperature is below 32\u00b0F); and total rainfall (when average temperature is 32\u00b0F or above) for each forecast date. The data should correspond to forecasts created in July 2019 for the following day.\n\nExternal Knowledge: functions_st_within.md"}, {"role": "assistant", "content": "WITH daily_forecasts AS (\n    SELECT\n        \"TRI\".\"creation_time\",\n\n        CAST(DATEADD(hour, 1, TO_TIMESTAMP_NTZ(TO_NUMBER(\"forecast\".value:\"time\") / 1000000)) AS DATE) AS \"local_forecast_date\",\n        MAX(\n            CASE \n                WHEN \"forecast\".value:\"temperature_2m_above_ground\" IS NOT NULL \n                THEN \"forecast\".value:\"temperature_2m_above_ground\" \n                ELSE NULL \n            END\n        ) AS \"max_temp\",\n        MIN(\n            CASE \n                WHEN \"forecast\".value:\"temperature_2m_above_ground\" IS NOT NULL \n                THEN \"forecast\".value:\"temperature_2m_above_ground\" \n                ELSE NULL \n            END\n        ) AS \"min_temp\",\n        AVG(\n            CASE \n                WHEN \"forecast\".value:\"temperature_2m_above_ground\" IS NOT NULL \n                THEN \"forecast\".value:\"temperature_2m_above_ground\" \n                ELSE NULL \n            END\n        ) AS \"avg_temp\",\n        SUM(\n            CASE \n                WHEN \"forecast\".value:\"total_precipitation_surface\" IS NOT NULL \n                THEN \"forecast\".value:\"total_precipitation_surface\" \n                ELSE 0 \n            END\n        ) AS \"total_precipitation\",\n        AVG(\n            CASE \n                WHEN CAST(DATEADD(hour, 1, TO_TIMESTAMP_NTZ(TO_NUMBER(\"forecast\".value:\"time\") / 1000000)    ) AS TIME) BETWEEN '10:00:00' AND '17:00:00'\n                     AND \"forecast\".value:\"total_cloud_cover_entire_atmosphere\" IS NOT NULL \n                THEN \"forecast\".value:\"total_cloud_cover_entire_atmosphere\" \n                ELSE NULL \n            END\n        ) AS \"avg_cloud_cover\",\n        CASE\n            WHEN AVG(\"forecast\".value:\"temperature_2m_above_ground\") < 32 THEN \n                SUM(\n                    CASE \n                        WHEN \"forecast\".value:\"total_precipitation_surface\" IS NOT NULL \n                        THEN \"forecast\".value:\"total_precipitation_surface\" \n                        ELSE 0 \n                    END\n                )\n            ELSE 0\n        END AS \"total_snow\",\n        CASE\n            WHEN AVG(\"forecast\".value:\"temperature_2m_above_ground\") >= 32 THEN \n                SUM(\n                    CASE \n                        WHEN \"forecast\".value:\"total_precipitation_surface\" IS NOT NULL \n                        THEN \"forecast\".value:\"total_precipitation_surface\" \n                        ELSE 0 \n                    END\n                )\n            ELSE 0\n        END AS \"total_rain\"\n    FROM\n        \"NOAA_GLOBAL_FORECAST_SYSTEM\".\"NOAA_GLOBAL_FORECAST_SYSTEM\".\"NOAA_GFS0P25\" AS \"TRI\"\n    CROSS JOIN LATERAL FLATTEN(input => \"TRI\".\"forecast\") AS \"forecast\"\n    WHERE\n        TO_TIMESTAMP_NTZ(TO_NUMBER(\"TRI\".\"creation_time\") / 1000000) BETWEEN '2019-07-01' AND '2021-07-31'  \n        AND ST_DWITHIN(\n            ST_GEOGFROMWKB(\"TRI\".\"geography\"),\n            ST_POINT(26.75, 51.5),\n            5000\n        )\n        AND CAST(TO_TIMESTAMP_NTZ(TO_NUMBER(\"forecast\".value:\"time\") / 1000000) AS DATE) = DATEADD(day, 1, CAST( TO_TIMESTAMP_NTZ(TO_NUMBER(\"TRI\".\"creation_time\") / 1000000) AS DATE))\n    GROUP BY\n        \"TRI\".\"creation_time\",\n        \"local_forecast_date\"\n)\n\nSELECT\n    TO_TIMESTAMP_NTZ(TO_NUMBER(\"creation_time\") / 1000000),\n    \"local_forecast_date\" AS \"forecast_date\",\n    \"max_temp\",\n    \"min_temp\",\n    \"avg_temp\",\n    \"total_precipitation\",\n    \"avg_cloud_cover\",\n    \"total_snow\",\n    \"total_rain\"\nFROM\n    daily_forecasts\nORDER BY\n    \"creation_time\",\n    \"forecast_date\";"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: GEO_OPENSTREETMAP\nQuestion: What are the five longest types of highways within the multipolygon boundary of Denmark (as defined by Wikidata ID 'Q35') by total length, analyzed through planet features?\n\nExternal Knowledge: functions_st_dwithin.md"}, {"role": "assistant", "content": "WITH bounding_area AS (\n    SELECT \"geometry\" AS geometry\n    FROM GEO_OPENSTREETMAP.GEO_OPENSTREETMAP.PLANET_FEATURES,\n    LATERAL FLATTEN(INPUT => planet_features.\"all_tags\") AS \"tag\"\n    WHERE \"feature_type\" = 'multipolygons'\n      AND \"tag\".value:\"key\" = 'wikidata'\n      AND \"tag\".value:\"value\" = 'Q35'\n),\n\nhighway_info AS (\n    SELECT \n        SUM(ST_LENGTH(\n                ST_GEOGRAPHYFROMWKB(planet_features.\"geometry\")\n            )\n        ) AS highway_length,\n        \"tag\".value:\"value\" AS highway_type\n    FROM \n        GEO_OPENSTREETMAP.GEO_OPENSTREETMAP.PLANET_FEATURES AS planet_features,\n        bounding_area\n    CROSS JOIN LATERAL FLATTEN(INPUT => planet_features.\"all_tags\") AS \"tag\"\n    WHERE \"tag\".value:\"key\" = 'highway'\n    AND \"feature_type\" = 'lines'\n    AND ST_DWITHIN(\n        ST_GEOGFROMWKB(planet_features.\"geometry\"), \n        ST_GEOGFROMWKB(bounding_area.geometry),\n        0.0\n    ) \n    GROUP BY highway_type\n)\n\nSELECT \n  REPLACE(highway_type, '\"', '') AS highway_type\nFROM\n  highway_info\nORDER BY \n  highway_length DESC\nLIMIT 5;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: GEO_OPENSTREETMAP\nQuestion: Which OpenStreetMap ID from the planet features table corresponds to an administrative boundary, represented as multipolygons, whose total number of 'amenity'-tagged Points of Interest (POIs), as derived from the planet nodes table, is closest to the median count among all such boundaries?\n\nExternal Knowledge: functions_st_dwithin.md"}, {"role": "assistant", "content": "WITH bounding_area AS (\n    SELECT \n        \"osm_id\",\n        \"geometry\" AS geometry,\n        ST_AREA(ST_GEOGRAPHYFROMWKB(\"geometry\")) AS area\n    FROM GEO_OPENSTREETMAP.GEO_OPENSTREETMAP.PLANET_FEATURES,\n    LATERAL FLATTEN(INPUT => PLANET_FEATURES.\"all_tags\") AS \"tag\"\n    WHERE \n        \"feature_type\" = 'multipolygons'\n        AND \"tag\".value:\"key\" = 'boundary'\n        AND \"tag\".value:\"value\" = 'administrative'\n),\n\npoi AS (\n    SELECT \n        nodes.\"id\" AS poi_id,\n        nodes.\"geometry\" AS poi_geometry,\n        tags.value:\"value\" AS poitype\n    FROM GEO_OPENSTREETMAP.GEO_OPENSTREETMAP.PLANET_NODES AS nodes,\n    LATERAL FLATTEN(INPUT => nodes.\"all_tags\") AS tags\n    WHERE tags.value:\"key\" = 'amenity'\n),\n\npoi_counts AS (\n    SELECT\n        ba.\"osm_id\",\n        COUNT(poi.poi_id) AS total_pois\n    FROM bounding_area ba\n    JOIN poi\n    ON ST_DWITHIN(\n        ST_GEOGRAPHYFROMWKB(ba.geometry), \n        ST_GEOGRAPHYFROMWKB(poi.poi_geometry), \n        0.0\n    )\n    GROUP BY ba.\"osm_id\"\n),\n\nmedian_value AS (\n    SELECT \n        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY total_pois) AS median_pois\n    FROM poi_counts\n),\n\nclosest_to_median AS (\n    SELECT\n        \"osm_id\",\n        total_pois,\n        ABS(total_pois - (SELECT median_pois FROM median_value)) AS diff_from_median\n    FROM poi_counts\n)\n\nSELECT\n    \"osm_id\"\nFROM closest_to_median\nORDER BY diff_from_median\nLIMIT 1;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: CENSUS_BUREAU_ACS_2\nQuestion: Which are the top five states with the greatest average difference in median income between 2015 and 2018 at the ZIP code level, and what is the corresponding average number of vulnerable employees across wholesale trade, natural resources and construction, arts and entertainment, information, and retail trade industries in 2017 according to the ACS Five-Year Estimates and ZIP code boundaries data?\n\nExternal Knowledge: avg_vulnerable_weights.md"}, {"role": "assistant", "content": "WITH median_income_diff_by_zipcode AS (\n  WITH acs_2018 AS (\n    SELECT\n      \"geo_id\",\n      \"median_income\" AS \"median_income_2018\"\n    FROM\n      CENSUS_BUREAU_ACS_2.CENSUS_BUREAU_ACS.\"ZIP_CODES_2018_5YR\"\n  ),\n  acs_2015 AS (\n    SELECT\n      \"geo_id\",\n      \"median_income\" AS \"median_income_2015\"\n    FROM\n      CENSUS_BUREAU_ACS_2.CENSUS_BUREAU_ACS.\"ZIP_CODES_2015_5YR\"\n  ),\n  acs_diff AS (\n    SELECT\n      a18.\"geo_id\",\n      (a18.\"median_income_2018\" - a15.\"median_income_2015\") AS \"median_income_diff\"\n    FROM\n      acs_2018 a18\n    JOIN\n      acs_2015 a15 ON a18.\"geo_id\" = a15.\"geo_id\"\n  )\n  SELECT\n    \"geo_id\",\n    AVG(\"median_income_diff\") AS \"avg_median_income_diff\"\n  FROM\n    acs_diff\n  WHERE\n    \"median_income_diff\" IS NOT NULL\n  GROUP BY \"geo_id\"\n),\nbase_census AS (\n  SELECT\n    geo.\"state_name\",\n    AVG(i.\"avg_median_income_diff\") AS \"avg_median_income_diff\",\n    AVG(\n      \"employed_wholesale_trade\" * 0.38423645320197042 +\n      \"occupation_natural_resources_construction_maintenance\" * 0.48071410777129553 +\n      \"employed_arts_entertainment_recreation_accommodation_food\" * 0.89455676291236841 +\n      \"employed_information\" * 0.31315240083507306 +\n      \"employed_retail_trade\" * 0.51\n    ) AS \"avg_vulnerable\"\n  FROM\n    CENSUS_BUREAU_ACS_2.CENSUS_BUREAU_ACS.\"ZIP_CODES_2017_5YR\" AS census\n  JOIN\n    median_income_diff_by_zipcode i ON CAST(census.\"geo_id\" AS STRING) = i.\"geo_id\"\n  JOIN\n    CENSUS_BUREAU_ACS_2.GEO_US_BOUNDARIES.\"ZIP_CODES\" geo ON census.\"geo_id\" = geo.\"zip_code\"\n  GROUP BY geo.\"state_name\"\n)\n\nSELECT \n  \"state_name\",\n  \"avg_median_income_diff\",\n  \"avg_vulnerable\"\nFROM \n  base_census\nORDER BY \n  \"avg_median_income_diff\" DESC\nLIMIT 5;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: GEO_OPENSTREETMAP\nQuestion: Among all multipolygons located within the same geographic area as the multipolygon associated with Wikidata item Q191, but lacking a 'wikidata' tag themselves, which two rank highest by the number of points that lie within their boundaries, and what are their names?\n\nExternal Knowledge: functions_st_dwithin.md"}, {"role": "assistant", "content": "WITH bounding_area AS (\n    SELECT \"geometry\" AS geometry\n    FROM GEO_OPENSTREETMAP.GEO_OPENSTREETMAP.PLANET_FEATURES,\n    LATERAL FLATTEN(INPUT => \"all_tags\") AS tag\n    WHERE \"feature_type\" = 'multipolygons'\n      AND tag.value:\"key\" = 'wikidata'\n      AND tag.value:\"value\" = 'Q191'\n),\nbounding_area_features AS (\n    SELECT \n        planet_features.\"osm_id\", \n        planet_features.\"feature_type\", \n        planet_features.\"geometry\", \n        planet_features.\"all_tags\"\n    FROM GEO_OPENSTREETMAP.GEO_OPENSTREETMAP.PLANET_FEATURES AS planet_features,\n         bounding_area\n    WHERE ST_DWITHIN(\n        ST_GEOGFROMWKB(planet_features.\"geometry\"), \n        ST_GEOGFROMWKB(bounding_area.geometry), \n        0.0\n    )\n),\nosm_id_with_wikidata AS (\n    SELECT DISTINCT\n        baf.\"osm_id\"\n    FROM bounding_area_features AS baf,\n         LATERAL FLATTEN(INPUT => baf.\"all_tags\") AS tag\n    WHERE tag.value:\"key\" = 'wikidata'\n),\n\npolygons_wo_wikidata AS (\n    SELECT \n        baf.\"osm_id\",\n        tag.value:\"value\" as name,\n        baf.\"geometry\" as geometry\n    FROM bounding_area_features AS baf\n    LEFT JOIN osm_id_with_wikidata AS wd\n      ON baf.\"osm_id\" = wd.\"osm_id\",\n    LATERAL FLATTEN(INPUT => \"all_tags\") AS tag\n    WHERE wd.\"osm_id\" IS NULL\n    AND baf.\"osm_id\" IS NOT NULL\n    AND baf.\"feature_type\" = 'multipolygons'\n    AND tag.value:\"key\" = 'name'\n)\n\nSELECT \n    TRIM(pww.name) as name\nFROM bounding_area_features AS baf\nJOIN polygons_wo_wikidata AS pww\n    ON ST_DWITHIN(\n        ST_GEOGFROMWKB(baf.\"geometry\"), \n        ST_GEOGFROMWKB(pww.geometry), \n        0.0\n    )\nLEFT JOIN osm_id_with_wikidata AS wd\n    ON baf.\"osm_id\" = wd.\"osm_id\"\nWHERE wd.\"osm_id\" IS NOT NULL\n  AND baf.\"feature_type\" = 'points'\nGROUP BY pww.name\nORDER BY COUNT(baf.\"osm_id\") DESC\nLIMIT 2"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: GEO_OPENSTREETMAP_CENSUS_PLACES\nQuestion: Can you find the shortest distance between any two amenities (either a library, place of worship, or community center) located within Philadelphia, analyzed through pennsylvania table and planet features points?\n\nExternal Knowledge: functions_st_contains.md"}, {"role": "assistant", "content": "WITH philadelphia AS (\n    SELECT \n        * \n    FROM \n        GEO_OPENSTREETMAP_CENSUS_PLACES.GEO_US_CENSUS_PLACES.PLACES_PENNSYLVANIA\n    WHERE \n        \"place_name\" = 'Philadelphia'\n),\namenities AS (\n    SELECT \n        features.*, \n        tags.value:\"value\" AS amenity\n    FROM \n        GEO_OPENSTREETMAP_CENSUS_PLACES.GEO_OPENSTREETMAP.PLANET_FEATURES_POINTS AS features\n    CROSS JOIN philadelphia\n    -- Use FLATTEN on \"all_tags\" to get the tags and filter by \"key\"\n    , LATERAL FLATTEN(input => features.\"all_tags\") AS tags\n    WHERE \n        ST_CONTAINS(ST_GEOGFROMWKB(philadelphia.\"place_geom\"), ST_GEOGFROMWKB(features.\"geometry\"))\n    AND \n        tags.value:\"key\" = 'amenity' \n    AND \n        tags.value:\"value\" IN ('library', 'place_of_worship', 'community_centre')\n),\njoiin AS (\n    SELECT \n        a1.*, \n        a2.\"osm_id\" AS nearest_osm_id, \n        ST_DISTANCE(ST_GEOGFROMWKB(a1.\"geometry\"), ST_GEOGFROMWKB(a2.\"geometry\")) AS distance, \n        ROW_NUMBER() OVER (PARTITION BY a1.\"osm_id\" ORDER BY ST_DISTANCE(ST_GEOGFROMWKB(a1.\"geometry\"), ST_GEOGFROMWKB(a2.\"geometry\"))) AS row_num\n    FROM amenities a1\n    CROSS JOIN amenities a2\n    WHERE a1.\"osm_id\" < a2.\"osm_id\"\n    ORDER BY a1.\"osm_id\", distance\n) \nSELECT distance\nFROM joiin  \nWHERE row_num = 1\nORDER BY distance ASC\nLIMIT 1;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: GEO_OPENSTREETMAP_WORLDPOP\nQuestion: Based on the most recent 1km population grid data in Singapore before January 2023, using ST_CONVEXHULL to aggregate all population grid centroids into a bounding region and ST_INTERSECTS to identify hospitals from OpenStreetMap\u2019s planet layer (layer_code in (2110, 2120)) that fall within this region, then calculating the distance from each grid cell to its nearest hospital, what is the total population of the grid cell that is farthest from any hospital?\n\nExternal Knowledge: OpenStreetMap_data_in_layered_GIS_format.md"}, {"role": "assistant", "content": "WITH country_name AS (\n  SELECT 'Singapore' AS value\n),\n\nlast_updated AS (\n  SELECT\n    MAX(\"last_updated\") AS value\n  FROM GEO_OPENSTREETMAP_WORLDPOP.WORLDPOP.POPULATION_GRID_1KM AS pop\n    INNER JOIN country_name ON (pop.\"country_name\" = country_name.value)\n  WHERE \"last_updated\" < '2023-01-01'\n),\n\naggregated_population AS (\n  SELECT\n    \"geo_id\",\n    SUM(\"population\") AS sum_population,\n    ST_POINT(\"longitude_centroid\", \"latitude_centroid\") AS centr  -- \u8ba1\u7b97\u6bcf\u4e2a geo_id \u7684\u4e2d\u5fc3\u70b9\n  FROM\n    GEO_OPENSTREETMAP_WORLDPOP.WORLDPOP.POPULATION_GRID_1KM AS pop\n    INNER JOIN country_name ON (pop.\"country_name\" = country_name.value)\n    INNER JOIN last_updated ON (pop.\"last_updated\" = last_updated.value)\n  GROUP BY \"geo_id\", \"longitude_centroid\", \"latitude_centroid\"\n),\n\npopulation AS (\n  SELECT\n    SUM(sum_population) AS sum_population,\n    ST_ENVELOPE(ST_UNION_AGG(centr)) AS boundingbox  -- \u4f7f\u7528 ST_ENVELOPE \u6765\u4ee3\u66ff ST_CONVEXHULL\n  FROM aggregated_population\n),\n\nhospitals AS (\n  SELECT\n    layer.\"geometry\"\n  FROM\n    GEO_OPENSTREETMAP_WORLDPOP.GEO_OPENSTREETMAP.PLANET_LAYERS AS layer\n    INNER JOIN population ON ST_INTERSECTS(population.boundingbox, ST_GEOGFROMWKB(layer.\"geometry\"))\n  WHERE\n    layer.\"layer_code\" IN (2110, 2120)\n),\n\ndistances AS (\n  SELECT\n    pop.\"geo_id\",\n    pop.\"population\",\n    MIN(ST_DISTANCE(ST_GEOGFROMWKB(pop.\"geog\"), ST_GEOGFROMWKB(hospitals.\"geometry\"))) AS distance\n  FROM\n    GEO_OPENSTREETMAP_WORLDPOP.WORLDPOP.POPULATION_GRID_1KM AS pop\n    INNER JOIN country_name ON pop.\"country_name\" = country_name.value\n    INNER JOIN last_updated ON pop.\"last_updated\" = last_updated.value\n    CROSS JOIN hospitals\n  WHERE pop.\"population\" > 0\n  GROUP BY \"geo_id\", \"population\"\n)\n\nSELECT\n  SUM(pd.\"population\") AS population\nFROM\n  distances pd\nCROSS JOIN population p\nGROUP BY distance\nORDER BY distance DESC\nLIMIT 1;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: CRYPTO\nQuestion: Can you calculate the daily change in the market value of USDC tokens (address `0xa0b86991c6218b36c1d19d4a2e9eb0ce3606eb48`) for 2023, based on Ethereum transactions? The change should be computed from minting (input pattern `0x40c10f19%`) and burning (input pattern `0x42966c68%`) operations. For each transaction, minting should be positive and burning negative. Extract the relevant amount from the 'input' field as a hexadecimal, convert it to millions, express it in USD format. Group the results by date and order them in descending order.\n\nExternal Knowledge: Total_Market_Value_Change.md"}, {"role": "assistant", "content": "SELECT \n  TO_DATE(TO_TIMESTAMP_NTZ(\"block_timestamp\" / 1000000)) AS \"Date\",  -- \u5c06\u65f6\u95f4\u6233\u8f6c\u6362\u4e3a\u65e5\u671f\u683c\u5f0f\uff0c\u9664\u4ee51000000\n  TO_CHAR(SUM(\n      CASE\n          WHEN \"input\" LIKE '0x40c10f19%' THEN 1\n          ELSE -1\n      END * \n      CAST(CONCAT('0x', LTRIM(SUBSTRING(\"input\", \n                                       CASE \n                                           WHEN \"input\" LIKE '0x40c10f19%' THEN 75\n                                           ELSE 11\n                                       END, 64), '0')) AS FLOAT) / 1000000)\n  , '$999,999,999,999') AS \"\u0394 Total Market Value\"\nFROM \n  \"CRYPTO\".\"CRYPTO_ETHEREUM\".\"TRANSACTIONS\"\nWHERE \n  TO_DATE(TO_TIMESTAMP_NTZ(\"block_timestamp\" / 1000000)) BETWEEN '2023-01-01' AND '2023-12-31'\n  AND \"to_address\" = '0xa0b86991c6218b36c1d19d4a2e9eb0ce3606eb48'  -- USDC Token\n  AND (\"input\" LIKE '0x42966c68%' -- Burn\n       OR \"input\" LIKE '0x40c10f19%' -- Mint\n  )\nGROUP BY \n  TO_DATE(TO_TIMESTAMP_NTZ(\"block_timestamp\" / 1000000))\nORDER BY \n  \"Date\" DESC;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: CRYPTO\nQuestion: Which Ethereum address has the top 3 smallest positive balance from transactions involving the token at address \"0xa92a861fc11b99b24296af880011b47f9cafb5ab\"?"}, {"role": "assistant", "content": "WITH transaction_addresses AS (\n    SELECT \n        \"from_address\", \n        \"to_address\", \n        CAST(\"value\" AS NUMERIC) / 1000000 AS \"value\"\n    FROM \n        \"CRYPTO\".\"CRYPTO_ETHEREUM\".\"TOKEN_TRANSFERS\"\n    WHERE \n        \"token_address\" = '0xa92a861fc11b99b24296af880011b47f9cafb5ab'\n),\n\nout_addresses AS (\n    SELECT \n        \"from_address\", \n        SUM(-1 * \"value\") AS \"total_value\"\n    FROM \n        transaction_addresses\n    GROUP BY \n        \"from_address\"\n),\n\nin_addresses AS (\n    SELECT \n        \"to_address\", \n        SUM(\"value\") AS \"total_value\"\n    FROM \n        transaction_addresses\n    GROUP BY \n        \"to_address\"\n),\n\nall_addresses AS (\n    SELECT \n        \"from_address\" AS \"address\", \n        \"total_value\"\n    FROM \n        out_addresses\n\n    UNION ALL\n\n    SELECT \n        \"to_address\" AS \"address\", \n        \"total_value\"\n    FROM \n        in_addresses\n)\n\nSELECT \n    \"address\"\nFROM \n    all_addresses\nGROUP BY \n    \"address\"\nHAVING \n    SUM(\"total_value\") > 0\nORDER BY \n    SUM(\"total_value\") ASC\nLIMIT 3;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: CRYPTO\nQuestion: Can you pull the blockchain timestamp, block number, and transaction hash for the first five mint and burn events from Ethereum logs for the address '0x8ad599c3a0ff1de082011efddc58f1908eb6e6d8'? Please include mint events identified by the topic '0x7a53080ba414158be7ec69b987b5fb7d07dee101fe85488f0853ae16239d0bde' and burn events by '0x0c396cd989a39f4459b5fa1aed6a9a8dcdbc45908acfd67e028cd568da98982c', and order them by block timestamp from the oldest to the newest.\n\nExternal Knowledge: ethereum_logs_and_events_overview.md"}, {"role": "assistant", "content": "WITH parsed_burn_logs AS (\n  SELECT\n    logs.\"block_timestamp\" AS block_timestamp,\n    logs.\"block_number\" AS block_number,\n    logs.\"transaction_hash\" AS transaction_hash,\n    logs.\"log_index\" AS log_index,\n    PARSE_JSON(logs.\"data\") AS data,\n    logs.\"topics\"\n  FROM CRYPTO.CRYPTO_ETHEREUM.LOGS AS logs\n  WHERE logs.\"address\" = '0x8ad599c3a0ff1de082011efddc58f1908eb6e6d8'\n    AND logs.\"topics\"[0] = '0x0c396cd989a39f4459b5fa1aed6a9a8dcdbc45908acfd67e028cd568da98982c'\n),\nparsed_mint_logs AS (\n  SELECT\n    logs.\"block_timestamp\" AS block_timestamp,\n    logs.\"block_number\" AS block_number,\n    logs.\"transaction_hash\" AS transaction_hash,\n    logs.\"log_index\" AS log_index,\n    PARSE_JSON(logs.\"data\") AS data,\n    logs.\"topics\"\n  FROM CRYPTO.CRYPTO_ETHEREUM.LOGS AS logs\n  WHERE logs.\"address\" = '0x8ad599c3a0ff1de082011efddc58f1908eb6e6d8'\n    AND logs.\"topics\"[0] = '0x7a53080ba414158be7ec69b987b5fb7d07dee101fe85488f0853ae16239d0bde'\n)\n\nSELECT\n    block_timestamp,\n    block_number,\n    transaction_hash\nFROM parsed_mint_logs\n\nUNION ALL\n\nSELECT\n    block_timestamp,\n    block_number,\n    transaction_hash\nFROM parsed_burn_logs\n\nORDER BY block_timestamp\nLIMIT 5;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: CRYPTO\nQuestion: Calculate the annual differences in Bitcoin output value averages between two methods: Merged input/output records: Combine the inputs and outputs tables, filter to only output records, and calculate yearly averages. Transactions table: Directly use the output_value field from the transactions table for yearly averages. Show the difference (merged outputs average minus transactions average) only for years with data in both methods."}, {"role": "assistant", "content": "WITH all_transactions AS (\n    SELECT \n        TO_TIMESTAMP_NTZ(\"block_timestamp\" / 1000000) AS \"timestamp\",  -- \u5c06\u65f6\u95f4\u6233\u8f6c\u6362\u4e3a\u65e5\u671f\u65f6\u95f4\u683c\u5f0f\n        \"value\",\n        'input' AS \"type\"\n    FROM \n        \"CRYPTO\".\"CRYPTO_BITCOIN\".\"INPUTS\"\n    UNION ALL\n    SELECT \n        TO_TIMESTAMP_NTZ(\"block_timestamp\" / 1000000) AS \"timestamp\",  -- \u5c06\u65f6\u95f4\u6233\u8f6c\u6362\u4e3a\u65e5\u671f\u65f6\u95f4\u683c\u5f0f\n        \"value\",\n        'output' AS \"type\"\n    FROM \n        \"CRYPTO\".\"CRYPTO_BITCOIN\".\"OUTPUTS\"\n),\nfiltered_transactions AS (\n    SELECT\n        EXTRACT(YEAR FROM \"timestamp\") AS \"year\",\n        \"value\"\n    FROM \n        all_transactions\n    WHERE \"type\" = 'output'\n),\naverage_output_values AS (\n    SELECT\n        \"year\",\n        AVG(\"value\") AS \"avg_value\"\n    FROM \n        filtered_transactions\n    GROUP BY \"year\"\n),\naverage_transaction_values AS (\n    SELECT \n        EXTRACT(YEAR FROM TO_TIMESTAMP_NTZ(\"block_timestamp\" / 1000000)) AS \"year\",  -- \u540c\u6837\u8f6c\u6362\u65f6\u95f4\u6233\n        AVG(\"output_value\") AS \"avg_transaction_value\" \n    FROM \n        \"CRYPTO\".\"CRYPTO_BITCOIN\".\"TRANSACTIONS\" \n    GROUP BY \"year\" \n    ORDER BY \"year\"\n),\ncommon_years AS (\n    SELECT\n        ao.\"year\",\n        ao.\"avg_value\" AS \"avg_output_value\",\n        atv.\"avg_transaction_value\"\n    FROM\n        average_output_values ao\n    JOIN\n        average_transaction_values atv \n        ON ao.\"year\" = atv.\"year\"\n)\n\nSELECT\n    \"year\",\n    \"avg_transaction_value\" - \"avg_output_value\" AS \"difference\"\nFROM\n    common_years\nORDER BY\n    \"year\";"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: CRYPTO\nQuestion: Which month (e.g., 3 for March) in 2021 witnessed the highest percentage of Bitcoin transaction volume occurring in CoinJoin transactions (defined as transactions with >2 outputs, output value \u2264 input value, and having multiple equal-value outputs)? Also provide the percentage of all Bitcoin transactions that were CoinJoins, the percentage of UTXOs involved in CoinJoin transactions (average of input and output percentages), and the percentage of total Bitcoin volume that occurred in CoinJoin transactions for that month. Round all percentages to 1 decimal place."}, {"role": "assistant", "content": "WITH totals AS (\n    -- Aggregate monthly totals for Bitcoin txs, input/output UTXOs,\n    -- and input/output values (UTXO stands for Unspent Transaction Output)\n    SELECT\n        \"txs_tot\".\"block_timestamp_month\" AS tx_month,\n        COUNT(\"txs_tot\".\"hash\") AS tx_count,\n        SUM(\"txs_tot\".\"input_count\") AS tx_inputs,\n        SUM(\"txs_tot\".\"output_count\") AS tx_outputs,\n        SUM(\"txs_tot\".\"input_value\") / 100000000 AS tx_input_val,\n        SUM(\"txs_tot\".\"output_value\") / 100000000 AS tx_output_val\n    FROM CRYPTO.CRYPTO_BITCOIN.TRANSACTIONS AS \"txs_tot\"\n    WHERE \"txs_tot\".\"block_timestamp_month\" BETWEEN CAST('2021-01-01' AS DATE) AND CAST('2021-12-31' AS DATE)\n    GROUP BY \"txs_tot\".\"block_timestamp_month\"\n    ORDER BY \"txs_tot\".\"block_timestamp_month\" DESC\n),\ncoinjoinOuts AS (\n    -- Builds a table where each row represents an output of a \n    -- potential CoinJoin tx, defined as a tx that had more \n    -- than two outputs and had a total output value less than its\n    -- input value, per Adam Fiscor's description in this article: \n    SELECT \n        \"txs\".\"hash\",\n        \"txs\".\"block_number\",\n        \"txs\".\"block_timestamp_month\",\n        \"txs\".\"input_count\",\n        \"txs\".\"output_count\",\n        \"txs\".\"input_value\",\n        \"txs\".\"output_value\",\n        \"o\".value:\"value\" AS \"outputs_val\"\n    FROM CRYPTO.CRYPTO_BITCOIN.TRANSACTIONS AS \"txs\", \n         LATERAL FLATTEN(INPUT => \"txs\".\"outputs\") AS \"o\"\n    WHERE \"txs\".\"output_count\" > 2 \n      AND \"txs\".\"output_value\" <= \"txs\".\"input_value\"\n      AND \"txs\".\"block_timestamp_month\" BETWEEN CAST('2021-01-01' AS DATE) AND CAST('2021-12-31' AS DATE)\n    ORDER BY \"txs\".\"block_number\", \"txs\".\"hash\" DESC\n),\ncoinjoinTxs AS (\n    -- Builds a table of just the distinct CoinJoin tx hashes\n    -- which had more than one equal-value output.\n    SELECT \n        \"coinjoinouts\".\"hash\" AS \"cjhash\",\n        \"coinjoinouts\".\"outputs_val\" AS outputVal,\n        COUNT(*) AS cjOuts\n    FROM coinjoinOuts AS \"coinjoinouts\"\n    GROUP BY \"coinjoinouts\".\"hash\", \"coinjoinouts\".\"outputs_val\"\n    HAVING COUNT(*) > 1\n),\ncoinjoinsD AS (\n    -- Filter out all potential CoinJoin txs that did not have\n    -- more than one equal-value output. Do not list the\n    -- outputs themselves, only the distinct tx hashes and\n    -- their input/output counts and values.\n    SELECT DISTINCT \n        \"coinjoinouts\".\"hash\", \n        \"coinjoinouts\".\"block_number\", \n        \"coinjoinouts\".\"block_timestamp_month\",\n        \"coinjoinouts\".\"input_count\",\n        \"coinjoinouts\".\"output_count\",\n        \"coinjoinouts\".\"input_value\",\n        \"coinjoinouts\".\"output_value\"\n    FROM coinjoinOuts AS \"coinjoinouts\"\n    INNER JOIN coinjoinTxs AS \"coinjointxs\" \n        ON \"coinjoinouts\".\"hash\" = \"coinjointxs\".\"cjhash\"\n),\ncoinjoins AS (\n    -- Aggregate monthly totals for CoinJoin txs, input/output UTXOs,\n    -- and input/output values\n    SELECT \n        \"cjs\".\"block_timestamp_month\" AS cjs_month,\n        COUNT(\"cjs\".\"hash\") AS cjs_count,\n        SUM(\"cjs\".\"input_count\") AS cjs_inputs,\n        SUM(\"cjs\".\"output_count\") AS cjs_outputs,\n        SUM(\"cjs\".\"input_value\") / 100000000 AS cjs_input_val,\n        SUM(\"cjs\".\"output_value\") / 100000000 AS cjs_output_val\n    FROM coinjoinsD AS \"cjs\"\n    GROUP BY \"cjs\".\"block_timestamp_month\"\n    ORDER BY \"cjs\".\"block_timestamp_month\" DESC\n)\nSELECT EXTRACT(MONTH FROM tx_month) AS month,\n    -- Calculate resulting CoinJoin percentages:\n    -- tx_percent = percent of monthly Bitcoin txs that were CoinJoins\n    ROUND(coinjoins.cjs_count / totals.tx_count * 100, 1) AS tx_percent,\n    \n    -- utxos_percent = percent of monthly Bitcoin utxos that were CoinJoins\n    ROUND((coinjoins.cjs_inputs / totals.tx_inputs + coinjoins.cjs_outputs / totals.tx_outputs) / 2 * 100, 1) AS utxos_percent,\n    \n    -- value_percent = percent of monthly Bitcoin volume that took place\n    -- in CoinJoined transactions\n    ROUND(coinjoins.cjs_input_val / totals.tx_input_val * 100, 1) AS value_percent\nFROM totals\nINNER JOIN coinjoins\n    ON totals.tx_month = coinjoins.cjs_month\nORDER BY value_percent DESC\nLIMIT 1;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: CRYPTO\nQuestion: Using double-entry bookkeeping principles by treating transaction inputs as debits (negative values) and outputs as credits (positive values) for all Bitcoin Cash transactions between 2014-03-01 and 2014-04-01, how can we calculate the maximum and minimum final balances grouped by address type from these transactions?"}, {"role": "assistant", "content": "WITH double_entry_book AS (\n    -- debits\n    SELECT\n        ARRAY_TO_STRING(\"inputs\".value:addresses, ',') AS \"address\",  -- Use the correct JSON path notation\n        \"inputs\".value:type AS \"type\",\n        - \"inputs\".value:value AS \"value\"\n    FROM CRYPTO.CRYPTO_BITCOIN_CASH.TRANSACTIONS,\n         LATERAL FLATTEN(INPUT => \"inputs\") AS \"inputs\"\n    WHERE TO_TIMESTAMP(\"block_timestamp\" / 1000000) >= '2014-03-01' \n      AND TO_TIMESTAMP(\"block_timestamp\" / 1000000) < '2014-04-01'\n\n    UNION ALL\n \n    -- credits\n    SELECT\n        ARRAY_TO_STRING(\"outputs\".value:addresses, ',') AS \"address\",  -- Use the correct JSON path notation\n        \"outputs\".value:type AS \"type\",\n        \"outputs\".value:value AS \"value\"\n    FROM CRYPTO.CRYPTO_BITCOIN_CASH.TRANSACTIONS, \n         LATERAL FLATTEN(INPUT => \"outputs\") AS \"outputs\"\n    WHERE TO_TIMESTAMP(\"block_timestamp\" / 1000000) >= '2014-03-01' \n      AND TO_TIMESTAMP(\"block_timestamp\" / 1000000) < '2014-04-01'\n),\naddress_balances AS (\n    SELECT \n        \"address\",\n        \"type\",\n        SUM(\"value\") AS \"balance\"\n    FROM double_entry_book\n    GROUP BY \"address\", \"type\"\n),\nmax_min_balances AS (\n    SELECT\n        \"type\",\n        MAX(\"balance\") AS max_balance,\n        MIN(\"balance\") AS min_balance\n    FROM address_balances\n    GROUP BY \"type\"\n)\nSELECT\n    REPLACE(\"type\", '\"', '') AS \"type\",  -- Replace double quotes with nothing\n    max_balance,\n    min_balance\nFROM max_min_balances\nORDER BY \"type\";"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: CRYPTO\nQuestion: What were the maximum and minimum net balance changes for Ethereum Classic addresses on October 14, 2016? Calculate these by summing all transactions where addresses received funds (debits), sent funds (credits), and paid or received gas fees. Only include successful status transactions and exclude internal calls of types. For gas fees, consider both the fees paid by transaction senders and received by miners, calculated as multiplied by the gas price for both miners and senders"}, {"role": "assistant", "content": "WITH double_entry_book AS (\n    -- Debits\n    SELECT \n        \"to_address\" AS \"address\", \n        \"value\" AS \"value\"\n    FROM \n        CRYPTO.CRYPTO_ETHEREUM_CLASSIC.TRACES\n    WHERE \n        \"to_address\" IS NOT NULL\n        AND \"status\" = 1\n        AND (\"call_type\" NOT IN ('delegatecall', 'callcode', 'staticcall') OR \"call_type\" IS NULL)\n        AND TO_DATE(TO_TIMESTAMP(\"block_timestamp\" / 1000000)) = '2016-10-14'\n\n    UNION ALL\n    \n    -- Credits\n    SELECT \n        \"from_address\" AS \"address\", \n        - \"value\" AS \"value\"\n    FROM \n        CRYPTO.CRYPTO_ETHEREUM_CLASSIC.TRACES\n    WHERE \n        \"from_address\" IS NOT NULL\n        AND \"status\" = 1\n        AND (\"call_type\" NOT IN ('delegatecall', 'callcode', 'staticcall') OR \"call_type\" IS NULL)\n        AND TO_DATE(TO_TIMESTAMP(\"block_timestamp\" / 1000000)) = '2016-10-14'\n\n    UNION ALL\n\n    -- Transaction Fees Debits\n    SELECT \n        \"miner\" AS \"address\", \n        SUM(CAST(\"receipt_gas_used\" AS NUMERIC) * CAST(\"gas_price\" AS NUMERIC)) AS \"value\"\n    FROM \n        CRYPTO.CRYPTO_ETHEREUM_CLASSIC.TRANSACTIONS AS \"transactions\"\n    JOIN \n        CRYPTO.CRYPTO_ETHEREUM_CLASSIC.BLOCKS AS \"blocks\" \n        ON \"blocks\".\"number\" = \"transactions\".\"block_number\"\n    WHERE \n        TO_DATE(TO_TIMESTAMP(\"block_timestamp\" / 1000000)) = '2016-10-14'\n    GROUP BY \n        \"blocks\".\"miner\"\n\n    UNION ALL\n    \n    -- Transaction Fees Credits\n    SELECT \n        \"from_address\" AS \"address\", \n        -(CAST(\"receipt_gas_used\" AS NUMERIC) * CAST(\"gas_price\" AS NUMERIC)) AS \"value\"\n    FROM \n        CRYPTO.CRYPTO_ETHEREUM_CLASSIC.TRANSACTIONS\n    WHERE \n        TO_DATE(TO_TIMESTAMP(\"block_timestamp\" / 1000000)) = '2016-10-14'\n),\nnet_changes AS (\n    SELECT \n        \"address\",\n        SUM(\"value\") AS \"net_change\"\n    FROM \n        double_entry_book\n    GROUP BY \n        \"address\"\n)\nSELECT \n    MAX(\"net_change\") AS \"max_net_change\",\n    MIN(\"net_change\") AS \"min_net_change\"\nFROM\n    net_changes;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: HUMAN_GENOME_VARIANTS\nQuestion: About the refined human genetic variations collected in phase 3 on 2015-02-20, I want to know the minimum and maximum start positions as well as the proportions of these two respectively for reference bases 'AT' and 'TA'."}, {"role": "assistant", "content": "WITH A AS (\n    SELECT\n        \"reference_bases\",\n        \"start_position\"\n    FROM\n        \"HUMAN_GENOME_VARIANTS\".\"HUMAN_GENOME_VARIANTS\".\"_1000_GENOMES_PHASE_3_OPTIMIZED_SCHEMA_VARIANTS_20150220\"\n    WHERE\n        \"reference_bases\" IN ('AT', 'TA')\n),\nB AS (\n    SELECT\n        \"reference_bases\",\n        MIN(\"start_position\") AS \"min_start_position\",\n        MAX(\"start_position\") AS \"max_start_position\",\n        COUNT(1) AS \"total_count\"\n    FROM\n        A\n    GROUP BY\n        \"reference_bases\"\n),\nmin_counts AS (\n    SELECT\n        A.\"reference_bases\",  -- Explicitly referencing the column from table A\n        A.\"start_position\" AS \"min_start_position\",\n        COUNT(1) AS \"min_count\"\n    FROM\n        A\n    INNER JOIN B \n        ON A.\"reference_bases\" = B.\"reference_bases\"\n    WHERE\n        A.\"start_position\" = B.\"min_start_position\"\n    GROUP BY\n        A.\"reference_bases\", A.\"start_position\"\n),\nmax_counts AS (\n    SELECT\n        A.\"reference_bases\",  -- Explicitly referencing the column from table A\n        A.\"start_position\" AS \"max_start_position\",\n        COUNT(1) AS \"max_count\"\n    FROM\n        A\n    INNER JOIN B\n        ON A.\"reference_bases\" = B.\"reference_bases\"\n    WHERE\n        A.\"start_position\" = B.\"max_start_position\"\n    GROUP BY\n        A.\"reference_bases\", A.\"start_position\"\n)\nSELECT\n    B.\"reference_bases\",  -- Explicitly referencing the column from table B\n    B.\"min_start_position\",\n    CAST(min_counts.\"min_count\" AS FLOAT) / B.\"total_count\" AS \"min_position_ratio\",\n    B.\"max_start_position\",\n    CAST(max_counts.\"max_count\" AS FLOAT) / B.\"total_count\" AS \"max_position_ratio\"\nFROM\n    B\nLEFT JOIN\n    min_counts ON B.\"reference_bases\" = min_counts.\"reference_bases\" AND B.\"min_start_position\" = min_counts.\"min_start_position\"\nLEFT JOIN\n    max_counts ON B.\"reference_bases\" = max_counts.\"reference_bases\" AND B.\"max_start_position\" = max_counts.\"max_start_position\"\nORDER BY\n    B.\"reference_bases\";"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: ETHEREUM_BLOCKCHAIN\nQuestion: Calculate the average balance (in quadrillions, 10^15) of the top 10 Ethereum addresses by net balance, including incoming and outgoing transfers from traces (only successful transactions and excluding call types like delegatecall, callcode, and staticcall), miner rewards (sum of gas fees per block), and sender gas fee deductions. Exclude null addresses and round the result to two decimal places."}, {"role": "assistant", "content": "WITH double_entry_book AS (\n  -- Debits\n  SELECT \n    \"to_address\" AS \"address\",\n    \"value\" AS \"value\"\n  FROM \"ETHEREUM_BLOCKCHAIN\".\"ETHEREUM_BLOCKCHAIN\".\"TRACES\"\n  WHERE \"to_address\" IS NOT NULL\n    AND \"status\" = 1\n    AND (\"call_type\" NOT IN ('delegatecall', 'callcode', 'staticcall') OR \"call_type\" IS NULL)\n  \n  UNION ALL\n  \n  -- Credits\n  SELECT \n    \"from_address\" AS \"address\",\n    - \"value\" AS \"value\"\n  FROM \"ETHEREUM_BLOCKCHAIN\".\"ETHEREUM_BLOCKCHAIN\".\"TRACES\"\n  WHERE \"from_address\" IS NOT NULL\n    AND \"status\" = 1\n    AND (\"call_type\" NOT IN ('delegatecall', 'callcode', 'staticcall') OR \"call_type\" IS NULL)\n  \n  UNION ALL\n  \n  -- Transaction fees debits\n  SELECT \n    \"miner\" AS \"address\",\n    SUM(CAST(\"receipt_gas_used\" AS NUMBER) * CAST(\"gas_price\" AS NUMBER)) AS \"value\"\n  FROM \"ETHEREUM_BLOCKCHAIN\".\"ETHEREUM_BLOCKCHAIN\".\"TRANSACTIONS\" AS \"transactions\"\n  JOIN \"ETHEREUM_BLOCKCHAIN\".\"ETHEREUM_BLOCKCHAIN\".\"BLOCKS\" AS \"blocks\"\n    ON \"blocks\".\"number\" = \"transactions\".\"block_number\"\n  GROUP BY \"blocks\".\"miner\"\n  \n  UNION ALL\n  \n  -- Transaction fees credits\n  SELECT \n    \"from_address\" AS \"address\",\n    -(CAST(\"receipt_gas_used\" AS NUMBER) * CAST(\"gas_price\" AS NUMBER)) AS \"value\"\n  FROM \"ETHEREUM_BLOCKCHAIN\".\"ETHEREUM_BLOCKCHAIN\".\"TRANSACTIONS\"\n),\ntop_10_balances AS (\n  SELECT\n    \"address\",\n    SUM(\"value\") AS \"balance\"\n  FROM double_entry_book\n  GROUP BY \"address\"\n  ORDER BY \"balance\" DESC\n  LIMIT 10\n)\nSELECT \n    ROUND(AVG(\"balance\") / 1e15, 2) AS \"average_balance_trillion\"\nFROM top_10_balances;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: ETHEREUM_BLOCKCHAIN\nQuestion: Calculate the total circulating supply of 'BNB' tokens (in units divided by 10^18) by summing balances of all non-zero addresses, where each address\u2019s balance equals its total received BNB minus sent BNB. Exclude transactions involving the zero address (0x000...) for both senders and receivers."}, {"role": "assistant", "content": "WITH tokenInfo AS (\n    SELECT \"address\"\n    FROM \"ETHEREUM_BLOCKCHAIN\".\"ETHEREUM_BLOCKCHAIN\".\"TOKENS\"\n    WHERE \"name\" = 'BNB'\n),\n\nreceivedTx AS (\n    SELECT \"tx\".\"to_address\" AS \"addr\", \n           \"tokens\".\"name\" AS \"name\", \n           SUM(CAST(\"tx\".\"value\" AS FLOAT) / POWER(10, 18)) AS \"amount_received\"\n    FROM \"ETHEREUM_BLOCKCHAIN\".\"ETHEREUM_BLOCKCHAIN\".\"TOKEN_TRANSFERS\" AS \"tx\"\n    JOIN tokenInfo ON \"tx\".\"token_address\" = tokenInfo.\"address\"\n    JOIN \"ETHEREUM_BLOCKCHAIN\".\"ETHEREUM_BLOCKCHAIN\".\"TOKENS\" AS \"tokens\"\n      ON \"tx\".\"token_address\" = \"tokens\".\"address\"\n    WHERE \"tx\".\"to_address\" <> '0x0000000000000000000000000000000000000000'\n    GROUP BY \"tx\".\"to_address\", \"tokens\".\"name\"\n),\n\nsentTx AS (\n    SELECT \"tx\".\"from_address\" AS \"addr\", \n           \"tokens\".\"name\" AS \"name\", \n           SUM(CAST(\"tx\".\"value\" AS FLOAT) / POWER(10, 18)) AS \"amount_sent\"\n    FROM \"ETHEREUM_BLOCKCHAIN\".\"ETHEREUM_BLOCKCHAIN\".\"TOKEN_TRANSFERS\" AS \"tx\"\n    JOIN tokenInfo ON \"tx\".\"token_address\" = tokenInfo.\"address\"\n    JOIN \"ETHEREUM_BLOCKCHAIN\".\"ETHEREUM_BLOCKCHAIN\".\"TOKENS\" AS \"tokens\"\n      ON \"tx\".\"token_address\" = \"tokens\".\"address\"\n    WHERE \"tx\".\"from_address\" <> '0x0000000000000000000000000000000000000000'\n    GROUP BY \"tx\".\"from_address\", \"tokens\".\"name\"\n),\n\nwalletBalances AS (\n    SELECT r.\"addr\",\n           COALESCE(SUM(r.\"amount_received\"), 0) - COALESCE(SUM(s.\"amount_sent\"), 0) AS \"balance\"\n    FROM receivedTx AS r\n    LEFT JOIN sentTx AS s\n      ON r.\"addr\" = s.\"addr\"\n    GROUP BY r.\"addr\"\n)\n\nSELECT \n    SUM(\"balance\") AS \"circulating_supply\"\nFROM walletBalances;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: ghcn_d\nQuestion: I want to know the IDs, names of weather stations within a 50 km straight-line distance from the center of Chicago (41.8319\u00b0N, 87.6847\u00b0W)"}, {"role": "assistant", "content": "WITH params AS (\n  SELECT ST_GeogPoint(-87.6847, 41.8319) AS center,\n         50 AS maxdist_km\n),\ndistance_from_center AS (\n  SELECT\n    id,\n    name,\n    state,\n    ST_GeogPoint(longitude, latitude) AS loc,\n    ST_Distance(ST_GeogPoint(longitude, latitude), params.center) AS dist_meters\n  FROM\n    `bigquery-public-data.ghcn_d.ghcnd_stations`,\n    params\n  WHERE ST_DWithin(ST_GeogPoint(longitude, latitude), params.center, params.maxdist_km*1000)\n),\nnearest_stations AS (\n  SELECT \n    *, \n    RANK() OVER (ORDER BY dist_meters ASC) AS rank\n  FROM \n    distance_from_center\n),\nnearest_nstations AS (\n  SELECT \n    station.* \n  FROM \n    nearest_stations AS station, params\n)\nSELECT * from nearest_nstations"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: ghcn_d\nQuestion: Could you provide the highest recorded precipitation, minimum temperature, and maximum temperature from the last 15 days of each year from 2013 to 2016 at weather station USW00094846? Ensure each value represents the peak measurement for that period, with precipitation in millimeters and temperatures in degrees Celsius, using only validated data (non-null values and no quality flags)"}, {"role": "assistant", "content": "WITH data AS (\n  SELECT\n    EXTRACT(YEAR FROM wx.date) AS year,\n    MAX(IF(wx.element = 'PRCP', wx.value/10, NULL)) AS max_prcp,\n    MAX(IF(wx.element = 'TMIN', wx.value/10, NULL)) AS max_tmin,\n    MAX(IF(wx.element = 'TMAX', wx.value/10, NULL)) AS max_tmax\n  FROM\n    `bigquery-public-data.ghcn_d.ghcnd_2013` AS wx\n  WHERE\n    wx.id = 'USW00094846' AND\n    wx.qflag IS NULL AND\n    wx.value IS NOT NULL AND\n    DATE_DIFF(DATE('2013-12-31'), wx.date, DAY) < 15\n  GROUP BY\n    year\n\n  UNION ALL\n\n  SELECT\n    EXTRACT(YEAR FROM wx.date) AS year,\n    MAX(IF(wx.element = 'PRCP', wx.value/10, NULL)) AS max_prcp,\n    MAX(IF(wx.element = 'TMIN', wx.value/10, NULL)) AS max_tmin,\n    MAX(IF(wx.element = 'TMAX', wx.value/10, NULL)) AS max_tmax\n  FROM\n    `bigquery-public-data.ghcn_d.ghcnd_2014` AS wx\n  WHERE\n    wx.id = 'USW00094846' AND\n    wx.qflag IS NULL AND\n    wx.value IS NOT NULL AND\n    DATE_DIFF(DATE('2014-12-31'), wx.date, DAY) < 15\n  GROUP BY\n    year\n\n  UNION ALL\n\n  SELECT\n    EXTRACT(YEAR FROM wx.date) AS year,\n    MAX(IF(wx.element = 'PRCP', wx.value/10, NULL)) AS max_prcp,\n    MAX(IF(wx.element = 'TMIN', wx.value/10, NULL)) AS max_tmin,\n    MAX(IF(wx.element = 'TMAX', wx.value/10, NULL)) AS max_tmax\n  FROM\n    `bigquery-public-data.ghcn_d.ghcnd_2015` AS wx\n  WHERE\n    wx.id = 'USW00094846' AND\n    wx.qflag IS NULL AND\n    wx.value IS NOT NULL AND\n    DATE_DIFF(DATE('2015-12-31'), wx.date, DAY) < 15\n  GROUP BY\n    year\n\n  UNION ALL\n\n  SELECT\n    EXTRACT(YEAR FROM wx.date) AS year,\n    MAX(IF(wx.element = 'PRCP', wx.value/10, NULL)) AS max_prcp,\n    MAX(IF(wx.element = 'TMIN', wx.value/10, NULL)) AS max_tmin,\n    MAX(IF(wx.element = 'TMAX', wx.value/10, NULL)) AS max_tmax\n  FROM\n    `bigquery-public-data.ghcn_d.ghcnd_2016` AS wx\n  WHERE\n    wx.id = 'USW00094846' AND\n    wx.qflag IS NULL AND\n    wx.value IS NOT NULL AND\n    DATE_DIFF(DATE('2016-12-31'), wx.date, DAY) < 15\n  GROUP BY\n    year\n)\n\nSELECT\n  year,\n  MAX(max_prcp) AS annual_max_prcp,\n  MAX(max_tmin) AS annual_max_tmin,\n  MAX(max_tmax) AS annual_max_tmax\nFROM data\nGROUP BY year\nORDER BY year ASC;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: new_york\nQuestion: Calculate the change in the number of living trees of each fall color in New York City from 1995 to 2015 by computing, for each tree species, the difference between the number of trees not marked as dead in 1995 and the number of trees alive in 2015, matching species by the uppercase form of their scientific names from the tree_species table. Then, group the species by their fall color and sum these differences to determine the total change in the number of trees for each fall color."}, {"role": "assistant", "content": "SELECT\n  c.fall_color,\n  SUM(d.count_growth) AS change\nFROM (\n  SELECT\n    fall_color,\n    UPPER(species_scientific_name) AS latin\n  FROM\n    `bigquery-public-data.new_york.tree_species`)c\nJOIN (\n  SELECT\n    IFNULL(a.upper_latin,\n      b.upper_latin) AS latin,\n    (IFNULL(count_2015,\n        0)-IFNULL(count_1995,\n        0)) AS count_growth\n  FROM (\n    SELECT\n      UPPER(spc_latin) AS upper_latin,\n      spc_common,\n      COUNT(*) AS count_2015\n    FROM\n      `bigquery-public-data.new_york.tree_census_2015`\n    WHERE\n      status=\"Alive\"\n    GROUP BY\n      spc_latin,\n      spc_common)a\n  FULL OUTER JOIN (\n    SELECT\n      UPPER(spc_latin) AS upper_latin,\n      COUNT(*) AS count_1995\n    FROM\n      `bigquery-public-data.new_york.tree_census_1995`\n    WHERE\n      status !=\"Dead\"\n    GROUP BY\n      spc_latin)b\n  ON\n    a.upper_latin=b.upper_latin\n  ORDER BY\n    count_growth DESC)d\nON\n  d.latin=c.latin\nGROUP BY\n  fall_color\nORDER BY\n  change DESC"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: new_york\nQuestion: For the top 20 Citi Bike routes in 2016, which route is faster than yellow taxis and among those, which one has the longest average bike duration? Please provide the start station name of this route. The coordinates are rounded to three decimals."}, {"role": "assistant", "content": "WITH top20route AS (\nSELECT\n  start_station_name, end_station_name, avg_bike_duration, avg_taxi_duration\nFROM (\n  SELECT\n    start_station_name,\n    end_station_name,\n    ROUND(start_station_latitude, 3) AS ss_lat,\n    ROUND(start_station_longitude, 3) AS ss_long,\n    ROUND(end_station_latitude, 3) AS es_lat,\n    ROUND(end_station_longitude, 3) AS es_long,\n    AVG(tripduration) AS avg_bike_duration,\n    COUNT(*) AS bike_trips\n  FROM\n    `bigquery-public-data.new_york.citibike_trips`\n  WHERE \n  EXTRACT(YEAR from starttime) = 2016 AND\n    start_station_name != end_station_name\n  GROUP BY\n    start_station_name, end_station_name, ss_lat, ss_long, es_lat, es_long\n  ORDER BY\n    bike_trips DESC\n  LIMIT\n    20\n) a\nJOIN (\n  SELECT\n    ROUND(pickup_latitude, 3) AS pu_lat,\n    ROUND(pickup_longitude, 3) AS pu_long,\n    ROUND(dropoff_latitude, 3) AS do_lat,\n    ROUND(dropoff_longitude, 3) AS do_long,\n    AVG(UNIX_SECONDS(dropoff_datetime)-UNIX_SECONDS(pickup_datetime)) AS avg_taxi_duration,\n    COUNT(*) AS taxi_trips\n  FROM\n    `bigquery-public-data.new_york.tlc_yellow_trips_2016`\n  GROUP BY\n    pu_lat, pu_long, do_lat, do_long\n) b\nON\n  a.ss_lat = b.pu_lat AND\n  a.es_lat = b.do_lat AND\n  a.ss_long = b.pu_long AND\n  a.es_long = b.do_long\n)\n\nSELECT start_station_name\nFROM top20route\nWHERE avg_bike_duration < avg_taxi_duration\nORDER BY\navg_bike_duration\nDESC\nLIMIT 1"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: new_york_plus\nQuestion: What is the average trip duration in minutes for all valid Yellow taxi trips that took place between February 1, 2016, and February 7, 2016 (inclusive), with a positive trip duration, more than three passengers, and a trip distance of at least ten miles, where both the pickup and dropoff locations are in Brooklyn?"}, {"role": "assistant", "content": "SELECT \n    AVG(TIMESTAMP_DIFF(dropoff_datetime, pickup_datetime, SECOND) / 60.0) AS average_trip_duration_in_minutes\nFROM\n(\n    SELECT *\n    FROM `bigquery-public-data.new_york_taxi_trips.tlc_yellow_trips_2016` t\n    WHERE \n        pickup_datetime BETWEEN '2016-02-01' AND '2016-02-07' AND \n        dropoff_datetime BETWEEN '2016-02-01' AND '2016-02-07' AND\n        TIMESTAMP_DIFF(dropoff_datetime, pickup_datetime, SECOND) > 0 AND \n        passenger_count > 3 AND \n        trip_distance >= 10\n) t\nINNER JOIN `bigquery-public-data.new_york_taxi_trips.taxi_zone_geom` tz\nON t.pickup_location_id = tz.zone_id\nINNER JOIN `bigquery-public-data.new_york_taxi_trips.taxi_zone_geom` tz1\nON t.dropoff_location_id = tz1.zone_id\nWHERE \n    tz.borough = \"Brooklyn\" AND\n    tz1.borough = \"Brooklyn\";"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: new_york_plus\nQuestion: For NYC yellow taxi trips where both the pickup and dropoff occurred between January 1 and 7, 2016, inclusive, calculate the percentage of trips with no tip in each pickup borough, ensuring that only trips where the dropoff occurs after the pickup are included, the passenger count is greater than zero, and the trip distance, tip amount, tolls amount, MTA tax, fare amount, and total amount are non-negative; define \"no tip\" trips as those where the tip rate is zero, with the tip rate calculated as (tip_amount \u00d7 100) divided by total_amount (and considered zero when total_amount is zero).\n\nExternal Knowledge: taxi_tip_rate.md"}, {"role": "assistant", "content": "WITH t2 AS\n(\nSELECT \n    t.*,\n    t.pickup_location_id as pickup_zone_id,\n    tz.borough as pickup_borough\nFROM\n(\nSELECT *,\n    TIMESTAMP_DIFF(dropoff_datetime,pickup_datetime,SECOND) as time_duration_in_secs,\n    (CASE WHEN total_amount=0 THEN 0\n    ELSE (tip_amount*100/total_amount) END) as tip_rate\nFROM `bigquery-public-data.new_york_taxi_trips.tlc_yellow_trips_2016`\n) t\nINNER JOIN `bigquery-public-data.new_york_taxi_trips.taxi_zone_geom` tz\nON t.pickup_location_id = tz.zone_id\nWHERE \n    pickup_datetime BETWEEN '2016-01-01' AND '2016-01-07' \n    AND dropoff_datetime BETWEEN '2016-01-01' AND '2016-01-07'\n    AND TIMESTAMP_DIFF(dropoff_datetime,pickup_datetime,SECOND) > 0\n    AND passenger_count > 0\n    AND trip_distance >= 0 \n    AND tip_amount >= 0 \n    AND tolls_amount >= 0 \n    AND mta_tax >= 0 \n    AND fare_amount >= 0\n    AND total_amount >= 0\n),\nt3 AS\n(SELECT \npickup_borough,\n(CASE \n    WHEN tip_rate = 0 THEN 'no tip'\n    WHEN tip_rate <= 5 THEN 'Less than 5%'\n    WHEN tip_rate <= 10 THEN '5% to 10%'\n    WHEN tip_rate <= 15 THEN '10% to 15%'\n    WHEN tip_rate <= 20 THEN '15% to 20%'\n    WHEN tip_rate <= 25 THEN '20% to 25%'\n    ELSE 'More than 25%' END)as tip_category,\nCOUNT(*) as no_of_trips\nFROM t2\nGROUP BY 1,2\nORDER BY pickup_borough ASC),\nINFO AS (\nSELECT pickup_borough\n     , tip_category\n     , Sum(no_of_trips) as no_of_trips,\n     (CASE \n          WHEN pickup_borough is null THEN (select sum(no_of_trips)\n          FROM t3)\n          \n          WHEN pickup_borough is not null and tip_category is null THEN (select sum(no_of_trips)\n          FROM t3)\n          \n          WHEN pickup_borough is not null and tip_category is not null THEN (select sum(no_of_trips)\n          FROM t3\n          WHERE pickup_borough = m.pickup_borough)\n          END) as parent_sum,\n       (\n          Sum(no_of_trips)\n            /\n          (\n            CASE \n          WHEN pickup_borough is null THEN (select sum(no_of_trips)\n          FROM t3)\n          \n          WHEN pickup_borough is not null and tip_category is null THEN (select sum(no_of_trips)\n          FROM t3)\n          \n          WHEN pickup_borough is not null and tip_category is not null THEN (select sum(no_of_trips)\n          FROM t3\n          WHERE pickup_borough = m.pickup_borough)\n          END\n          )\n        ) as percentage\nFROM t3 m\nGROUP BY ROLLUP(pickup_borough, tip_category)\norder by 1, 2\n)\n\nSELECT \n    pickup_borough,\n    (SUM(CASE WHEN tip_category = 'no tip' THEN no_of_trips ELSE 0 END) * 100.0 / SUM(no_of_trips)) AS percentage_no_tip\nFROM t3\nGROUP BY pickup_borough\nORDER BY pickup_borough;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: new_york_plus\nQuestion: Find the top 10 taxi trips in New York City between July 1 and July 7, 2016 (ensuring both pickup and dropoff times fall within these dates) where the passenger count is greater than five, the trip distance is at least ten miles, and there are no negative fare-related amounts (including tip, tolls, mta tax, fare, and total costs). Exclude any trips where the dropoff time is not strictly after the pickup time, then sort the results by total fare amount in descending order. Finally, display each trip\u2019s pickup zone, dropoff zone, trip duration in seconds, driving speed in miles per hour, and tip rate as a percentage of the total fare amount."}, {"role": "assistant", "content": "SELECT \n    tz.zone_name AS pickup_zone,\n    tz1.zone_name AS dropoff_zone, \n    time_duration_in_secs,\n    driving_speed_miles_per_hour,\n    tip_rate\nFROM\n(\nSELECT *,\n    TIMESTAMP_DIFF(dropoff_datetime,pickup_datetime,SECOND) as time_duration_in_secs,\n    ROUND(trip_distance / (TIMESTAMP_DIFF(dropoff_datetime, pickup_datetime, SECOND) / 3600), 2) AS driving_speed_miles_per_hour,\n    (CASE WHEN total_amount=0 THEN 0\n          ELSE (tip_amount*100/total_amount) END) as tip_rate\nFROM `bigquery-public-data.new_york_taxi_trips.tlc_yellow_trips_2016`\n) t\nINNER JOIN `bigquery-public-data.new_york_taxi_trips.taxi_zone_geom` tz\nON t.pickup_location_id = tz.zone_id\nINNER JOIN `bigquery-public-data.new_york_taxi_trips.taxi_zone_geom` tz1\nON t.dropoff_location_id = tz1.zone_id\nWHERE \n    pickup_datetime BETWEEN '2016-07-01' AND '2016-07-07' \n    AND dropoff_datetime BETWEEN '2016-07-01' AND '2016-07-07'\n    AND TIMESTAMP_DIFF(dropoff_datetime,pickup_datetime,SECOND) > 0\n    AND passenger_count > 5\n    AND trip_distance >= 10\n    AND tip_amount >= 0 \n    AND tolls_amount >= 0 \n    AND mta_tax >= 0 \n    AND fare_amount >= 0\n    AND total_amount >= 0\nORDER BY total_amount DESC\nLIMIT 10;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: new_york_plus\nQuestion: For each New York City borough, how many subway stations are there in total, how many have at least one entrance that is marked both as an actual entry and as ADA-compliant, and what percentage of the total stations in each borough does this represent, listing boroughs from the highest to the lowest percentage?"}, {"role": "assistant", "content": "WITH stations_n_entrances AS (\n      SELECT borough_name,s.station_name,entry,ada_compliant\n      FROM `bigquery-public-data.new_york_subway.stations` s\n      JOIN `bigquery-public-data.new_york_subway.station_entrances` se\n      ON s.station_name = se.station_name\n      )\n\nSELECT se.borough_name, COUNT(DISTINCT se.station_name) num_stations,\n      COUNT(DISTINCT adas.station_name) num_stations_w_compliant_entrance, \n      (100*COUNT(DISTINCT adas.station_name))/(COUNT(DISTINCT se.station_name)) percent_compliant_stations\nFROM `stations_n_entrances` se\nLEFT JOIN `stations_n_entrances` adas\nON se.station_name = adas.station_name\nAND adas.entry AND adas.ada_compliant\nGROUP BY 1\nORDER BY 4 DESC"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: san_francisco\nQuestion: What is the total distance traveled by each bike in the San Francisco Bikeshare program, measured in meters? Use data from bikeshare trips and stations to calculate this."}, {"role": "assistant", "content": "SELECT\n  bike_number, \n  AVG(dist_in_m) AS avg_dist_m, \n  SUM(dist_in_m) AS total_dist_m\nFROM (\n  SELECT\n    ST_DISTANCE(\n      ST_GEOGPOINT(start_lon, start_lat),\n      ST_GEOGPOINT(end_lon, end_lat)\n    ) AS dist_in_m,\n    starts.bike_number\n  FROM (\n    SELECT \n      latitude AS start_lat,\n      longitude AS start_lon,\n      bike_number,\n      trip_id\n    FROM `bigquery-public-data.san_francisco.bikeshare_trips` trips\n    LEFT JOIN `bigquery-public-data.san_francisco.bikeshare_stations` stations\n      ON trips.start_station_id = stations.station_id\n  ) starts\n  LEFT JOIN (\n    SELECT \n      latitude AS end_lat,\n      longitude AS end_lon,\n      bike_number,\n      trip_id\n    FROM `bigquery-public-data.san_francisco.bikeshare_trips` trips\n    LEFT JOIN `bigquery-public-data.san_francisco.bikeshare_stations` stations\n      ON trips.end_station_id = stations.station_id\n  ) ends ON ends.trip_id = starts.trip_id\n)\nGROUP BY bike_number\nORDER BY total_dist_m DESC"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: san_francisco_plus\nQuestion: Find the latest ride data for each region between 2014 and 2017. I want to know the name of each region, the trip ID of this ride, the ride duration, the start time, the starting station, and the gender of the rider."}, {"role": "assistant", "content": "SELECT t1.*\n  FROM \n  (SELECT Trips.trip_id TripId,\n               Trips.duration_sec TripDuration,\n               Trips.start_date TripStartDate,\n               Trips.start_station_name TripStartStation,\n               Trips.member_gender Gender,\n               Regions.name RegionName\n          FROM `bigquery-public-data.san_francisco_bikeshare.bikeshare_trips` Trips\n         INNER JOIN `bigquery-public-data.san_francisco_bikeshare.bikeshare_station_info` StationInfo\n            ON CAST(Trips.start_station_id AS STRING) = CAST(StationInfo.station_id AS STRING)\n         INNER JOIN `bigquery-public-data.san_francisco_bikeshare.bikeshare_regions` Regions\n            ON StationInfo.region_id = Regions.region_id\n         WHERE (EXTRACT(YEAR from Trips.start_date)) BETWEEN 2014 AND 2017\n           ) \n           t1\n RIGHT JOIN (SELECT MAX(start_date) TripStartDate,\n                   Regions.name RegionName\n              FROM `bigquery-public-data.san_francisco_bikeshare.bikeshare_station_info` StationInfo\n             INNER JOIN `bigquery-public-data.san_francisco_bikeshare.bikeshare_trips` Trips\n                ON CAST(StationInfo.station_id AS STRING) = CAST(Trips.start_station_id AS STRING)\n             INNER JOIN `bigquery-public-data.san_francisco_bikeshare.bikeshare_regions` Regions\n                ON Regions.region_id = StationInfo.region_id\n                 WHERE (EXTRACT(YEAR from Trips.start_date) BETWEEN 2014 AND 2017\n           AND Regions.name IS NOT NULL)\n             GROUP BY RegionName) \n             t2\n    ON t1.RegionName = t2.RegionName AND t1.TripStartDate = t2.TripStartDate"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: SAN_FRANCISCO_PLUS\nQuestion: Could you provide the details of the top 5 longest bike share trips that started between July 1, 2017, and December 31, 2017, including the trip ID, duration in seconds, start date, start station name, route (derived from start station name to end station name), bike number, subscriber type, member's birth year, the member's current age (calculated using the current year), an age classification based on whether the member is younger than 40, between 40 and 60, or older than 60, the member's gender, and the name of the region of the start station? Please exclude any trips where the start station name, member's birth year, or member's gender is not specified.\n\nExternal Knowledge: trip_info.md"}, {"role": "assistant", "content": "SELECT\n  \"trip_id\",\n  \"duration_sec\",\n  DATE(TO_TIMESTAMP_LTZ(\"start_date\" / 1000000)) AS \"star_date\",\n  \"start_station_name\",\n  CONCAT(\"start_station_name\", ' - ', \"end_station_name\") AS \"route\",\n  \"bike_number\",\n  \"subscriber_type\",\n  \"member_birth_year\",\n  (EXTRACT(YEAR FROM CURRENT_DATE()) - \"member_birth_year\") AS \"age\",\n  CASE\n    WHEN (EXTRACT(YEAR FROM CURRENT_DATE()) - \"member_birth_year\") < 40 THEN 'Young (<40 Y.O)'\n    WHEN (EXTRACT(YEAR FROM CURRENT_DATE()) - \"member_birth_year\") BETWEEN 40 AND 60 THEN 'Adult (40-60 Y.O)'\n    ELSE 'Senior Adult (>60 Y.O)'\n  END AS \"age_class\",\n  \"member_gender\",\n  c.\"name\" AS \"region_name\"\nFROM \"SAN_FRANCISCO_PLUS\".\"SAN_FRANCISCO_BIKESHARE\".\"BIKESHARE_TRIPS\" a\nLEFT JOIN \"SAN_FRANCISCO_PLUS\".\"SAN_FRANCISCO_BIKESHARE\".\"BIKESHARE_STATION_INFO\" b \n  ON a.\"start_station_id\" = b.\"station_id\"\nLEFT JOIN \"SAN_FRANCISCO_PLUS\".\"SAN_FRANCISCO_BIKESHARE\".\"BIKESHARE_REGIONS\" c \n  ON b.\"region_id\" = c.\"region_id\"\nWHERE TO_TIMESTAMP_LTZ(\"start_date\" / 1000000) BETWEEN '2017-07-01' AND '2017-12-31'\n  AND b.\"station_id\" IS NOT NULL\n  AND \"member_birth_year\" IS NOT NULL\n  AND \"member_gender\" IS NOT NULL\nORDER BY \"duration_sec\" DESC\nLIMIT 5;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: san_francisco_plus\nQuestion: Which month in 2017 had the largest absolute difference between cumulative bike usage minutes for customers and subscribers?\tWhich month (in number) in 2017 had the largest absolute difference between cumulative bike usage minutes (in thousands) for customers and subscribers, based on the trip end dates in the San Francisco bikeshare data?"}, {"role": "assistant", "content": "WITH monthly_totals AS (\n  SELECT\n    SUM(CASE WHEN subscriber_type = 'Customer' THEN duration_sec / 60 ELSE NULL END) AS customer_minutes_sum,\n    SUM(CASE WHEN subscriber_type = 'Subscriber' THEN duration_sec / 60 ELSE NULL END) AS subscriber_minutes_sum,\n    EXTRACT(MONTH FROM end_date) AS end_month\n  FROM\n    `bigquery-public-data.san_francisco_bikeshare.bikeshare_trips`\n  WHERE\n    EXTRACT(YEAR FROM end_date) = 2017\n  GROUP BY\n    end_month\n),\n\ncumulative_totals AS (\n  SELECT\n    end_month,\n    SUM(customer_minutes_sum) OVER (ORDER BY end_month ROWS UNBOUNDED PRECEDING) / 1000 AS cumulative_minutes_cust,\n    SUM(subscriber_minutes_sum) OVER (ORDER BY end_month ROWS UNBOUNDED PRECEDING) / 1000 AS cumulative_minutes_sub\n  FROM\n    monthly_totals\n),\n\ndifferences AS (\n  SELECT\n    end_month,\n    ABS(cumulative_minutes_cust - cumulative_minutes_sub) AS abs_diff\n  FROM\n    cumulative_totals\n)\n\nSELECT\n  end_month\nFROM\n  differences\nORDER BY\n  abs_diff DESC\nLIMIT 1;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: san_francisco_plus\nQuestion: For trips where 'Clay St & Drumm St' occurs before 'Sacramento St & Davis St' in the stop sequence (one direction only), what are the earliest departure times from 'Clay St & Drumm St' and the latest arrival times at 'Sacramento St & Davis St' in the format HH:MM:SS? Please provide the trip headsign for each route."}, {"role": "assistant", "content": "WITH SelectedStops AS (\n  SELECT \n      stop_id,\n      stop_name\n  FROM \n      `bigquery-public-data.san_francisco_transit_muni.stops`\n  WHERE \n      stop_name IN ('Clay St & Drumm St', 'Sacramento St & Davis St')\n),\nFilteredStopTimes AS (\n  SELECT \n      st.trip_id, \n      st.stop_id, \n      st.arrival_time, \n      st.departure_time, \n      st.stop_sequence, \n      ss.stop_name\n  FROM \n      `bigquery-public-data.san_francisco_transit_muni.stop_times` st\n  JOIN \n      SelectedStops ss ON CAST(st.stop_id AS STRING) = ss.stop_id\n)\nSELECT\n    t.trip_headsign,\n    MIN(st1.departure_time) AS start_time,\n    MAX(st2.arrival_time) AS end_time\nFROM \n    `bigquery-public-data.san_francisco_transit_muni.trips` t\nJOIN FilteredStopTimes st1 ON t.trip_id = CAST(st1.trip_id AS STRING) AND st1.stop_name = 'Clay St & Drumm St'\nJOIN FilteredStopTimes st2 ON t.trip_id = CAST(st2.trip_id AS STRING) AND st2.stop_name = 'Sacramento St & Davis St'\nWHERE \n    st1.stop_sequence < st2.stop_sequence\nGROUP BY \n    t.trip_headsign;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: san_francisco_plus\nQuestion: What is the highest average speed (rounded to 1 decimal, in metric m/s) for bike trips in Berkeley with trip distance greater than 1000 meters?"}, {"role": "assistant", "content": "WITH stations AS (\n  SELECT station_id\n  FROM\n    `bigquery-public-data.san_francisco_bikeshare.bikeshare_station_info` AS stainfo\n  WHERE stainfo.region_id = (\n    SELECT region.region_id\n    FROM `bigquery-public-data.san_francisco_bikeshare.bikeshare_regions` AS region\n    WHERE region.name = \"Berkeley\"\n  )\n),\nmeta_data AS (\n    SELECT\n        round(st_distance(start_station_geom, end_station_geom), 1) as distancia_metros,\n        round(st_distance(start_station_geom, end_station_geom) / duration_sec, 1) as velocidade_media\n    FROM\n        `bigquery-public-data.san_francisco_bikeshare.bikeshare_trips` AS trips\n    WHERE\n        cast(trips.start_station_id as string) IN (SELECT station_id FROM stations)\n        AND cast(trips.end_station_id as string) IN (SELECT station_id FROM stations)\n        AND start_station_latitude IS NOT NULL\n        AND start_station_longitude IS NOT NULL\n        AND end_station_latitude IS NOT NULL\n        AND end_station_longitude IS NOT NULL\n        AND st_distance(start_station_geom, end_station_geom) > 1000\n    ORDER BY\n        velocidade_media DESC\n    LIMIT 1\n)\n\nSELECT velocidade_media as max_velocity\nFROM meta_data;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: san_francisco_plus\nQuestion: For each neighborhood in San Francisco where at least one bike share station and at least one crime incident are located, provide the neighborhood name along with the total count of bike share stations and the total number of crime incidents in that neighborhood."}, {"role": "assistant", "content": "WITH station_neighborhoods AS (\n   SELECT\n       bs.station_id,\n       bs.name AS station_name,\n       nb.neighborhood\n   FROM `bigquery-public-data.san_francisco.bikeshare_stations` bs\n   JOIN\n       bigquery-public-data.san_francisco_neighborhoods.boundaries nb\n   ON \n       ST_Intersects(ST_GeogPoint(bs.longitude, bs.latitude), nb.neighborhood_geom)\n),\n\nneighborhood_crime_counts AS (\n   SELECT\n       neighborhood,\n       COUNT(*) AS crime_count\n   FROM (\n       SELECT\n           n.neighborhood\n       FROM\n           bigquery-public-data.san_francisco.sfpd_incidents i\n       JOIN\n           bigquery-public-data.san_francisco_neighborhoods.boundaries n\n       ON\n           ST_Intersects(ST_GeogPoint(i.longitude, i.latitude), n.neighborhood_geom)\n   ) AS incident_neighborhoods\n   GROUP BY\n       neighborhood\n)\n\nSELECT\n  sn.neighborhood,\n  COUNT(station_name) AS station_number,\n  ANY_VALUE(ncc.crime_count) AS crime_number\nFROM\n  station_neighborhoods sn\nJOIN\n  neighborhood_crime_counts ncc\nON\n  sn.neighborhood = ncc.neighborhood\nGROUP BY sn.neighborhood\nORDER BY\n  crime_number ASC"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: THELOOK_ECOMMERCE\nQuestion: From January 1, 2019, to April 30, 2022, how many users are at the youngest age and how many users are at the oldest age for each gender in the e-commerce platform, counting both youngest and oldest users separately for each gender?"}, {"role": "assistant", "content": "WITH filtered_users AS (\n    SELECT \n        \"first_name\", \n        \"last_name\", \n        \"gender\", \n        \"age\",\n        CAST(TO_TIMESTAMP(\"created_at\" / 1000000.0) AS DATE) AS \"created_at\"\n    FROM \n        \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"USERS\"\n    WHERE \n        CAST(TO_TIMESTAMP(\"created_at\" / 1000000.0) AS DATE) BETWEEN '2019-01-01' AND '2022-04-30'\n),\nyoungest_ages AS (\n    SELECT \n        \"gender\", \n        MIN(\"age\") AS \"age\"\n    FROM \n        filtered_users\n    GROUP BY \n        \"gender\"\n),\noldest_ages AS (\n    SELECT \n        \"gender\", \n        MAX(\"age\") AS \"age\"\n    FROM \n        filtered_users\n    GROUP BY \n        \"gender\"\n),\nyoungest_oldest AS (\n    SELECT \n        u.\"first_name\", \n        u.\"last_name\", \n        u.\"gender\", \n        u.\"age\", \n        'youngest' AS \"tag\"\n    FROM \n        filtered_users u\n    JOIN \n        youngest_ages y\n    ON \n        u.\"gender\" = y.\"gender\" AND u.\"age\" = y.\"age\"\n    \n    UNION ALL\n    \n    SELECT \n        u.\"first_name\", \n        u.\"last_name\", \n        u.\"gender\", \n        u.\"age\", \n        'oldest' AS \"tag\"\n    FROM \n        filtered_users u\n    JOIN \n        oldest_ages o\n    ON \n        u.\"gender\" = o.\"gender\" AND u.\"age\" = o.\"age\"\n)\nSELECT \n    \"tag\", \n    \"gender\", \n    COUNT(*) AS \"num\"\nFROM \n    youngest_oldest\nGROUP BY \n    \"tag\", \"gender\"\nORDER BY \n    \"tag\", \"gender\";"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: THELOOK_ECOMMERCE\nQuestion: Please create a month-by-month report for the year 2023 that focuses on the 'Sleep & Lounge' category, showing for each month the total sales, total cost, number of complete orders, total profit, and the profit-to-cost ratio, ensuring that the order is marked as 'Complete,' the creation date is between January 1, 2023, and December 31, 2023, and the cost data is accurately associated with the corresponding product through the order items. "}, {"role": "assistant", "content": "WITH d AS (\n    SELECT\n        a.\"order_id\", \n        TO_CHAR(TO_TIMESTAMP(a.\"created_at\" / 1000000.0), 'YYYY-MM') AS \"month\",  -- \u683c\u5f0f\u5316\u4e3a\u5e74\u6708\n        TO_CHAR(TO_TIMESTAMP(a.\"created_at\" / 1000000.0), 'YYYY') AS \"year\",  -- \u683c\u5f0f\u5316\u4e3a\u5e74\u4efd\n        b.\"product_id\", b.\"sale_price\", c.\"category\", c.\"cost\"\n    FROM \n        \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"ORDERS\" AS a\n    JOIN \n        \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"ORDER_ITEMS\" AS b\n        ON a.\"order_id\" = b.\"order_id\"\n    JOIN \n        \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"PRODUCTS\" AS c\n        ON b.\"product_id\" = c.\"id\"\n    WHERE \n        a.\"status\" = 'Complete'\n        AND TO_TIMESTAMP(a.\"created_at\" / 1000000.0) BETWEEN TO_TIMESTAMP('2023-01-01') AND TO_TIMESTAMP('2023-12-31')\n        AND c.\"category\" = 'Sleep & Lounge'\n),\n\ne AS (\n    SELECT \n        \"month\", \n        \"year\", \n        \"sale_price\", \n        \"category\", \n        \"cost\",\n        SUM(\"sale_price\") OVER (PARTITION BY \"month\", \"category\") AS \"TPV\",\n        SUM(\"cost\") OVER (PARTITION BY \"month\", \"category\") AS \"total_cost\",\n        COUNT(DISTINCT \"order_id\") OVER (PARTITION BY \"month\", \"category\") AS \"TPO\",\n        SUM(\"sale_price\" - \"cost\") OVER (PARTITION BY \"month\", \"category\") AS \"total_profit\",\n        SUM((\"sale_price\" - \"cost\") / \"cost\") OVER (PARTITION BY \"month\", \"category\") AS \"Profit_to_cost_ratio\"\n    FROM \n        d\n)\n\nSELECT DISTINCT \n    \"month\", \n    \"category\", \n    \"TPV\", \n    \"total_cost\", \n    \"TPO\", \n    \"total_profit\", \n    \"Profit_to_cost_ratio\"\nFROM \n    e\nORDER BY \n    \"month\";"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: THELOOK_ECOMMERCE\nQuestion: Identify the difference in the number of the oldest and youngest users registered between January 1, 2019, and April 30, 2022, from our e-commerce platform data."}, {"role": "assistant", "content": "WITH youngest AS (\n    SELECT\n        \"gender\", \n        \"id\", \n        \"first_name\", \n        \"last_name\", \n        \"age\", \n        'youngest' AS \"tag\"\n    FROM \n        \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"USERS\"\n    WHERE \n        \"age\" = (SELECT MIN(\"age\") FROM \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"USERS\")\n        AND TO_TIMESTAMP(\"created_at\" / 1000000.0) BETWEEN TO_TIMESTAMP('2019-01-01') AND TO_TIMESTAMP('2022-04-30')\n    GROUP BY \n        \"gender\", \"id\", \"first_name\", \"last_name\", \"age\"\n    ORDER BY \n        \"gender\"\n),\n\noldest AS (\n    SELECT\n        \"gender\", \n        \"id\", \n        \"first_name\", \n        \"last_name\", \n        \"age\", \n        'oldest' AS \"tag\"\n    FROM \n        \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"USERS\"\n    WHERE \n        \"age\" = (SELECT MAX(\"age\") FROM \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"USERS\")\n        AND TO_TIMESTAMP(\"created_at\" / 1000000.0) BETWEEN TO_TIMESTAMP('2019-01-01') AND TO_TIMESTAMP('2022-04-30')\n    GROUP BY \n        \"gender\", \"id\", \"first_name\", \"last_name\", \"age\"\n    ORDER BY \n        \"gender\"\n),\n\nTEMP_record AS (\n    SELECT * FROM youngest\n    UNION ALL\n    SELECT * FROM oldest\n)\n\nSELECT \n    SUM(CASE WHEN \"age\" = (SELECT MAX(\"age\") FROM \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"USERS\") THEN 1 END) - \n    SUM(CASE WHEN \"age\" = (SELECT MIN(\"age\") FROM \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"USERS\") THEN 1 END) AS \"diff\"\nFROM \n    TEMP_record;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: THELOOK_ECOMMERCE\nQuestion: Can you list the email addresses of the top 10 users who registered in 2019 and made purchases in 2019, ranking them by their highest average order value, where average order value is calculated by multiplying the number of items in each order by the sale price, summing this total across all orders for each user, and then dividing by the total number of orders?"}, {"role": "assistant", "content": "WITH\n  main AS (\n    SELECT\n      \"id\" AS \"user_id\",\n      \"email\",\n      \"gender\",\n      \"country\",\n      \"traffic_source\"\n    FROM\n      \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"USERS\"\n    WHERE\n      TO_TIMESTAMP(\"created_at\" / 1000000.0) BETWEEN TO_TIMESTAMP('2019-01-01') AND TO_TIMESTAMP('2019-12-31')\n  ),\n\n  daate AS (\n    SELECT\n      \"user_id\",\n      \"order_id\",\n      CAST(TO_TIMESTAMP(\"created_at\" / 1000000.0) AS DATE) AS \"order_date\",\n      \"num_of_item\"\n    FROM\n      \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"ORDERS\"\n    WHERE\n      TO_TIMESTAMP(\"created_at\" / 1000000.0) BETWEEN TO_TIMESTAMP('2019-01-01') AND TO_TIMESTAMP('2019-12-31')\n  ),\n\n  orders AS (\n    SELECT\n      \"user_id\",\n      \"order_id\",\n      \"product_id\",\n      \"sale_price\",\n      \"status\"\n    FROM\n      \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"ORDER_ITEMS\"\n    WHERE\n      TO_TIMESTAMP(\"created_at\" / 1000000.0) BETWEEN TO_TIMESTAMP('2019-01-01') AND TO_TIMESTAMP('2019-12-31')\n  ),\n\n  nest AS (\n    SELECT\n      o.\"user_id\",\n      o.\"order_id\",\n      o.\"product_id\",\n      d.\"order_date\",\n      d.\"num_of_item\",\n      ROUND(o.\"sale_price\", 2) AS \"sale_price\",\n      ROUND(d.\"num_of_item\" * o.\"sale_price\", 2) AS \"total_sale\"\n    FROM\n      orders o\n    INNER JOIN\n      daate d\n    ON\n      o.\"order_id\" = d.\"order_id\"\n    ORDER BY\n      o.\"user_id\"\n  ),\n\n  type AS (\n    SELECT\n      \"user_id\",\n      MIN(nest.\"order_date\") AS \"cohort_date\",\n      MAX(nest.\"order_date\") AS \"latest_shopping_date\",\n      DATEDIFF(MONTH, MIN(nest.\"order_date\"), MAX(nest.\"order_date\")) AS \"lifespan_months\",\n      ROUND(SUM(\"total_sale\"), 2) AS \"ltv\",\n      COUNT(\"order_id\") AS \"no_of_order\"\n    FROM\n      nest\n    GROUP BY\n      \"user_id\"\n  ),\n\n  kite AS (\n    SELECT\n      m.\"user_id\",\n      m.\"email\",\n      m.\"gender\",\n      m.\"country\",\n      m.\"traffic_source\",\n      EXTRACT(YEAR FROM n.\"cohort_date\") AS \"cohort_year\",\n      n.\"latest_shopping_date\",\n      n.\"lifespan_months\",\n      n.\"ltv\",\n      n.\"no_of_order\",\n      ROUND(n.\"ltv\" / n.\"no_of_order\", 2) AS \"avg_order_value\"\n    FROM\n      main m\n    INNER JOIN\n      type n\n    ON\n      m.\"user_id\" = n.\"user_id\"\n  )\n\nSELECT\n  \"email\"\nFROM\n  kite\nORDER BY\n  \"avg_order_value\" DESC\nLIMIT 10;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: THELOOK_ECOMMERCE\nQuestion: Please generate a report that, for each month in 2021, provides the number of orders, the number of unique purchasers, and the profit (calculated as the sum of product retail prices minus the sum of product costs), where the orders were placed during 2021 by users who registered in 2021 for inventory items created in 2021, and group the results by the users' country, product department, and product category."}, {"role": "assistant", "content": "WITH\norders_x_order_items AS (\n  SELECT orders.*,\n         order_items.\"inventory_item_id\",\n         order_items.\"sale_price\"\n  FROM \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"ORDERS\" AS orders\n  LEFT JOIN \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"ORDER_ITEMS\" AS order_items\n  ON orders.\"order_id\" = order_items.\"order_id\"\n  WHERE TO_TIMESTAMP_NTZ(orders.\"created_at\" / 1000000) BETWEEN TO_TIMESTAMP_NTZ('2021-01-01') AND TO_TIMESTAMP_NTZ('2021-12-31')\n),\n\norders_x_inventory AS (\n  SELECT orders_x_order_items.*,\n         inventory_items.\"product_category\",\n         inventory_items.\"product_department\",\n         inventory_items.\"product_retail_price\",\n         inventory_items.\"product_distribution_center_id\",\n         inventory_items.\"cost\",\n         distribution_centers.\"name\"\n  FROM orders_x_order_items\n  LEFT JOIN \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"INVENTORY_ITEMS\" AS inventory_items\n  ON orders_x_order_items.\"inventory_item_id\" = inventory_items.\"id\"\n  LEFT JOIN \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"DISTRIBUTION_CENTERS\" AS distribution_centers\n  ON inventory_items.\"product_distribution_center_id\" = distribution_centers.\"id\"\n  WHERE TO_TIMESTAMP_NTZ(inventory_items.\"created_at\" / 1000000) BETWEEN TO_TIMESTAMP_NTZ('2021-01-01') AND TO_TIMESTAMP_NTZ('2021-12-31')\n),\n\norders_x_users AS (\n  SELECT orders_x_inventory.*,\n         users.\"country\" AS \"users_country\"\n  FROM orders_x_inventory\n  LEFT JOIN \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"USERS\" AS users\n  ON orders_x_inventory.\"user_id\" = users.\"id\"\n  WHERE TO_TIMESTAMP_NTZ(users.\"created_at\" / 1000000) BETWEEN TO_TIMESTAMP_NTZ('2021-01-01') AND TO_TIMESTAMP_NTZ('2021-12-31')\n)\n\nSELECT \n  DATE_TRUNC('MONTH', TO_DATE(TO_TIMESTAMP_NTZ(orders_x_users.\"created_at\" / 1000000))) AS \"reporting_month\",\n  orders_x_users.\"users_country\",\n  orders_x_users.\"product_department\",\n  orders_x_users.\"product_category\",\n  COUNT(DISTINCT orders_x_users.\"order_id\") AS \"n_order\",\n  COUNT(DISTINCT orders_x_users.\"user_id\") AS \"n_purchasers\",\n  SUM(orders_x_users.\"product_retail_price\") - SUM(orders_x_users.\"cost\") AS \"profit\"\nFROM orders_x_users\nGROUP BY 1, 2, 3, 4\nORDER BY \"reporting_month\";"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: THELOOK_ECOMMERCE\nQuestion: Can you list the top 5 months from August 2022 to November 2023 where the profit from Facebook-sourced completed orders showed the largest month-over-month increase? Calculate profit as sales minus costs, group by delivery month, and include only orders created between August 2022 and November 2023. Compare each month's profit to its previous month to find the largest increases."}, {"role": "assistant", "content": "WITH \norders AS (\n  SELECT\n    \"order_id\", \n    \"user_id\", \n    \"created_at\",\n    DATE_TRUNC('MONTH', TO_TIMESTAMP_NTZ(\"delivered_at\" / 1000000)) AS \"delivery_month\",  -- Converting to timestamp\n    \"status\" \n  FROM \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"ORDERS\"\n),\n\norder_items AS (\n  SELECT \n    \"order_id\", \n    \"product_id\", \n    \"sale_price\" \n  FROM \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"ORDER_ITEMS\"\n),\n\nproducts AS (\n  SELECT \n    \"id\", \n    \"cost\"\n  FROM \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"PRODUCTS\"\n),\n\nusers AS (\n  SELECT\n    \"id\", \n    \"traffic_source\" \n  FROM \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"USERS\"\n),\n\nfilter_join AS (\n  SELECT \n    orders.\"order_id\",\n    orders.\"user_id\",\n    order_items.\"product_id\",\n    orders.\"delivery_month\",\n    orders.\"status\",\n    order_items.\"sale_price\",\n    products.\"cost\",\n    users.\"traffic_source\"\n  FROM orders\n  JOIN order_items ON orders.\"order_id\" = order_items.\"order_id\"\n  JOIN products ON order_items.\"product_id\" = products.\"id\"\n  JOIN users ON orders.\"user_id\" = users.\"id\"\n  WHERE orders.\"status\" = 'Complete' \n    AND users.\"traffic_source\" = 'Facebook'\n    AND TO_TIMESTAMP_NTZ(orders.\"created_at\" / 1000000) BETWEEN TO_TIMESTAMP_NTZ('2022-07-01') AND TO_TIMESTAMP_NTZ('2023-11-30')  -- Include July for calculation\n),\n\nmonthly_sales AS (\n  SELECT \n    \"delivery_month\",\n    \"traffic_source\",\n    SUM(\"sale_price\") AS \"total_revenue\",\n    SUM(\"sale_price\") - SUM(\"cost\") AS \"total_profit\",\n    COUNT(DISTINCT \"product_id\") AS \"product_quantity\",\n    COUNT(DISTINCT \"order_id\") AS \"orders_quantity\",\n    COUNT(DISTINCT \"user_id\") AS \"users_quantity\"\n  FROM filter_join\n  GROUP BY \"delivery_month\", \"traffic_source\"\n)\n\n-- Filter to show only 8th month and onwards, but calculate using July\nSELECT \n  current_month.\"delivery_month\",\n  COALESCE(\n    current_month.\"total_profit\" - previous_month.\"total_profit\", \n    0  -- If there is no previous month (i.e. for 8\u6708), return 0\n  ) AS \"profit_vs_prior_month\"\nFROM monthly_sales AS current_month\nLEFT JOIN monthly_sales AS previous_month\n  ON current_month.\"traffic_source\" = previous_month.\"traffic_source\"\n  AND current_month.\"delivery_month\" = DATEADD(MONTH, -1, previous_month.\"delivery_month\")  -- Correctly join to previous month\nWHERE current_month.\"delivery_month\" >= '2022-08-01'  -- Only show August and later data, but use July for calculation\nORDER BY \"profit_vs_prior_month\" DESC\nLIMIT 5;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: census_bureau_international\nQuestion: Provide a list of the top 10 countries for the year 2020, ordered by the highest percentage of their population under 20 years old. For each country, include the total population under 20 years old, the total midyear population, and the percentage of the population that is under 20 years old."}, {"role": "assistant", "content": "SELECT\n  age.country_name,\n  SUM(age.population) AS under_25,\n  pop.midyear_population AS total,\n  ROUND((SUM(age.population) / pop.midyear_population) * 100,2) AS pct_under_25\nFROM (\n  SELECT\n    country_name,\n    population,\n    country_code\n  FROM\n    `bigquery-public-data.census_bureau_international.midyear_population_agespecific`\n  WHERE\n    year =2020\n    AND age < 20) age\nINNER JOIN (\n  SELECT\n    midyear_population,\n    country_code\n  FROM\n    `bigquery-public-data.census_bureau_international.midyear_population`\n  WHERE\n    year = 2020) pop\nON\n  age.country_code = pop.country_code\nGROUP BY\n  1,\n  3\nORDER BY\n  4 DESC\n/* Remove limit for visualization */\nLIMIT\n  10"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: census_bureau_international\nQuestion: Which country has the highest percentage of population under the age of 25 in 2017?"}, {"role": "assistant", "content": "SELECT\ncountry_name\nFROM\n(SELECT\n  age.country_name,\n  SUM(age.population) AS under_25,\n  pop.midyear_population AS total,\n  ROUND((SUM(age.population) / pop.midyear_population) * 100,2) AS pct_under_25\nFROM (\n  SELECT\n    country_name,\n    population,\n    country_code\n  FROM\n    `bigquery-public-data.census_bureau_international.midyear_population_agespecific`\n  WHERE\n    year =2017\n    AND age < 25) age\nINNER JOIN (\n  SELECT\n    midyear_population,\n    country_code\n  FROM\n    `bigquery-public-data.census_bureau_international.midyear_population`\n  WHERE\n    year = 2017) pop\nON\n  age.country_code = pop.country_code\nGROUP BY\n  1,\n  3\nORDER BY\n  4 DESC\n)\nLIMIT\n1"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: covid19_open_data\nQuestion: Which day in March and April had the highest COVID-19 confirmed case growth rate in the United States? The format is MM-DD."}, {"role": "assistant", "content": "WITH us_cases_by_date AS (\n  SELECT\n    date,\n    SUM( cumulative_confirmed ) AS cases\n  FROM\n    `bigquery-public-data.covid19_open_data.covid19_open_data`\n  WHERE\n    country_name=\"United States of America\"\n    AND date between '2020-03-01' and '2020-04-30'\n  GROUP BY\n    date\n  ORDER BY\n    date ASC\n )\n\n, us_previous_day_comparison AS\n(SELECT\n  date,\n  cases,\n  LAG(cases) OVER(ORDER BY date) AS previous_day,\n  cases - LAG(cases) OVER(ORDER BY date) AS net_new_cases,\n  (cases - LAG(cases) OVER(ORDER BY date))*100/LAG(cases) OVER(ORDER BY date) AS percentage_increase\nFROM us_cases_by_date\n)\nSELECT\n  FORMAT_DATE('%m-%d', Date) \nFROM\n  us_previous_day_comparison\nORDER BY  \n  percentage_increase\nDESC\nLIMIT 1"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: covid19_open_world_bank\nQuestion: You need to calculate the percentage of each country's population that had been confirmed with COVID-19 by June 30, 2020. The population data for 2018 can be found in the World Bank dataset, and the cumulative COVID-19 confirmed cases data is available in the COVID-19 Open Data dataset. Calculate the percentage of each country's population, that was cumulatively confirmed to have COVID-19"}, {"role": "assistant", "content": "WITH\n  country_pop AS (\n  SELECT\n    country_code AS iso_3166_1_alpha_3,\n    year_2018 AS population_2018\n  FROM\n    `bigquery-public-data.world_bank_global_population.population_by_country`)\nSELECT\n  country_code,\n  country_name,\n  cumulative_confirmed AS june_confirmed_cases,\n  population_2018,\n  ROUND(cumulative_confirmed/population_2018 * 100,2) AS case_percent\nFROM\n  `bigquery-public-data.covid19_open_data.covid19_open_data`\nJOIN\n  country_pop\nUSING\n  (iso_3166_1_alpha_3)\nWHERE\n  date = '2020-06-30'\n  AND aggregation_level = 0\nORDER BY\n  case_percent DESC"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: covid19_jhu_world_bank\nQuestion: Could you provide, for the United States, France, China, Italy, Spain, Germany, and Iran, the total number of confirmed COVID-19 cases as of April 20, 2020, along with the number of cases per 100,000 people based on their total 2020 populations calculated by summing all relevant population entries from the World Bank data"}, {"role": "assistant", "content": "SELECT\n  c.country,\n  c.total_confirmed_cases,\n  (c.total_confirmed_cases / p.population) * 100000 AS cases_per_100k\nFROM\n  (\n    SELECT\n      CASE\n        WHEN country_region = 'US' THEN 'United States'\n        WHEN country_region = 'Iran' THEN 'Iran, Islamic Rep.'\n        ELSE country_region\n      END AS country,\n      SUM(confirmed) AS total_confirmed_cases\n    FROM\n      `bigquery-public-data.covid19_jhu_csse.summary`\n    WHERE\n      date = '2020-04-20'\n      AND country_region IN ('US', 'France', 'China', 'Italy', 'Spain', 'Germany', 'Iran')\n    GROUP BY\n      country\n  ) AS c\nJOIN\n  (\n    SELECT\n      country_name AS country,\n      SUM(value) AS population\n    FROM\n      `bigquery-public-data.world_bank_wdi.indicators_data`\n    WHERE\n      indicator_code = 'SP.POP.TOTL'\n      AND year = 2020\n    GROUP BY\n      country_name\n  ) AS p\nON\n  c.country = p.country\nORDER BY\n  cases_per_100k DESC"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: covid19_nyt\nQuestion: Analyze daily new COVID-19 case counts from March to May 2020, identifying the top five states by daily increases. Please compile a ranking based on how often each state appears in these daily top fives. Then, examine the state that ranks fourth overall and identify its top five counties based on their frequency of appearing in the daily top five new case counts."}, {"role": "assistant", "content": "WITH StateCases AS (\n    SELECT\n        b.state_name,\n        b.date,\n        b.confirmed_cases - a.confirmed_cases AS daily_new_cases\n    FROM \n        (SELECT\n            state_name,\n            state_fips_code,\n            confirmed_cases,\n            DATE_ADD(date, INTERVAL 1 DAY) AS date_shift\n        FROM\n            `bigquery-public-data.covid19_nyt.us_states`\n        WHERE\n            date >= '2020-02-29' AND date <= '2020-05-30'\n        ) a\n    JOIN\n        `bigquery-public-data.covid19_nyt.us_states` b \n        ON a.state_fips_code = b.state_fips_code AND a.date_shift = b.date\n    WHERE\n        b.date >= '2020-03-01' AND b.date <= '2020-05-31'\n),\nRankedStatesPerDay AS (\n    SELECT\n        state_name,\n        date,\n        daily_new_cases,\n        RANK() OVER (PARTITION BY date ORDER BY daily_new_cases DESC) as rank\n    FROM\n        StateCases\n),\nTopStates AS (\n    SELECT\n        state_name,\n        COUNT(*) AS appearance_count\n    FROM\n        RankedStatesPerDay\n    WHERE\n        rank <= 5\n    GROUP BY\n        state_name\n    ORDER BY\n        appearance_count DESC\n),\nFourthState AS (\n    SELECT\n        state_name\n    FROM\n        TopStates\n    LIMIT 1\n    OFFSET 3\n),\nCountyCases AS (\n    SELECT\n        b.county,\n        b.date,\n        b.confirmed_cases - a.confirmed_cases AS daily_new_cases\n    FROM \n        (SELECT\n            county,\n            county_fips_code,\n            confirmed_cases,\n            DATE_ADD(date, INTERVAL 1 DAY) AS date_shift\n        FROM\n            `bigquery-public-data.covid19_nyt.us_counties`\n        WHERE\n            date >= '2020-02-29' AND date <= '2020-05-30'\n        ) a\n    JOIN\n        `bigquery-public-data.covid19_nyt.us_counties` b \n        ON a.county_fips_code = b.county_fips_code AND a.date_shift = b.date\n    WHERE\n        b.date >= '2020-03-01' AND b.date <= '2020-05-31'\n        AND b.state_name = (SELECT state_name FROM FourthState)\n),\nRankedCountiesPerDay AS (\n    SELECT\n        county,\n        date,\n        daily_new_cases,\n        RANK() OVER (PARTITION BY date ORDER BY daily_new_cases DESC) as rank\n    FROM\n        CountyCases\n),\nTopCounties AS (\n    SELECT\n        county,\n        COUNT(*) AS appearance_count\n    FROM\n        RankedCountiesPerDay\n    WHERE\n        rank <= 5\n    GROUP BY\n        county\n    ORDER BY\n        appearance_count DESC\n    LIMIT 5\n)\nSELECT\n    county\nFROM\n    TopCounties;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: covid19_symptom_search\nQuestion: Please calculate the overall percentage change in the average weekly search frequency for the symptom 'Anosmia' across the five New York City counties\u2014Bronx County, Queens County, Kings County, New York County, and Richmond County\u2014by comparing the combined data from January 1, 2019, through December 31, 2019, with the combined data from January 1, 2020, through December 31, 2020."}, {"role": "assistant", "content": "SELECT\n  table_2019.avg_symptom_Anosmia_2019,\n  table_2020.avg_symptom_Anosmia_2020,\n  ((table_2020.avg_symptom_Anosmia_2020 - table_2019.avg_symptom_Anosmia_2019) / table_2019.avg_symptom_Anosmia_2019) * 100 AS avg_increase\nFROM (\n  SELECT\n    AVG(SAFE_CAST(symptom_Anosmia AS FLOAT64)) AS avg_symptom_Anosmia_2020\n  FROM\n    `bigquery-public-data.covid19_symptom_search.symptom_search_sub_region_2_weekly`\n  WHERE\n    sub_region_1 = \"New York\"\n    AND sub_region_2 IN (\"Bronx County\", \"Queens County\", \"Kings County\", \"New York County\", \"Richmond County\")\n    AND date >= '2020-01-01'\n    AND date < '2021-01-01'\n) AS table_2020,\n(\n  SELECT\n    AVG(SAFE_CAST(symptom_Anosmia AS FLOAT64)) AS avg_symptom_Anosmia_2019\n  FROM\n    `bigquery-public-data.covid19_symptom_search.symptom_search_sub_region_2_weekly`\n  WHERE\n    sub_region_1 = \"New York\"\n    AND sub_region_2 IN (\"Bronx County\", \"Queens County\", \"Kings County\", \"New York County\", \"Richmond County\")\n    AND date >= '2019-01-01'\n    AND date < '2020-01-01'\n) AS table_2019"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: covid19_symptom_search\nQuestion: Please calculate the average levels of anxiety and depression symptoms from the weekly country data for the United States during the periods from January 1, 2019, to January 1, 2020, and from January 1, 2020, to January 1, 2021. Then, compute the percentage increase in these average symptom levels from the 2019 period to the 2020 period."}, {"role": "assistant", "content": "SELECT\n  table_2019.avg_symptom_Anxiety_2019,\n  table_2020.avg_symptom_Anxiety_2020,\n  ((table_2020.avg_symptom_Anxiety_2020 - table_2019.avg_symptom_Anxiety_2019)/table_2019.avg_symptom_Anxiety_2019) * 100 AS percent_increase_anxiety,\n  table_2019.avg_symptom_Depression_2019,\n  table_2020.avg_symptom_Depression_2020,\n  ((table_2020.avg_symptom_Depression_2020 - table_2019.avg_symptom_Depression_2019)/table_2019.avg_symptom_Depression_2019) * 100 AS percent_increase_depression\nFROM (\n  SELECT\n    AVG(CAST(symptom_Anxiety AS FLOAT64)) AS avg_symptom_Anxiety_2020,\n    AVG(CAST(symptom_Depression AS FLOAT64)) AS avg_symptom_Depression_2020,\n  FROM\n    `bigquery-public-data.covid19_symptom_search.symptom_search_country_weekly`\n  WHERE\n    country_region_code = \"US\"\n    AND date >= '2020-01-01'\n    AND date <'2021-01-01') AS table_2020,\n  (\n  SELECT\n    AVG(CAST(symptom_Anxiety AS FLOAT64)) AS avg_symptom_Anxiety_2019,\n    AVG(CAST(symptom_Depression AS FLOAT64)) AS avg_symptom_Depression_2019,\n  FROM\n    `bigquery-public-data.covid19_symptom_search.symptom_search_country_weekly`\n  WHERE\n    country_region_code = \"US\"\n    AND date >= '2019-01-01'\n    AND date <'2020-01-01') AS table_2019"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: covid19_usa\nQuestion: Given the latest population estimates from the 2018 five-year American Community Survey, what is the number of vaccine sites per 1000 people for counties in California?"}, {"role": "assistant", "content": "WITH\n  num_vaccine_sites_per_county AS (\n  SELECT\n    facility_sub_region_1 AS us_state,\n    facility_sub_region_2 AS us_county,\n    facility_sub_region_2_code AS us_county_fips,\n    COUNT(DISTINCT facility_place_id) AS num_vaccine_sites\n  FROM\n    bigquery-public-data.covid19_vaccination_access.facility_boundary_us_all\n  WHERE\n    STARTS_WITH(facility_sub_region_2_code, \"06\")\n  GROUP BY\n    facility_sub_region_1,\n    facility_sub_region_2,\n    facility_sub_region_2_code ),\n  total_population_per_county AS (\n  SELECT\n    LEFT(geo_id, 5) AS us_county_fips,\n    ROUND(SUM(total_pop)) AS total_population\n  FROM\n    bigquery-public-data.census_bureau_acs.censustract_2018_5yr\n  WHERE\n    STARTS_WITH(LEFT(geo_id, 5), \"06\")\n  GROUP BY\n    LEFT(geo_id, 5) )\nSELECT\n  * EXCEPT(us_county_fips),\n  ROUND((num_vaccine_sites * 1000) / total_population, 2) AS sites_per_1k_ppl\nFROM\n  num_vaccine_sites_per_county\nINNER JOIN\n  total_population_per_county\nUSING\n  (us_county_fips)\nORDER BY\n  sites_per_1k_ppl ASC\nLIMIT\n  100;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: covid19_usa\nQuestion: Find the top three counties with populations over 50,000, using the 2020 5-year census data, that had the highest COVID-19 case fatality rates on August 27, 2020. For these counties, provide the name, state, median age, total population, number of confirmed COVID-19 cases per 100,000 people, number of deaths per 100,000 people, and the case fatality rate as a percentage"}, {"role": "assistant", "content": "WITH population_data AS (\n  SELECT\n    geo_id,\n    median_age,\n    total_pop\n  FROM\n    `bigquery-public-data.census_bureau_acs.county_2020_5yr`\n  WHERE\n    total_pop > 50000\n),\ncovid_data AS (\n  SELECT\n    county_fips_code,\n    county_name,\n    state,\n    SUM(confirmed_cases) AS total_cases,\n    SUM(deaths) AS total_deaths\n  FROM\n    `bigquery-public-data.covid19_usafacts.summary`\n  WHERE\n    date = '2020-08-27'\n  GROUP BY\n    county_fips_code, county_name, state\n)\nSELECT\n  covid.county_name,\n  covid.state,\n  pop.median_age,\n  pop.total_pop,\n  (covid.total_cases / pop.total_pop * 100000) AS confirmed_cases_per_100000,\n  (covid.total_deaths / pop.total_pop * 100000) AS deaths_per_100000,\n  (covid.total_deaths / covid.total_cases * 100) AS case_fatality_rate\nFROM\n  covid_data covid\nJOIN\n  population_data pop ON covid.county_fips_code = pop.geo_id\nORDER BY\n  case_fatality_rate DESC\nLIMIT 3;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: census_bureau_international\nQuestion: Which top 3 countries had the highest net migration in 2017 among those with an area greater than 500 square kilometers? And what are their migration rates?"}, {"role": "assistant", "content": "WITH results AS (\n    SELECT\n        growth.country_name,\n        growth.net_migration,\n        CAST(area.country_area as INT64) as country_area\n    FROM (\n        SELECT\n            country_name,\n            net_migration,\n            country_code\n        FROM\n            `bigquery-public-data.census_bureau_international.birth_death_growth_rates`\n        WHERE\n            year = 2017\n    ) growth\n    INNER JOIN (\n        SELECT\n            country_area,\n            country_code\n        FROM\n            `bigquery-public-data.census_bureau_international.country_names_area`\n        WHERE\n            country_area > 500\n    ) area\n    ON\n        growth.country_code = area.country_code\n    ORDER BY\n        net_migration DESC\n    LIMIT 3\n)\nSELECT country_name, net_migration\nFROM results;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: census_bureau_acs_1\nQuestion: Can you find the census tracts in the 36047 area that are among the top 20 for the largest percentage increases in population from 2011 to 2018, are also among the top 20 for the largest absolute increases in median income during the same period, and had over 1,000 residents in each of those years?"}, {"role": "assistant", "content": "WITH population_change AS (\n    SELECT\n        a.geo_id,\n        a.total_pop AS pop_2011,\n        b.total_pop AS pop_2018,\n        ((b.total_pop - a.total_pop) / a.total_pop) * 100 AS population_change_percentage\n    FROM\n        bigquery-public-data.census_bureau_acs.censustract_2011_5yr a\n    JOIN\n        bigquery-public-data.census_bureau_acs.censustract_2018_5yr b\n    ON\n        a.geo_id = b.geo_id\n    WHERE \n        a.total_pop > 1000\n        AND b.total_pop > 1000\n        AND a.geo_id LIKE '36047%'\n        AND b.geo_id LIKE '36047%'\n    ORDER BY \n        population_change_percentage DESC\n    LIMIT 20\n),\n\nacs_2018 AS (\n    SELECT \n        geo_id, \n        median_income AS median_income_2018\n    FROM \n        bigquery-public-data.census_bureau_acs.censustract_2018_5yr  \n    WHERE \n        geo_id LIKE '36047%'\n        AND total_pop > 1000\n),\n\nacs_2011 AS (\n    SELECT \n        geo_id, \n        median_income AS median_income_2011\n    FROM \n        bigquery-public-data.census_bureau_acs.censustract_2011_5yr \n    WHERE \n        geo_id LIKE '36047%'\n    AND total_pop > 1000\n),\n\nacs_diff AS (\n    SELECT\n        a18.geo_id, \n        a18.median_income_2018, \n        a11.median_income_2011,\n        (a18.median_income_2018 - a11.median_income_2011) AS median_income_diff\n    FROM \n        acs_2018 a18\n    JOIN \n        acs_2011 a11\n        ON a18.geo_id = a11.geo_id\n    WHERE \n        (a18.median_income_2018 - a11.median_income_2011) IS NOT NULL\n    ORDER BY \n        (a18.median_income_2018 - a11.median_income_2011) DESC\n    LIMIT 20\n),\n\ncommon_geoids AS (\n    SELECT population_change.geo_id\n    FROM population_change\n    JOIN acs_diff ON population_change.geo_id = acs_diff.geo_id\n)\n\nSELECT geo_id FROM common_geoids;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: census_bureau_acs_1\nQuestion: Which census tract has witnessed the largest increase in median income between 2015 and 2018 in California? Tell me the tract code."}, {"role": "assistant", "content": "WITH acs_2018 AS (\n    SELECT\n      geo_id,\n      median_income AS median_income_2018\n    FROM\n      `bigquery-public-data.census_bureau_acs.censustract_2018_5yr` \n),\nacs_2015 AS (\n    SELECT\n      geo_id,\n      median_income AS median_income_2015\n    FROM\n      `bigquery-public-data.census_bureau_acs.censustract_2015_5yr` ),\nacs_diff AS (\n    SELECT\n      a18.geo_id,\n      a18.median_income_2018,\n      a15.median_income_2015,\n      (a18.median_income_2018 - a15.median_income_2015) AS median_income_diff,\n    FROM\n      acs_2018 a18\n    JOIN\n      acs_2015 a15\n    ON\n      a18.geo_id = a15.geo_id\n),\nmax_geo_id AS (\n    SELECT\n      geo_id\n    FROM\n      acs_diff\n    WHERE\n      median_income_diff IS NOT NULL\n      AND acs_diff.geo_id in (\n        SELECT\n          geo_id\n        FROM\n          `bigquery-public-data.geo_census_tracts.census_tracts_california`\n      )\n    ORDER BY\n      median_income_diff DESC\n    LIMIT 1\n)\nSELECT\n    tracts.tract_ce as tract_code\nFROM\n    max_geo_id\nJOIN\n    `bigquery-public-data.geo_census_tracts.census_tracts_california` AS tracts\nON\n    max_geo_id.geo_id = tracts.geo_id;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: census_bureau_acs_1\nQuestion: Using the 2017 U.S. Census Tract data from the BigQuery public datasets, you need to proportionally allocate each tract's population and income to the zip codes based on the overlapping area between their geographic boundaries. Then, filter the results to include only those zip codes located within a 5-mile radius of a specific point in Washington State, with coordinates at latitude 47.685833\u00b0N and longitude -122.191667\u00b0W. Finally, calculate the total population and the average individual income for each zip code (rounded to one decimal place) and sort the results by the average individual income in descending order.\n\nExternal Knowledge: functions_st_intersects_area.md"}, {"role": "assistant", "content": "WITH all_zip_tract_join AS (\n  SELECT \n    zips.zip_code, \n    zips.functional_status as zip_functional_status,\n    tracts.tract_ce, \n    tracts.geo_id as tract_geo_id, \n    tracts.functional_status as tract_functional_status,\n    ST_Area(ST_Intersection(tracts.tract_geom, zips.zip_code_geom))\n        / ST_Area(tracts.tract_geom) as tract_pct_in_zip_code\n  FROM  \n    `bigquery-public-data.geo_census_tracts.us_census_tracts_national` tracts,\n    `bigquery-public-data.geo_us_boundaries.zip_codes` zips\n  WHERE \n    ST_Intersects(tracts.tract_geom, zips.zip_code_geom)\n),\nzip_tract_join AS (\n  SELECT * FROM all_zip_tract_join WHERE tract_pct_in_zip_code > 0\n),\ncensus_totals AS (\n  -- convert averages to additive totals\n  SELECT \n    geo_id,\n    total_pop,\n    total_pop * income_per_capita AS total_income \n  FROM \n    `bigquery-public-data.census_bureau_acs.censustract_2017_5yr` \n),\njoined AS ( \n  -- join with precomputed census/zip pairs,\n  -- compute zip's share of tract\n  SELECT \n    zip_code, \n    total_pop * tract_pct_in_zip_code    AS zip_pop,\n    total_income * tract_pct_in_zip_code AS zip_income\n  FROM census_totals c\n  JOIN zip_tract_join ztj\n  ON c.geo_id = ztj.tract_geo_id\n),\nsums AS ( \n  -- aggregate all \"pieces\" of zip code\n  SELECT\n    zip_code, \n    SUM(zip_pop) AS zip_pop,\n    SUM(zip_income) AS zip_total_inc\n  FROM joined \n  GROUP BY zip_code\n),\nzip_pop_income AS (\n    SELECT \n        zip_code, zip_pop, \n        -- convert to averages\n        zip_total_inc / zip_pop AS income_per_capita\n    FROM sums\n),\nzipcodes_within_distance as (\n    SELECT \n        zip_code, zip_code_geom\n    FROM \n        `bigquery-public-data.geo_us_boundaries.zip_codes`\n    WHERE\n        state_code = 'WA'  -- Washington state code\n        AND\n        ST_DWithin(\n            ST_GeogPoint(-122.191667, 47.685833),\n            zip_code_geom,\n            8046.72\n        )\n)\nselect \n  stats.zip_code,\n  ROUND(stats.zip_pop, 1) as zip_population,\n  ROUND(stats.income_per_capita, 1) as average_income\nfrom \n  zipcodes_within_distance area\njoin \n  zip_pop_income stats\non area.zip_code = stats.zip_code\nORDER BY\n    average_income DESC;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: ncaa_basketball\nQuestion: List the top 5 universities with the most seasons where they achieved the maximum wins in their respective NCAA basketball seasons between 1900-2000, showing each team's total number of such peak-performance seasons, while excluding entries with missing team names."}, {"role": "assistant", "content": "SELECT\n  team_name,\n  COUNT(*) AS top_performer_count\nFROM (\n  SELECT\n    DISTINCT c2.season,\n    c2.market AS team_name\n  FROM (\n    SELECT\n      season AS a,\n      MAX(wins) AS win_max\n    FROM\n      `bigquery-public-data.ncaa_basketball.mbb_historical_teams_seasons`\n    WHERE\n      season<=2000\n      AND season >=1900\n    GROUP BY\n      season ),\n    `bigquery-public-data.ncaa_basketball.mbb_historical_teams_seasons` c2\n  WHERE\n    win_max = c2.wins\n    AND a = c2.season\n    AND c2.market IS NOT NULL\n  ORDER BY\n    c2.season)\nGROUP BY\n  team_name\nORDER BY\n  top_performer_count DESC,\n  team_name\nLIMIT\n  5"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: ncaa_basketball\nQuestion: For the top five team markets with the highest number of distinct players who scored at least 15 points during the second period of games between 2010 and 2018, provide details of each game they played in NCAA basketball historical tournament matches during the same period, as specified in the data model document.\n\nExternal Knowledge: ncaa_data_model.md"}, {"role": "assistant", "content": "WITH top_teams AS (\n  SELECT\n    team_market\n  FROM (\n    SELECT\n      team_market,\n      player_id AS id,\n      SUM(points_scored)\n    FROM\n      `bigquery-public-data.ncaa_basketball.mbb_pbp_sr`\n    WHERE\n      season >= 2010 AND season <=2018 AND period = 2\n    GROUP BY\n      game_id,\n      team_market,\n      player_id\n    HAVING\n      SUM(points_scored) >= 15) C\n  GROUP BY\n    team_market\n  HAVING\n    COUNT(DISTINCT id) > 5\n  ORDER BY\n    COUNT(DISTINCT id) DESC\n  LIMIT 5\n)\n\n\nSELECT\n  season,\n  round,\n  days_from_epoch,\n  game_date,\n  day,\n  'win' AS label,\n  win_seed AS seed,\n  win_market AS market,\n  win_name AS name,\n  win_alias AS alias,\n  win_school_ncaa AS school_ncaa,\n  lose_seed AS opponent_seed,\n  lose_market AS opponent_market,\n  lose_name AS opponent_name,\n  lose_alias AS opponent_alias,\n  lose_school_ncaa AS opponent_school_ncaa\nFROM `bigquery-public-data.ncaa_basketball.mbb_historical_tournament_games`\nJOIN top_teams ON top_teams.team_market = win_market\nWHERE season >= 2010 AND season <=2018\n\nUNION ALL\n\nSELECT\n  season,\n  round,\n  days_from_epoch,\n  game_date,\n  day,\n  'loss' AS label,\n  lose_seed AS seed,\n  lose_market AS market,\n  lose_name AS name,\n  lose_alias AS alias,\n  lose_school_ncaa AS school_ncaa,\n  win_seed AS opponent_seed,\n  win_market AS opponent_market,\n  win_name AS opponent_name,\n  win_alias AS opponent_alias,\n  win_school_ncaa AS opponent_school_ncaa\nFROM `bigquery-public-data.ncaa_basketball.mbb_historical_tournament_games`\nJOIN top_teams ON top_teams.team_market = lose_market\nWHERE season >= 2010 AND season <=2018"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: ncaa_insights\nQuestion: Create a dataset by combining NCAA men's basketball tournament game outcomes from the 2014 season onwards, including both the historical tournament games and the 2018 tournament results, with the corresponding pace and efficiency performance metrics for each team and their opponents from the feature_engineering data. The dataset should include the season, game outcome labels (win or loss), team and opponent seeds, school names, pace and efficiency rankings, statistical values, and the differences between the team's and the opponent's metrics to enable a comprehensive analysis of team and opponent dynamics.\n\nExternal Knowledge: NCAA_Basketball_Tournament_SQL_Query_Variable_Guide.md"}, {"role": "assistant", "content": "WITH outcomes AS (\nSELECT\n\n  season, # 1994\n  \"win\" AS label, # our label\n  win_seed AS seed, # ranking # this time without seed even\n  win_school_ncaa AS school_ncaa,\n  lose_seed AS opponent_seed, # ranking\n  lose_school_ncaa AS opponent_school_ncaa\nFROM `data-to-insights.ncaa.mbb_historical_tournament_games` t\nWHERE season >= 2014\nUNION ALL\n\nSELECT\n\n  season, # 1994\n  \"loss\" AS label, # our label\n  lose_seed AS seed, # ranking\n  lose_school_ncaa AS school_ncaa,\n  win_seed AS opponent_seed, # ranking\n  win_school_ncaa AS opponent_school_ncaa\nFROM\n`data-to-insights.ncaa.mbb_historical_tournament_games` t\nWHERE season >= 2014\nUNION ALL\n\nSELECT\n  season,\n  label,\n  seed,\n  school_ncaa,\n  opponent_seed,\n  opponent_school_ncaa\nFROM\n  `data-to-insights.ncaa.2018_tournament_results`\n)\nSELECT\no.season,\nlabel,\n  seed,\n  school_ncaa,\n  team.pace_rank,\n  team.poss_40min,\n  team.pace_rating,\n  team.efficiency_rank,\n  team.pts_100poss,\n  team.efficiency_rating,\n  opponent_seed,\n  opponent_school_ncaa,\n  opp.pace_rank AS opp_pace_rank,\n  opp.poss_40min AS opp_poss_40min,\n  opp.pace_rating AS opp_pace_rating,\n  opp.efficiency_rank AS opp_efficiency_rank,\n  opp.pts_100poss AS opp_pts_100poss,\n  opp.efficiency_rating AS opp_efficiency_rating,\n  opp.pace_rank - team.pace_rank AS pace_rank_diff,\n  opp.poss_40min - team.poss_40min AS pace_stat_diff,\n  opp.pace_rating - team.pace_rating AS pace_rating_diff,\n  opp.efficiency_rank - team.efficiency_rank AS eff_rank_diff,\n  opp.pts_100poss - team.pts_100poss AS eff_stat_diff,\n  opp.efficiency_rating - team.efficiency_rating AS eff_rating_diff\nFROM outcomes AS o\nLEFT JOIN `data-to-insights.ncaa.feature_engineering` AS team\nON o.school_ncaa = team.team AND o.season = team.season\nLEFT JOIN `data-to-insights.ncaa.feature_engineering` AS opp\nON o.opponent_school_ncaa = opp.team AND o.season = opp.season"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: bls\nQuestion: Which county in Utah experienced the greatest percentage increase in construction employment from 2000 to 2018, calculated by averaging the employment levels during the third month of each quarter in those years? What is the corresponding percentage increase?"}, {"role": "assistant", "content": "WITH utah_code AS (\n  SELECT DISTINCT geo_id\n  FROM bigquery-public-data.geo_us_boundaries.states\n  WHERE state_name = 'Utah'\n),\ne2000 as(\n  SELECT\n    AVG(month3_emplvl_23_construction) AS construction_employees_2000,\n    geoid\n  FROM\n    `bigquery-public-data.bls_qcew.2000_*`\n  WHERE\n    geoid LIKE CONCAT((SELECT geo_id FROM utah_code), '%')\n  GROUP BY\n    geoid),\n\ne2018 AS (\n  SELECT\n    AVG(month3_emplvl_23_construction) AS construction_employees_2018,\n    geoid,\n  FROM\n    `bigquery-public-data.bls_qcew.2018_*` e2018\n  WHERE\n    geoid LIKE CONCAT((SELECT geo_id FROM utah_code), '%')\n  GROUP BY\n    geoid)\n\nSELECT\n  c.county_name AS county,\n  (construction_employees_2018 - construction_employees_2000) / construction_employees_2000 * 100 AS increase_rate\nFROM\n  e2000\nJOIN\n  e2018 USING (geoid)\nJOIN \n  `bigquery-public-data.geo_us_boundaries.counties` c ON c.geo_id = e2018.geoid\nWHERE\n  c.state_fips_code = (SELECT geo_id FROM utah_code)\nORDER BY\n  increase_rate desc\nLIMIT 1"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: bls\nQuestion: Between 1998 and 2017, for Allegheny County in the Pittsburgh area, did the average annual wages for all industries keep pace with the inflation of all consumer items, and what were the respective percentage growth rates (to two decimal places) for wages and the CPI over that period?"}, {"role": "assistant", "content": "WITH geo AS (\n  SELECT DISTINCT geo_id\n  FROM `bigquery-public-data.geo_us_boundaries.counties`\n  WHERE county_name = \"Allegheny\" \n),\navg_wage_1998 AS(\n  SELECT\n    ROUND(AVG(avg_wkly_wage_10_total_all_industries) * 52, 2) AS wages_1998\n  FROM\n    `bigquery-public-data.bls_qcew.1998*`\n  WHERE\n    geoid = (SELECT geo_id FROM geo) --Selecting Allgeheny County\n),\n    \navg_wage_2017 AS (\n  SELECT\n    ROUND(AVG(avg_wkly_wage_10_total_all_industries) * 52, 2) AS wages_2017\n  FROM\n    `bigquery-public-data.bls_qcew.2017*`\n  WHERE\n    geoid = (SELECT geo_id FROM geo) --Selecting Allgeheny County\n),\n\navg_cpi_1998 AS (\n  SELECT\n    AVG(value) AS cpi_1998\n  FROM\n    `bigquery-public-data.bls.cpi_u` c\n  WHERE\n    year = 1998\n    AND item_code in (\n      SELECT DISTINCT item_code FROM `bigquery-public-data.bls.cpi_u` WHERE LOWER(item_name) = \"all items\"\n    )\n    AND area_code = (\n      SELECT DISTINCT area_code FROM `bigquery-public-data.bls.cpi_u` WHERE area_name LIKE '%Pittsburgh%'\n    )\n), \n-- A104 is the code for Pittsburgh, PA\n-- SA0 is the code for all items\n    \navg_cpi_2017 AS(\n  SELECT\n    AVG(value) AS cpi_2017\n  FROM\n    `bigquery-public-data.bls.cpi_u` c\n  WHERE\n    year = 2017\n    AND item_code in (\n      SELECT DISTINCT item_code FROM `bigquery-public-data.bls.cpi_u` WHERE LOWER(item_name) = \"all items\"\n    )\n    AND area_code = (\n      SELECT DISTINCT area_code FROM `bigquery-public-data.bls.cpi_u` WHERE area_name LIKE '%Pittsburgh%'\n    )\n)\n-- A104 is the code for Pittsburgh, PA\n-- SA0 is the code for all items\n\nSELECT\n  ROUND((wages_2017 - wages_1998) / wages_1998 * 100, 2) AS wages_percent_change,\n  ROUND((cpi_2017 - cpi_1998) / cpi_1998 * 100, 2) AS cpi_percent_change\nFROM\n  avg_wage_2017,\n  avg_wage_1998,\n  avg_cpi_2017,\n  avg_cpi_1998"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: google_dei\nQuestion: Please calculate the growth rates for Asians, Black people, Latinx people, Native Americans, White people, US women, US men, global women, and global men from 2014 to 2024 concerning the overall workforce."}, {"role": "assistant", "content": "CREATE TEMP FUNCTION GrowthRate(end_value FLOAT64, begin_value FLOAT64)\nRETURNS FLOAT64\nAS ((end_value - begin_value) / begin_value);\n\nSELECT\n  GrowthRate(SUM(IF(report_year=2024, race_asian, 0)),\n             SUM(IF(report_year=2014, race_asian, 0))) AS race_asian_growth,\n  GrowthRate(SUM(IF(report_year=2024, race_black, 0)),\n             SUM(IF(report_year=2014, race_black, 0))) AS race_black_growth,\n  GrowthRate(SUM(IF(report_year=2024, race_hispanic_latinx, 0)),\n             SUM(IF(report_year=2014, race_hispanic_latinx, 0))) AS race_hispanic_growth,\n  GrowthRate(SUM(IF(report_year=2024, race_native_american, 0)),\n             SUM(IF(report_year=2014, race_native_american, 0))) AS race_native_american_growth,\n  GrowthRate(SUM(IF(report_year=2024, race_white, 0)),\n             SUM(IF(report_year=2014, race_white, 0))) AS race_white_growth,\n  GrowthRate(SUM(IF(report_year=2024, gender_us_women, 0)),\n             SUM(IF(report_year=2014, gender_us_women, 0))) AS gender_us_women_growth,\n  GrowthRate(SUM(IF(report_year=2024, gender_us_men, 0)),\n             SUM(IF(report_year=2014, gender_us_men, 0))) AS gender_us_men_growth,\n  GrowthRate(SUM(IF(report_year=2024, gender_global_women, 0)),\n             SUM(IF(report_year=2014, gender_global_women, 0))) AS gender_global_women_growth,\n  GrowthRate(SUM(IF(report_year=2024, gender_global_men, 0)),\n             SUM(IF(report_year=2014, gender_global_men, 0))) AS gender_global_men_growth\nFROM `bigquery-public-data.google_dei.dar_non_intersectional_representation`\nWHERE report_year IN (2014, 2024)\n  AND workforce = 'overall';"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: DEPS_DEV_V1\nQuestion: Considering only the latest release versions of NPM package, which packages are the top 8 most popular based on the Github star number, as well as their versions?"}, {"role": "assistant", "content": "WITH HighestReleases AS (\n    SELECT\n        HR.\"Name\",\n        HR.\"Version\"\n    FROM (\n        SELECT\n            \"Name\",\n            \"Version\",\n            ROW_NUMBER() OVER (\n                PARTITION BY \"Name\"\n                ORDER BY \n                    TO_NUMBER(PARSE_JSON(\"VersionInfo\"):\"Ordinal\") DESC\n            ) AS RowNumber\n        FROM\n            DEPS_DEV_V1.DEPS_DEV_V1.PACKAGEVERSIONS\n        WHERE\n            \"System\" = 'NPM'\n            AND TO_BOOLEAN(PARSE_JSON(\"VersionInfo\"):\"IsRelease\") = TRUE\n    ) AS HR\n    WHERE HR.RowNumber = 1\n),\nPVP AS (\n    SELECT\n        PVP.\"Name\", \n        PVP.\"Version\", \n        PVP.\"ProjectType\", \n        PVP.\"ProjectName\"\n    FROM\n        DEPS_DEV_V1.DEPS_DEV_V1.PACKAGEVERSIONTOPROJECT AS PVP\n    JOIN\n        HighestReleases AS HR\n    ON\n        PVP.\"Name\" = HR.\"Name\"\n        AND PVP.\"Version\" = HR.\"Version\"\n    WHERE\n        PVP.\"System\" = 'NPM'\n        AND PVP.\"ProjectType\" = 'GITHUB'\n)\nSELECT\n    PVP.\"Name\", \n    PVP.\"Version\"\nFROM\n    PVP\nJOIN\n    DEPS_DEV_V1.DEPS_DEV_V1.PROJECTS AS P\nON\n    PVP.\"ProjectType\" = P.\"Type\" \n    AND PVP.\"ProjectName\" = P.\"Name\"\nORDER BY \n    P.\"StarsCount\" DESC\nLIMIT 8;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: chicago\nQuestion: Calculate the minimum and maximum trip duration in minutes (rounded to the nearest whole number), total number of trips, and average fare for each of six equal quantile groups based on trip duration, considering only trips between 0 and 60 minutes."}, {"role": "assistant", "content": "SELECT\n  ROUND(MIN(trip_seconds) / 60, 0) AS min_minutes,\n  ROUND(MAX(trip_seconds) / 60, 0) AS max_minutes,\n  COUNT(*) AS total_trips,\n  AVG(fare) AS average_fare\nFROM (\n  SELECT\n    trip_seconds,\n    NTILE(6) OVER (ORDER BY trip_seconds) AS quantile,\n    fare\n  FROM\n    `bigquery-public-data.chicago_taxi_trips.taxi_trips`\n  WHERE\n    trip_seconds BETWEEN 0 AND 3600\n)\nGROUP BY\n  quantile\nORDER BY\n  min_minutes, max_minutes;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: chicago\nQuestion: Which three companies had the largest increase in trip numbers between two consecutive months in 2018?"}, {"role": "assistant", "content": "select company from\n            (select *,\n            row_number() over(partition by company order by month_o_month_calc desc) as rownum\n            from\n            (select *,\n            num_trips - lag(num_trips) over(partition by company order by month) as month_o_month_calc\n                from\n                (SELECT \n                company,\n                format_date(\"%Y-%m\", date_sub((cast(trip_start_timestamp as date)), interval 1 month)) as prev_month,\n                format_date(\"%Y-%m\", cast(trip_start_timestamp as date)) AS month,\n                count(1) AS num_trips\n                from `bigquery-public-data.chicago_taxi_trips.taxi_trips`\n                where extract(YEAR from trip_start_timestamp) = 2018\n                group by company, month, prev_month\n                order by company,month)\n            order by company, month_o_month_calc desc)\n            ) \n        where rownum = 1\n        order by month_o_month_calc desc, company \n        limit 3"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: chicago\nQuestion: Calculate the total number of trips and average fare (formatted to two decimal places) for ten equal-sized quantile groups. Create ten quantile groups by partitioning the trip duration dimension (from 1-50 minutes) into equal sets. Each group should represent a similar number of distinct minute values. Display each group's time range formatted as \"XXm to XXm\" (where the numbers are zero-padded to two digits), the total trips count, and the average fare. The time ranges should represent the minimum and maximum duration values within each quantile. Sort the results chronologically by time range. Use NTILE(10) to create the quantiles from the ordered trip durations."}, {"role": "assistant", "content": "SELECT\n  FORMAT('%02.0fm to %02.0fm', min_minutes, max_minutes) AS minutes_range,\n  SUM(trips) AS total_trips,\n  FORMAT('%3.2f', SUM(total_fare) / SUM(trips)) AS average_fare\nFROM (\n  SELECT\n    MIN(duration_in_minutes) OVER (quantiles) AS min_minutes,\n    MAX(duration_in_minutes) OVER (quantiles) AS max_minutes,\n    SUM(trips) AS trips,\n    SUM(total_fare) AS total_fare\n  FROM (\n    SELECT\n      ROUND(trip_seconds / 60) AS duration_in_minutes,\n      NTILE(10) OVER (ORDER BY trip_seconds / 60) AS quantile,\n      COUNT(1) AS trips,\n      SUM(fare) AS total_fare\n    FROM\n      `bigquery-public-data.chicago_taxi_trips.taxi_trips`\n    WHERE\n      ROUND(trip_seconds / 60) BETWEEN 1 AND 50\n    GROUP BY\n      trip_seconds,\n      duration_in_minutes )\n  GROUP BY\n    duration_in_minutes,\n    quantile\n  WINDOW quantiles AS (PARTITION BY quantile)\n  )\nGROUP BY\n  minutes_range\nORDER BY\n  Minutes_range"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: chicago\nQuestion: What is the highest number of motor vehicle theft incidents that occurred in any single month during 2016?"}, {"role": "assistant", "content": "SELECT\n  incidents AS highest_monthly_thefts\nFROM (\n  SELECT\n    year,\n    EXTRACT(MONTH FROM date) AS month,\n    COUNT(1) AS incidents,\n    RANK() OVER (PARTITION BY year ORDER BY COUNT(1) DESC) AS ranking\n  FROM\n    `bigquery-public-data.chicago_crime.crime`\n  WHERE\n    primary_type = 'MOTOR VEHICLE THEFT'\n    AND year = 2016\n  GROUP BY\n    year,\n    month\n)\nWHERE\n  ranking = 1\nORDER BY\n  year DESC\nLIMIT 1;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: chicago\nQuestion: For each year from 2010 to 2016, what is the highest number of motor thefts in one month?"}, {"role": "assistant", "content": "SELECT\n  year,\n  incidents\nFROM (\n  SELECT\n    year,\n    EXTRACT(MONTH\n    FROM\n      date) AS month,\n    COUNT(1) AS incidents,\n    RANK() OVER (PARTITION BY year ORDER BY COUNT(1) DESC) AS ranking\n  FROM\n    `bigquery-public-data.chicago_crime.crime`\n  WHERE\n    primary_type = 'MOTOR VEHICLE THEFT'\n    AND year BETWEEN 2010 AND 2016\n  GROUP BY\n    year,\n    month )\nWHERE\n  ranking = 1\nORDER BY\n  year ASC"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: open_targets_genetics_1\nQuestion: Find the average, variance, max-min difference, and the QTL source(right study) of the maximum log2(h4/h3) for data where right gene id is \"ENSG00000169174\", h4 > 0.8, h3 < 0.02, reported trait includes \"lesterol levels\", right biological feature is \"IPSC\", and the variant is '1_55029009_C_T'."}, {"role": "assistant", "content": "WITH coloc_stats AS (\n  SELECT\n    coloc.coloc_log2_h4_h3,\n    coloc.right_study AS qtl_source\n  FROM\n    `open-targets-genetics.genetics.variant_disease_coloc` AS coloc\n  JOIN\n    `open-targets-genetics.genetics.studies` AS studies\n  ON\n    coloc.left_study = studies.study_id\n  WHERE\n    coloc.right_gene_id = \"ENSG00000169174\"\n    AND coloc.coloc_h4 > 0.8\n    AND coloc.coloc_h3 < 0.02\n    AND studies.trait_reported LIKE \"%lesterol levels%\"\n    AND coloc.right_bio_feature = 'IPSC'\n    AND CONCAT(coloc.left_chrom, '_', coloc.left_pos, '_', coloc.left_ref, '_', coloc.left_alt) = '1_55029009_C_T'\n),\nmax_value AS (\n  SELECT\n    MAX(coloc_log2_h4_h3) AS max_log2_h4_h3\n  FROM\n    coloc_stats\n)\n\nSELECT\n  AVG(coloc_log2_h4_h3) AS average,\n  VAR_SAMP(coloc_log2_h4_h3) AS variance,\n  MAX(coloc_log2_h4_h3) - MIN(coloc_log2_h4_h3) AS max_min_difference,\n  (SELECT qtl_source FROM coloc_stats WHERE coloc_log2_h4_h3 = (SELECT max_log2_h4_h3 FROM max_value)) AS qtl_source_of_max\nFROM\n  coloc_stats;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: CYMBAL_INVESTMENTS\nQuestion: How much higher the average intrinsic value is for trades using the feeling-lucky strategy compared to those using the momentum strategy under long-side trades?"}, {"role": "assistant", "content": "WITH MomentumTrades AS (\n  SELECT\n    StrikePrice - LastPx AS priceDifference\n  FROM\n    `bigquery-public-data.cymbal_investments.trade_capture_report`\n  WHERE\n    SUBSTR(TargetCompID, 0, 4) = 'MOMO'\n    AND (SELECT Side FROM UNNEST(Sides)) = 'LONG'\n),\n\nFeelingLuckyTrades AS (\n  SELECT\n    StrikePrice - LastPx AS priceDifference\n  FROM\n    `bigquery-public-data.cymbal_investments.trade_capture_report`\n  WHERE\n    SUBSTR(TargetCompID, 0, 4) = 'LUCK'\n    AND (SELECT Side FROM UNNEST(Sides)) = 'LONG'\n)\n\nSELECT\n  AVG(FeelingLuckyTrades.priceDifference) - AVG(MomentumTrades.priceDifference) AS averageDifference \nFROM\n  MomentumTrades,\n  FeelingLuckyTrades"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: CYMBAL_INVESTMENTS\nQuestion: Please collect the information of the top 6 trade report with the highest closing prices. Refer to the document for all the information I want.\n\nExternal Knowledge: Trade_Capture_Report_Data_List.md"}, {"role": "assistant", "content": "SELECT\n  OrderID AS tradeID,\n  MaturityDate AS tradeTimestamp,\n  (\n    CASE SUBSTR(TargetCompID, 0, 4)\n      WHEN 'MOMO' THEN 'Momentum'\n      WHEN 'LUCK' THEN 'Feeling Lucky'\n      WHEN 'PRED' THEN 'Prediction'\n  END\n    ) AS algorithm,\n  Symbol AS symbol,\n  LastPx AS openPrice,\n  StrikePrice AS closePrice,\n  (\n  SELECT\n    Side\n  FROM\n    UNNEST(Sides)\n  ) AS tradeDirection,\n  (CASE (\n    SELECT\n      Side\n    FROM\n      UNNEST(Sides))\n      WHEN 'SHORT' THEN -1\n      WHEN 'LONG' THEN 1\n  END\n    ) AS tradeMultiplier\nFROM\n  `bigquery-public-data.cymbal_investments.trade_capture_report`cv\nORDER BY closePrice DESC\nLIMIT 6"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: gbif\nQuestion: Determine which year had the earliest date after January on which more than 10 sightings of Sterna paradisaea were recorded north of 40 degrees latitude. For each year, find the first day after January with over 10 sightings of this species in that region, and identify the year whose earliest such date is the earliest among all years."}, {"role": "assistant", "content": "WITH tenplus AS (\n  SELECT \n    year, \n    EXTRACT(DAYOFYEAR FROM DATE(eventdate)) AS dayofyear, \n    COUNT(*) AS count\n  FROM \n    bigquery-public-data.gbif.occurrences\n  WHERE \n    eventdate IS NOT NULL \n    AND species = 'Sterna paradisaea' \n    AND decimallatitude > 40.0 \n    AND month > 1\n  GROUP BY \n    year, \n    eventdate\n  HAVING \n    COUNT(*) > 10\n)\n\nSELECT \n  year AS year\nFROM \n  tenplus\nGROUP BY \n  year\nORDER BY \n  MIN(dayofyear)\nLIMIT 1;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: gnomAD\nQuestion: Identify which start positions are associated with missense variants in the BRCA1 gene on chromosome 17, where the reference base is 'C' and the alternate base is 'T'. Using data from the gnomAD v2.1.1 version."}, {"role": "assistant", "content": "WITH gene_region AS (\n  SELECT \n    MIN(start_position) AS start_pos, \n    MAX(end_position) AS end_pos\n  FROM `bigquery-public-data.gnomAD.v2_1_1_genomes__chr17` AS main_table\n  WHERE EXISTS (\n    SELECT 1 \n    FROM UNNEST(main_table.alternate_bases) AS alternate_bases\n    WHERE EXISTS (\n      SELECT 1 \n      FROM UNNEST(alternate_bases.vep) AS vep\n      WHERE vep.SYMBOL = 'BRCA1'\n    )\n  )\n)\n\n\nSELECT \n  DISTINCT start_position\nFROM `bigquery-public-data.gnomAD.v2_1_1_genomes__chr17` AS main_table,\n     UNNEST(main_table.alternate_bases) AS alternate_bases,\n     UNNEST(alternate_bases.vep) AS vep,\n     gene_region\nWHERE main_table.start_position >= gene_region.start_pos\n  AND main_table.start_position <= gene_region.end_pos\n  AND REGEXP_CONTAINS(vep.Consequence, r\"missense_variant\")\n  AND reference_bases = \"C\"\n  AND alternate_bases.alt = \"T\""}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: gnomAD\nQuestion: Generate summary statistics on genetic variants in the region between positions 55039447 and 55064852 on chromosome 1. This includes the number of variants, the total allele count, the total number of alleles, and distinct gene symbols (using Variant Effect Predictor, VEP, for gene annotation). Additionally, compute the density of mutations by dividing the length of the region by the number of variants.  Using data from the gnomAD v3 version."}, {"role": "assistant", "content": "WITH summary_stats AS (\n  SELECT\n    COUNT(1) AS num_variants,\n    SUM((SELECT alt.AC FROM UNNEST(alternate_bases) AS alt)) AS sum_AC,\n    SUM(AN) AS sum_AN,\n    -- Also include some information from Variant Effect Predictor (VEP).\n    STRING_AGG(DISTINCT (SELECT annot.symbol FROM UNNEST(alternate_bases) AS alt,\n                                               UNNEST(vep) AS annot LIMIT 1), ', ') AS genes\n  FROM bigquery-public-data.gnomAD.v3_genomes__chr1 AS main_table\n  WHERE start_position >= 55039447 AND start_position <= 55064852\n)\nSELECT\n  ROUND((55064852 - 55039447) / num_variants, 3) AS burden_of_mutation,\n  *\nFROM summary_stats;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: GOOGLE_TRENDS\nQuestion: Based on the most recent refresh date, identify the top-ranked rising search term for the week that is exactly one year prior to the latest available week in the dataset."}, {"role": "assistant", "content": "WITH LatestWeek AS (\n    SELECT\n        DATEADD(WEEK, -52, MAX(\"week\")) AS \"last_year_week\"\n    FROM\n        GOOGLE_TRENDS.GOOGLE_TRENDS.TOP_RISING_TERMS\n),\nLatestRefreshDate AS (\n    SELECT\n        MAX(\"refresh_date\") AS \"latest_refresh_date\"\n    FROM\n        GOOGLE_TRENDS.GOOGLE_TRENDS.TOP_RISING_TERMS\n),\nRankedTerms AS (\n    SELECT\n        \"term\",\n        \"week\",\n        CASE WHEN \"score\" IS NULL THEN NULL ELSE \"dma_name\" END AS \"dma_name\",\n        \"rank\",\n        \"score\",\n        ROW_NUMBER() OVER (\n            PARTITION BY \"term\", \"week\"\n            ORDER BY \"score\" DESC\n        ) AS rn\n    FROM\n        GOOGLE_TRENDS.GOOGLE_TRENDS.TOP_RISING_TERMS\n    WHERE\n        \"week\" = (SELECT \"last_year_week\" FROM LatestWeek)\n        AND \"refresh_date\" = (SELECT \"latest_refresh_date\" FROM LatestRefreshDate)\n)\n\nSELECT\n    \"term\"\nFROM\n    RankedTerms\nWHERE\n    rn = 1\nORDER BY\n    \"rank\"\nLIMIT 1;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: nhtsa_traffic_fatalities_plus\nQuestion: According to the 2015 and 2016 accident and driver distraction, and excluding cases where the driver\u2019s distraction status is recorded as 'Not Distracted,' 'Unknown if Distracted,' or 'Not Reported,' how many traffic accidents per 100,000 people were caused by driver distraction in each U.S. state for those two years, based on 2010 census population data, and which five states each year had the highest rates?"}, {"role": "assistant", "content": "SELECT * FROM\n(\nSELECT\n  '2015' AS year,\n  COUNT(a.consecutive_number) AS total,\n  a.state_name AS state,\n  c.state_pop AS population,\n  (COUNT(a.consecutive_number) / c.state_pop * 100000) AS rate_per_100000\nFROM\n  `bigquery-public-data.nhtsa_traffic_fatalities.accident_2015` a\nJOIN\n  `bigquery-public-data.nhtsa_traffic_fatalities.distract_2015` b\nON\n  a.consecutive_number = b.consecutive_number\nJOIN (\n  SELECT\n    SUM(d.population) AS state_pop,\n    e.state_name AS state\n  FROM\n    `bigquery-public-data.census_bureau_usa.population_by_zip_2010` d\n  JOIN\n    `bigquery-public-data.utility_us.zipcode_area` e\n  ON\n    d.zipcode = e.zipcode\n  GROUP BY\n    state ) c\nON\n  c.state = a.state_name\nWHERE\n  b.driver_distracted_by_name NOT IN ('Not Distracted', 'Unknown if Distracted', 'Not Reported')\nGROUP BY\n  state,\n  population,\n  c.state_pop\nORDER BY\n  rate_per_100000 DESC\nLIMIT 5\n)\nUNION ALL\n(\nSELECT\n  '2016' AS year,\n  COUNT(a.consecutive_number) AS total,\n  a.state_name AS state,\n  c.state_pop AS population,\n  (COUNT(a.consecutive_number) / c.state_pop * 100000) AS rate_per_100000\nFROM\n  `bigquery-public-data.nhtsa_traffic_fatalities.accident_2016` a\nJOIN\n  `bigquery-public-data.nhtsa_traffic_fatalities.distract_2016` b\nON\n  a.consecutive_number = b.consecutive_number\nJOIN (\n  SELECT\n    SUM(d.population) AS state_pop,\n    e.state_name AS state\n  FROM\n    `bigquery-public-data.census_bureau_usa.population_by_zip_2010` d\n  JOIN\n    `bigquery-public-data.utility_us.zipcode_area` e\n  ON\n    d.zipcode = e.zipcode\n  GROUP BY\n    state ) c\nON\n  c.state = a.state_name\nWHERE\n  b.driver_distracted_by_name NOT IN ('Not Distracted', 'Unknown if Distracted', 'Not Reported')\nGROUP BY\n  state,\n  population,\n  c.state_pop\nORDER BY\n  rate_per_100000 DESC\nLIMIT 5\n)"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: nhtsa_traffic_fatalities\nQuestion: Which top 3 states had the largest differences in the number of traffic accidents between rainy and clear weather during weekends in 2016? Please also provide the respective differences for each state."}, {"role": "assistant", "content": "WITH weekend_accidents AS (\n    SELECT\n        state_name,\n        CASE\n            WHEN atmospheric_conditions_1_name = 'Rain' THEN 'Rain'\n            WHEN atmospheric_conditions_1_name = 'Clear' THEN 'Clear'\n            ELSE 'Other'\n        END AS Weather_Condition,\n        COUNT(DISTINCT consecutive_number) AS num_accidents\n    FROM\n        `bigquery-public-data.nhtsa_traffic_fatalities.accident_2016`\n    WHERE\n        EXTRACT(DAYOFWEEK FROM timestamp_of_crash) IN (1, 7)  -- 1 = Sunday, 7 = Saturday\n        AND atmospheric_conditions_1_name IN ('Rain', 'Clear')\n    GROUP BY\n        state_name, Weather_Condition\n),\n\nweather_difference AS (\n    SELECT\n        state_name,\n        MAX(CASE WHEN Weather_Condition = 'Rain' THEN num_accidents ELSE 0 END) AS Rain_Accidents,\n        MAX(CASE WHEN Weather_Condition = 'Clear' THEN num_accidents ELSE 0 END) AS Clear_Accidents,\n        ABS(MAX(CASE WHEN Weather_Condition = 'Rain' THEN num_accidents ELSE 0 END) -\n            MAX(CASE WHEN Weather_Condition = 'Clear' THEN num_accidents ELSE 0 END)) AS Difference\n    FROM\n        weekend_accidents\n    GROUP BY\n        state_name\n)\n\nSELECT\n    state_name,\n    Difference\nFROM\n    weather_difference\nORDER BY\n    Difference DESC\nLIMIT 3;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: sdoh\nQuestion: What is the increasing amount of the average earnings per job between the years 2012 and 2017 for each geographic region in Massachusetts (indicated by \"MA\" at the end of GeoName)?"}, {"role": "assistant", "content": "WITH bea_2012 AS (\n  SELECT GeoFIPS, GeoName, Earnings_per_job_avg AS earnings_2012\n  FROM `bigquery-public-data.sdoh_bea_cainc30.fips`\n  WHERE Year='2012-01-01' AND ENDS_WITH(GeoName, \"MA\") IS TRUE\n),\n\nbea_2017 AS (\n  SELECT GeoFIPS, GeoName, Earnings_per_job_avg AS earnings_2017\n  FROM `bigquery-public-data.sdoh_bea_cainc30.fips`\n  WHERE Year='2017-01-01' AND ENDS_WITH(GeoName, \"MA\") IS TRUE\n),\n\nearnings_diff AS (\n  SELECT\n    bea_2017.GeoFIPS, bea_2017.GeoName, bea_2017.earnings_2017, bea_2012.earnings_2012, \n    (bea_2017.earnings_2017 - bea_2012.earnings_2012) AS earnings_change\n   FROM bea_2017 \n   JOIN bea_2012\n   ON bea_2017.GeoFIPS = bea_2012.GeoFIPS\n)\n \nSELECT * FROM earnings_diff WHERE earnings_change IS NOT NULL ORDER BY earnings_change DESC"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: sdoh\nQuestion: Identify the top 10 regions (counties) with the highest total number of SNAP-participating households, using the 2017 5-year ACS county-level data and SNAP enrollment data from January 1, 2017, excluding regions where the total SNAP participation is zero. For each of these regions, calculate the ratio of households earning under $20,000 to the total number of SNAP-participating households."}, {"role": "assistant", "content": "WITH acs_2017 AS (\n  SELECT geo_id, income_less_10000 AS i10, income_10000_14999 AS i15, income_15000_19999 AS i20\n  FROM `bigquery-public-data.census_bureau_acs.county_2017_5yr`\n ),\n\nsnap_2017_Jan AS (\n  SELECT FIPS, SNAP_All_Participation_Households AS snap_total\n  FROM `bigquery-public-data.sdoh_snap_enrollment.snap_enrollment`\n  WHERE Date = '2017-01-01'\n)\n\nSELECT acs_2017.geo_id, snap_2017_Jan.snap_total,\n(acs_2017.i10 + acs_2017.i15 + acs_2017.i20) As households_under_20,\n(acs_2017.i10 + acs_2017.i15 + acs_2017.i20)/snap_2017_Jan.snap_total As under_20_snap_ratio \nFROM acs_2017\nJOIN snap_2017_Jan\nON  acs_2017.geo_id = snap_2017_Jan.FIPS\nWHERE snap_2017_Jan.snap_total > 0\nORDER BY snap_2017_Jan.snap_total DESC\nLIMIT 10"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: sdoh\nQuestion: What is the change in the number of homeless veterans between 2012 and 2018 for each CoC region in New York that has data available in both years?"}, {"role": "assistant", "content": "WITH homeless_2012 AS (\n  SELECT Homeless_Veterans AS Vet12, CoC_Name  \n  FROM `bigquery-public-data.sdoh_hud_pit_homelessness.hud_pit_by_coc` \n  WHERE SUBSTR(CoC_Number,0,2) = \"NY\" AND Count_Year = 2012\n),\n \nhomeless_2018 AS (\n  SELECT Homeless_Veterans AS Vet18, CoC_Name  \n  FROM `bigquery-public-data.sdoh_hud_pit_homelessness.hud_pit_by_coc` \n  WHERE SUBSTR(CoC_Number,0,2) = \"NY\" AND Count_Year = 2018\n),\n \nveterans_change AS (\n  SELECT homeless_2012.COC_Name, Vet12, Vet18, Vet18 - Vet12 AS VetChange\n  FROM homeless_2018\n  JOIN homeless_2012\n  ON homeless_2018.CoC_Name = homeless_2012.CoC_Name\n)\n\nSELECT COC_Name, VetChange FROM veterans_change\nORDER BY CoC_Name;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: sdoh\nQuestion: Calculate the percentage change in the total number of unsheltered homeless people from 2015 to 2018 for each state by summing the counts over all Continuums of Care (CoCs) within each state. Then, determine the national average of these state percentage changes. Identify the five states whose percentage change is closest to this national average percentage change. Please provide the state abbreviations."}, {"role": "assistant", "content": "WITH homeless_2015 AS (\n  SELECT Unsheltered_Homeless AS U15, SUBSTR(CoC_Number, 0, 2) as State_Abbr\n  FROM `bigquery-public-data.sdoh_hud_pit_homelessness.hud_pit_by_coc`\n  WHERE Count_Year = 2015\n),\n \nhomeless_2018 AS (\n  SELECT Unsheltered_Homeless AS U18, SUBSTR(CoC_Number, 0, 2) as State_Abbr\n  FROM `bigquery-public-data.sdoh_hud_pit_homelessness.hud_pit_by_coc`\n  WHERE Count_Year = 2018\n),\n\nunsheltered_change AS (\n  SELECT homeless_2018.State_Abbr, \n         SUM(U15) AS Unsheltered_2015, \n         SUM(U18) AS Unsheltered_2018, \n         (SUM(U18) - SUM(U15)) / SUM(U15) * 100 AS Percent_Change\n  FROM homeless_2018\n  JOIN homeless_2015\n  ON homeless_2018.State_Abbr = homeless_2015.State_Abbr\n  GROUP BY State_Abbr\n),\n\naverage_change AS (\n  SELECT AVG(Percent_Change) AS Avg_Change\n  FROM unsheltered_change\n),\n\nclosest_to_avg AS (\n  SELECT State_Abbr\n  FROM unsheltered_change, average_change\n  ORDER BY ABS(Percent_Change - Avg_Change)\n  LIMIT 5\n)\n\nSELECT State_Abbr FROM closest_to_avg;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: sdoh\nQuestion: Please list the average number of prenatal weeks in 2018 for counties in Wisconsin where more than 5% of the employed population had commutes of 45-59 minutes in 2017."}, {"role": "assistant", "content": "WITH natality_2018 AS (\n  SELECT County_of_Residence_FIPS AS FIPS, Ave_Number_of_Prenatal_Wks AS Vist_Ave, County_of_Residence\n  FROM `bigquery-public-data.sdoh_cdc_wonder_natality.county_natality` \n  WHERE SUBSTR(County_of_Residence_FIPS, 0, 2) = \"55\" AND Year = '2018-01-01'\n),\n\nacs_2017 AS (\n  SELECT geo_id, commute_45_59_mins, employed_pop\n  FROM `bigquery-public-data.census_bureau_acs.county_2017_5yr`\n),\n\ncorr_tbl AS (\n  SELECT\n    n.County_of_Residence,\n    ROUND((a.commute_45_59_mins / a.employed_pop) * 100, 2) AS percent_high_travel,\n    n.Vist_Ave\n  FROM acs_2017 a\n  JOIN natality_2018 n\n  ON a.geo_id = n.FIPS\n)\n\nSELECT County_of_Residence, Vist_Ave\nFROM corr_tbl\nWHERE percent_high_travel > 5"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: sdoh\nQuestion: Count the number of counties that experienced an increase in unemployment from 2015 to 2018, using 5-year ACS data, and a decrease in dual-eligible enrollee counts between December 1, 2015, and December 1, 2018."}, {"role": "assistant", "content": "WITH acs_2018 AS (\n  SELECT geo_id, unemployed_pop AS unemployed_2018  \n  FROM `bigquery-public-data.census_bureau_acs.county_2018_5yr` \n),\n \nacs_2015 AS (\n  SELECT geo_id, unemployed_pop AS unemployed_2015  \n  FROM `bigquery-public-data.census_bureau_acs.county_2015_5yr` \n),\n \nunemployed_change AS (\n  SELECT\n    u18.unemployed_2018, u18.geo_id, u15.unemployed_2015,\n    (u18.unemployed_2018 - u15.unemployed_2015) AS u_change\n  FROM acs_2018 u18\n  JOIN acs_2015 u15\n  ON u18.geo_id = u15.geo_id\n),\n \nduals_Jan_2018 AS (\n  SELECT Public_Total AS duals_2018, County_Name, FIPS \n  FROM `bigquery-public-data.sdoh_cms_dual_eligible_enrollment.dual_eligible_enrollment_by_county_and_program` \n  WHERE Date = '2018-12-01'\n),\n\nduals_Jan_2015 AS (\n  SELECT Public_Total AS duals_2015, County_Name, FIPS\n  FROM `bigquery-public-data.sdoh_cms_dual_eligible_enrollment.dual_eligible_enrollment_by_county_and_program` \n  WHERE Date = '2015-12-01'\n),\n\nduals_change AS (\n  SELECT\n    d18.FIPS, d18.County_Name, d18.duals_2018, d15.duals_2015,\n    (d18.duals_2018 - d15.duals_2015) AS total_duals_diff\n  FROM duals_Jan_2018 d18\n  JOIN duals_Jan_2015 d15\n  ON d18.FIPS = d15.FIPS\n),\n \ncorr_tbl AS (\n  SELECT unemployed_change.geo_id, duals_change.County_Name, unemployed_change.u_change, duals_change.total_duals_diff\n  FROM unemployed_change\n  JOIN duals_change\n  ON unemployed_change.geo_id = duals_change.FIPS\n)\n\n\nSELECT COUNT(*)\nFROM corr_tbl\nWHERE\nu_change >0\nAND\ncorr_tbl.total_duals_diff < 0"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: sdoh\nQuestion: Could you assess the relationship between the poverty rates from the previous year's census data and the percentage of births without maternal morbidity for the years 2016 to 2018? Use only data for births where no maternal morbidity was reported and for each year, use the 5-year census data from the year before to compute the Pearson correlation coefficient"}, {"role": "assistant", "content": "WITH poverty_and_natality AS (\n  SELECT\n    EXTRACT(YEAR FROM n.Year) AS data_year,\n    p.geo_id AS county_fips,\n    (p.poverty / p.pop_determined_poverty_status) * 100 AS poverty_rate,\n    SUM(n.Births) AS total_births,\n    SUM(CASE WHEN n.Maternal_Morbidity_YN = 0 THEN n.Births ELSE 0 END) AS births_without_morbidity\n  FROM\n    `bigquery-public-data.census_bureau_acs.county_2015_5yr` p\n  JOIN\n    `bigquery-public-data.sdoh_cdc_wonder_natality.county_natality_by_maternal_morbidity` n\n  ON p.geo_id = n.County_of_Residence_FIPS\n  WHERE\n    p.pop_determined_poverty_status > 0 AND\n    EXTRACT(YEAR FROM n.Year) = 2016\n  GROUP BY\n    p.geo_id, p.poverty, p.pop_determined_poverty_status, EXTRACT(YEAR FROM n.Year)\n  UNION ALL\n  SELECT\n    EXTRACT(YEAR FROM n.Year) AS data_year,\n    p.geo_id AS county_fips,\n    (p.poverty / p.pop_determined_poverty_status) * 100 AS poverty_rate,\n    SUM(n.Births) AS total_births,\n    SUM(CASE WHEN n.Maternal_Morbidity_YN = 0 THEN n.Births ELSE 0 END) AS births_without_morbidity\n  FROM\n    `bigquery-public-data.census_bureau_acs.county_2016_5yr` p\n  JOIN\n    `bigquery-public-data.sdoh_cdc_wonder_natality.county_natality_by_maternal_morbidity` n\n  ON p.geo_id = n.County_of_Residence_FIPS\n  WHERE\n    p.pop_determined_poverty_status > 0 AND\n    EXTRACT(YEAR FROM n.Year) = 2017\n  GROUP BY\n    p.geo_id, p.poverty, p.pop_determined_poverty_status, EXTRACT(YEAR FROM n.Year)\n  UNION ALL\n  SELECT\n    EXTRACT(YEAR FROM n.Year) AS data_year,\n    p.geo_id AS county_fips,\n    (p.poverty / p.pop_determined_poverty_status) * 100 AS poverty_rate,\n    SUM(n.Births) AS total_births,\n    SUM(CASE WHEN n.Maternal_Morbidity_YN = 0 THEN n.Births ELSE 0 END) AS births_without_morbidity\n  FROM\n    `bigquery-public-data.census_bureau_acs.county_2017_5yr` p\n  JOIN\n    `bigquery-public-data.sdoh_cdc_wonder_natality.county_natality_by_maternal_morbidity` n\n  ON p.geo_id = n.County_of_Residence_FIPS\n  WHERE\n    p.pop_determined_poverty_status > 0 AND\n    EXTRACT(YEAR FROM n.Year) = 2018\n  GROUP BY\n    p.geo_id, p.poverty, p.pop_determined_poverty_status, EXTRACT(YEAR FROM n.Year)\n)\n\nSELECT\n  data_year,\n  CORR(poverty_rate, (births_without_morbidity / total_births) * 100) AS correlation_coefficient\nFROM\n  poverty_and_natality\nGROUP BY\n  data_year"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: openaq\nQuestion: Which three cities have the largest difference between their 1990 EPA PM2.5 measurements (using units_of_measure = 'Micrograms/cubic meter (LC)' and parameter_name = 'Acceptable PM2.5 AQI & Speciation Mass') and their 2020 OpenAQ PM2.5 measurements (where pollutant = 'pm25' based on the year extracted from the timestamp), with both datasets matched by latitude and longitude rounded to two decimals, and the difference ordered from greatest to least?"}, {"role": "assistant", "content": "SELECT\n  aq.city,\n  epa.arithmetic_mean,\n  aq.value,\n  aq.timestamp,\n  (epa.arithmetic_mean - aq.value)\nFROM\n  `bigquery-public-data.openaq.global_air_quality` AS aq\nJOIN\n  `bigquery-public-data.epa_historical_air_quality.air_quality_annual_summary` AS epa\nON\n  ROUND(aq.latitude, 2) = ROUND(epa.latitude, 2)\n  AND ROUND(aq.longitude, 2) = ROUND(epa.longitude, 2)\nWHERE\n  epa.units_of_measure = \"Micrograms/cubic meter (LC)\"\n  AND epa.parameter_name = \"Acceptable PM2.5 AQI & Speciation Mass\"\n  AND epa.year = 1990\n  AND aq.pollutant = \"pm25\"\n  AND EXTRACT(YEAR FROM aq.timestamp) = 2020\nORDER BY\n  (epa.arithmetic_mean - aq.value) DESC\nLIMIT 3"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: STACKOVERFLOW\nQuestion: How do the average reputation and number of badges vary among Stack Overflow users based on the number of complete years they have been members, considering only those who joined on or before October 1, 2021?"}, {"role": "assistant", "content": "WITH sub AS (\n  SELECT \n    \"users\".\"id\",\n    CAST(TO_TIMESTAMP(MAX(\"users\".\"creation_date\") / 1000000.0) AS DATE) AS \"user_creation_date\",  -- \u4f7f\u7528 MAX \u805a\u5408 creation_date \u5e76\u8f6c\u6362\u4e3a DATE\n    MAX(\"users\".\"reputation\") AS \"reputation\",  \n    SUM(CASE WHEN badges.\"user_id\" IS NULL THEN 0 ELSE 1 END) AS \"num_badges\"\n  FROM \"STACKOVERFLOW\".\"STACKOVERFLOW\".\"USERS\" \"users\"\n  LEFT JOIN \"STACKOVERFLOW\".\"STACKOVERFLOW\".\"BADGES\" badges\n    ON \"users\".\"id\" = badges.\"user_id\"\n  WHERE CAST(TO_TIMESTAMP(\"users\".\"creation_date\" / 1000000.0) AS DATE) <= DATE '2021-10-01'\n  GROUP BY \"users\".\"id\"\n)\n\nSELECT \n  DATEDIFF(YEAR, \"user_creation_date\", DATE '2021-10-01') AS \"user_tenure\",\n  COUNT(1) AS \"Num_Users\",\n  AVG(\"reputation\") AS \"Avg_Reputation\",\n  AVG(\"num_badges\") AS \"Avg_Num_Badges\"\nFROM sub\nGROUP BY \"user_tenure\"\nORDER BY \"user_tenure\";"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: stackoverflow\nQuestion: You need to determine which day of the week has the third highest percentage of questions on Stack Overflow that receive an answer within an hour. To do this, use the question creation date from the posts_questions table and the earliest answer creation date from the posts_answers table. Once you\u2019ve calculated the percentage of questions that get answered within an hour for each day, identify the day with the third highest percentage and report that percentage."}, {"role": "assistant", "content": "WITH first_answers AS (\n  SELECT\n    parent_id AS question_id,\n    MIN(creation_date) AS first_answer_date\n  FROM\n    `bigquery-public-data.stackoverflow.posts_answers`\n  GROUP BY\n    parent_id\n)\n\nSELECT\n  FORMAT_DATE('%A', DATE(q.creation_date)) AS question_day,\n  SUM(CASE WHEN f.first_answer_date IS NOT NULL AND TIMESTAMP_DIFF(f.first_answer_date, q.creation_date, MINUTE) <= 60 THEN 1 ELSE 0 END) * 100.0 / COUNT(*) AS percent_questions\nFROM\n  `bigquery-public-data.stackoverflow.posts_questions` q\nLEFT JOIN\n  first_answers f\nON\n  q.id = f.question_id\nGROUP BY\n  question_day\nORDER BY\n  percent_questions DESC\nLIMIT 1 OFFSET 2"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: stackoverflow\nQuestion: Please provide the display name of the user who has answered the most questions on Stack Overflow, considering only users with a reputation greater than 10."}, {"role": "assistant", "content": "WITH UserAnswers AS (\n  SELECT\n    owner_user_id AS answer_owner_id,\n    COUNT(id) AS answer_count\n  FROM bigquery-public-data.stackoverflow.posts_answers\n  WHERE owner_user_id IS NOT NULL\n  GROUP BY owner_user_id\n),\nDetailedUsers AS (\n  SELECT\n    id AS user_id,\n    display_name AS user_display_name,\n    reputation\n  FROM bigquery-public-data.stackoverflow.users\n  WHERE display_name IS NOT NULL AND reputation > 10\n),\nRankedUsers AS (\n  SELECT\n    u.user_display_name,\n    u.reputation,\n    a.answer_count,\n    ROW_NUMBER() OVER (ORDER BY a.answer_count DESC) AS rank\n  FROM DetailedUsers u\n  JOIN UserAnswers a ON u.user_id = a.answer_owner_id\n)\nSELECT\n  user_display_name,\nFROM RankedUsers\nWHERE rank = 1;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: stackoverflow\nQuestion: What is the highest number of answers received for a single Python 2 specific question on Stack Overflow, excluding any discussions that involve Python 3?"}, {"role": "assistant", "content": "WITH\n  python2_questions AS (\n    SELECT\n      q.id AS question_id,\n      q.title,\n      q.body AS question_body,\n      q.tags\n    FROM\n      `bigquery-public-data.stackoverflow.posts_questions` q\n    WHERE\n      (LOWER(q.tags) LIKE '%python-2%'\n      OR LOWER(q.tags) LIKE '%python-2.x%'\n      OR (\n        LOWER(q.title) LIKE '%python 2%'\n        OR LOWER(q.body) LIKE '%python 2%'\n        OR LOWER(q.title) LIKE '%python2%'\n        OR LOWER(q.body) LIKE '%python2%'\n      ))\n      AND (\n        LOWER(q.title) NOT LIKE '%python 3%'\n        AND LOWER(q.body) NOT LIKE '%python 3%'\n        AND LOWER(q.title) NOT LIKE '%python3%'\n        AND LOWER(q.body) NOT LIKE '%python3%'\n      )\n  )\n\nSELECT\n  COUNT(*) AS count_number\nFROM\n  python2_questions q\nLEFT JOIN\n  `bigquery-public-data.stackoverflow.posts_answers` a\nON\n  q.question_id = a.parent_id\nGROUP BY q.question_id\nORDER BY count_number DESC\nLIMIT 1"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: stackoverflow\nQuestion: Retrieve details of accepted answers to Stack Overflow questions posted in January 2016 that have tags including \"javascript\" and at least one of \"xss\", \"cross-site\", \"exploit\", or \"cybersecurity\"; the answers themselves must also have been posted in January 2016. For each accepted answer, include the answer's ID, the answerer's reputation, score, and comment count, along with the associated question's tags, score, answer count, the asker's reputation, view count, and comment count."}, {"role": "assistant", "content": "SELECT\n    answer.id AS a_id,\n    (SELECT users.reputation FROM `bigquery-public-data.stackoverflow.users` users\n        WHERE users.id = answer.owner_user_id) AS a_user_reputation,\n    answer.score AS a_score,\n    answer.comment_count AS answer_comment_count,\n    questions.tags as q_tags,\n    questions.score AS q_score,  \n    questions.answer_count AS answer_count, \n    (SELECT users.reputation FROM `bigquery-public-data.stackoverflow.users` users\n        WHERE users.id = questions.owner_user_id) AS q_user_reputation,\n    questions.view_count AS q_view_count,\n    questions.comment_count AS q_comment_count\nFROM\n   `bigquery-public-data.stackoverflow.posts_answers` AS answer \nLEFT JOIN\n   `bigquery-public-data.stackoverflow.posts_questions` AS questions\n      ON answer.parent_id = questions.id\nWHERE\n    answer.id = questions.accepted_answer_id\n    AND \n    (\n        questions.tags LIKE '%javascript%' AND\n        (questions.tags LIKE '%xss%' OR\n        questions.tags LIKE '%cross-site%' OR\n        questions.tags LIKE '%exploit%' OR\n        questions.tags LIKE '%cybersecurity%')\n    )\n    AND DATE(questions.creation_date) BETWEEN '2016-01-01' AND '2016-01-31'\n    AND DATE(answer.creation_date) BETWEEN '2016-01-01' AND '2016-01-31'"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: stackoverflow\nQuestion: What is the monthly proportion of Stack Overflow questions tagged with 'python' in the year 2022?"}, {"role": "assistant", "content": "WITH\n-- Get recent data\nRecentData AS (\n    SELECT\n        FORMAT_TIMESTAMP('%Y%m', creation_date) AS month_index,\n        tags\n    FROM\n        `bigquery-public-data.stackoverflow.posts_questions`\n    WHERE\n        EXTRACT(YEAR FROM DATE(creation_date)) = 2022\n),\n\n-- Monthly number of questions posted\nMonthlyQuestions AS (\n    SELECT\n        month_index,\n        COUNT(*) AS num_questions\n    FROM\n        RecentData\n    GROUP BY\n        month_index\n),\n\n-- Monthly number of questions posted with specific tags\nTaggedQuestions AS (\n    SELECT\n        month_index,\n        tag,\n        COUNT(*) AS num_tags\n    FROM\n        RecentData,\n        UNNEST(SPLIT(tags, '|')) AS tag\n    WHERE\n        tag IN ('python')\n    GROUP BY\n        month_index, tag\n)\n\nSELECT\n    a.month_index,\n    a.num_tags / b.num_questions AS proportion\nFROM\n    TaggedQuestions a\nLEFT JOIN\n    MonthlyQuestions b ON a.month_index = b.month_index\nORDER BY\n    a.month_index, proportion DESC;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: stackoverflow\nQuestion: From July 1, 2019 through December 31, 2019, for all users with IDs between 16712208 and 18712208 on Stack Overflow, retrieve the user ID and the tags of the relevant question for each of their contributions, including comments on both questions and answers, any answers they posted, and any questions they authored, making sure to correctly associate the comment or answer with its parent question\u2019s tags."}, {"role": "assistant", "content": "SELECT u_id, tags\nFROM (\n    -- select comments with tags from the post\n    SELECT cm.u_id, cm.creation_date, cm.text, pq.tags, \"comment\" as type\n    FROM (\n            SELECT a.parent_id as q_id, c.user_id as u_id, c.creation_date as creation_date, c.text as text\n            FROM `bigquery-public-data.stackoverflow.comments` as c\n            INNER JOIN `bigquery-public-data.stackoverflow.posts_answers` as a ON (a.id = c.post_id)\n            WHERE c.user_id BETWEEN 16712208 AND 18712208\n              AND DATE(c.creation_date) BETWEEN '2019-07-01' AND '2019-12-31'\n            \n            UNION ALL \n            \n            SELECT q.id as q_id, c.user_id as u_id, c.creation_date as creation_date, c.text as text\n            FROM `bigquery-public-data.stackoverflow.comments` as c\n            INNER JOIN `bigquery-public-data.stackoverflow.posts_questions` as q ON (q.id = c.post_id)\n            WHERE c.user_id BETWEEN 16712208 AND 18712208\n              AND DATE(c.creation_date) BETWEEN '2019-07-01' AND '2019-12-31'\n        ) as cm\n    INNER JOIN `bigquery-public-data.stackoverflow.posts_questions` as pq ON (pq.id = cm.q_id)\n        \n    UNION ALL\n    -- select answers with tags related to the post\n    SELECT pa.owner_user_id as u_id, pa.creation_date as creation_date, pa.body as text, pq.tags as tags, \"answer\" as type\n    FROM `bigquery-public-data.stackoverflow.posts_answers` as pa\n    LEFT OUTER JOIN `bigquery-public-data.stackoverflow.posts_questions` as pq ON pq.id = pa.parent_id\n    WHERE pa.owner_user_id BETWEEN 16712208 AND 18712208\n      AND DATE(pa.creation_date) BETWEEN '2019-07-01' AND '2019-12-31'\n    \n    UNION ALL\n    -- select posts\n    SELECT pq.owner_user_id as u_id, pq.creation_date as creation_date, pq.body as text, pq.tags as tags, \"question\" as type\n    FROM `bigquery-public-data.stackoverflow.posts_questions` as pq\n    WHERE pq.owner_user_id BETWEEN 16712208 AND 18712208\n      AND DATE(pq.creation_date) BETWEEN '2019-07-01' AND '2019-12-31'\n)\nORDER BY u_id, creation_date;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: stackoverflow\nQuestion: Retrieve the top 50 most viewed questions for each of the following Android-related tags on StackOverflow: 'android-layout', 'android-activity', 'android-intent', 'android-edittext', 'android-fragments', 'android-recyclerview', 'listview', 'android-actionbar', 'google-maps', and 'android-asynctask'. Each question must contain the word 'how' in either its title or body and must not contain any of the following troubleshooting terms in either its title or body: 'fail', 'problem', 'error', 'wrong', 'fix', 'bug', 'issue', 'solve', or 'trouble'. Only include tags that have at least 50 questions meeting these criteria, and for each such tag, select the top 50 questions ranked by view count."}, {"role": "assistant", "content": "WITH\ntags_to_use AS (\n    SELECT tag, idx\n    FROM UNNEST([\n        'android-layout', \n        'android-activity', \n        'android-intent', \n        'android-edittext', \n        'android-fragments', \n        'android-recyclerview', \n        'listview', \n        'android-actionbar', \n        'google-maps', \n        'android-asynctask'\n    ]) AS tag WITH OFFSET idx\n),\nandroid_how_to_questions AS (\n    SELECT\n        PQ.*\n    FROM\n        bigquery-public-data.stackoverflow.posts_questions PQ\n    WHERE\n        EXISTS (\n            SELECT 1\n            FROM UNNEST(SPLIT(PQ.tags, '|')) tag\n            WHERE tag IN (SELECT tag FROM tags_to_use)\n        )\n        AND (LOWER(PQ.title) LIKE '%how%' OR LOWER(PQ.body) LIKE '%how%')\n        AND NOT (LOWER(PQ.title) LIKE '%fail%' OR LOWER(PQ.title) LIKE '%problem%' OR LOWER(PQ.title) LIKE '%error%'\n                 OR LOWER(PQ.title) LIKE '%wrong%' OR LOWER(PQ.title) LIKE '%fix%' OR LOWER(PQ.title) LIKE '%bug%'\n                 OR LOWER(PQ.title) LIKE '%issue%' OR LOWER(PQ.title) LIKE '%solve%' OR LOWER(PQ.title) LIKE '%trouble%')\n        AND NOT (LOWER(PQ.body) LIKE '%fail%' OR LOWER(PQ.body) LIKE '%problem%' OR LOWER(PQ.body) LIKE '%error%'\n                 OR LOWER(PQ.body) LIKE '%wrong%' OR LOWER(PQ.body) LIKE '%fix%' OR LOWER(PQ.body) LIKE '%bug%'\n                 OR LOWER(PQ.body) LIKE '%issue%' OR LOWER(PQ.body) LIKE '%solve%' OR LOWER(PQ.body) LIKE '%trouble%')\n),\nquestions_with_tag_rankings AS (\n    SELECT\n        T.id AS tag_id,\n        TTU.idx AS tag_offset,\n        T.tag_name,\n        T.wiki_post_id AS tag_wiki_post_id,\n        Q.id AS question_id,\n        Q.title,\n        Q.tags,\n        Q.view_count,\n        RANK() OVER (PARTITION BY T.id ORDER BY Q.view_count DESC) AS question_view_count_rank,\n        COUNT(*) OVER (PARTITION BY T.id) AS total_valid_questions\n    FROM\n        bigquery-public-data.stackoverflow.tags T\n    INNER JOIN\n        tags_to_use TTU ON T.tag_name = TTU.tag\n    INNER JOIN\n        android_how_to_questions Q ON T.tag_name IN UNNEST(SPLIT(Q.tags, '|'))\n)\nSELECT\n    question_id\nFROM\n    questions_with_tag_rankings\nWHERE\n    question_view_count_rank <= 50 AND total_valid_questions >= 50\nORDER BY\n    tag_offset ASC, question_view_count_rank ASC;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: stackoverflow\nQuestion: What is the title of the most viewed \"how\" question related to Android development on StackOverflow, across specified tags such as 'android-layout', 'android-activity', 'android-intent', and others"}, {"role": "assistant", "content": "WITH\ntags_to_use AS (\n    SELECT tag, idx\n    FROM UNNEST([\n        'android-layout', \n        'android-activity', \n        'android-intent', \n        'android-edittext', \n        'android-fragments', \n        'android-recyclerview', \n        'listview', \n        'android-actionbar', \n        'google-maps', \n        'android-asynctask'\n    ]) AS tag WITH OFFSET idx\n),\nandroid_how_to_questions AS (\n    SELECT\n        PQ.*\n    FROM\n        `bigquery-public-data.stackoverflow.posts_questions` PQ\n    WHERE\n        EXISTS (\n            SELECT 1\n            FROM UNNEST(SPLIT(PQ.tags, '|')) tag\n            WHERE tag IN (SELECT tag FROM tags_to_use)\n        )\n        AND (LOWER(PQ.title) LIKE '%how%' OR LOWER(PQ.body) LIKE '%how%')\n),\nmost_viewed_question AS (\n    SELECT\n        T.id AS tag_id,\n        T.tag_name,\n        Q.id AS question_id,\n        Q.title,\n        Q.tags,\n        Q.view_count\n    FROM\n        `bigquery-public-data.stackoverflow.tags` T\n    INNER JOIN\n        tags_to_use TTU ON T.tag_name = TTU.tag\n    INNER JOIN\n        android_how_to_questions Q ON T.tag_name IN UNNEST(SPLIT(Q.tags, '|'))\n    ORDER BY Q.view_count DESC\n    LIMIT 1\n)\nSELECT\n    title\nFROM\n    most_viewed_question;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: stackoverflow\nQuestion: Show the number of Stack Overflow questions asked each day of the week in 2021, and find out how many and what percentage of those were answered within one hour."}, {"role": "assistant", "content": "SELECT\n  Day_of_Week,\n  COUNT(1) AS Num_Questions,\n  SUM(answered_in_1h) AS Num_Answered_in_1H,\n  ROUND(100 * SUM(answered_in_1h) / COUNT(1),1) AS Percent_Answered_in_1H\nFROM\n(\n  SELECT\n    q.id AS question_id,\n    EXTRACT(DAYOFWEEK FROM q.creation_date) AS day_of_week,\n    MAX(IF(a.parent_id IS NOT NULL AND\n           (UNIX_SECONDS(a.creation_date)-UNIX_SECONDS(q.creation_date))/(60*60) <= 1, 1, 0)) AS answered_in_1h\n  FROM\n    `bigquery-public-data.stackoverflow.posts_questions` q\n  LEFT JOIN\n    `bigquery-public-data.stackoverflow.posts_answers` a\n  ON q.id = a.parent_id\n  WHERE EXTRACT(YEAR FROM a.creation_date) = 2020\n    AND EXTRACT(YEAR FROM q.creation_date) = 2020\n  GROUP BY question_id, day_of_week\n)\nGROUP BY\n  Day_of_Week\nORDER BY\n  Day_of_Week;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: stackoverflow\nQuestion: Retrieve the top 10 longest questions on Stack Overflow, measured by the length of their body text, where each question either has an accepted answer or has no accepted answer but has at least one answer with a score-to-view ratio exceeding 0.01. For each of these questions, include the reputation of the user who asked the question, the user's net votes (calculated as their total up_votes minus down_votes), and the total number of badges the user has earned."}, {"role": "assistant", "content": "WITH badge_counts AS (\n  SELECT\n    c.id,\n    COUNT(DISTINCT d.id) AS badge_number\n  FROM\n    `bigquery-public-data.stackoverflow.users` AS c\n  JOIN\n    `bigquery-public-data.stackoverflow.badges` AS d\n  ON\n    c.id = d.user_id\n  GROUP BY\n    c.id\n),\nlabeled_questions AS (\n  SELECT\n    a.id,\n    IF(\n      a.id IN (\n        SELECT DISTINCT b.id\n        FROM\n          `bigquery-public-data.stackoverflow.posts_answers` AS a\n        JOIN\n          `bigquery-public-data.stackoverflow.posts_questions` AS b\n        ON\n          a.parent_id = b.id\n        WHERE\n          b.accepted_answer_id IS NULL\n          AND a.score / b.view_count > 0.01\n      ) OR accepted_answer_id IS NOT NULL,\n      1,\n      0\n    ) AS label,\n    a.owner_user_id,\n    LENGTH(a.body) AS body_length\n  FROM\n    `bigquery-public-data.stackoverflow.posts_questions` AS a\n)\nSELECT\n  lq.id,\n  b.reputation,\n  b.up_votes - b.down_votes AS net_votes,\n  e.badge_number\nFROM\n  labeled_questions AS lq\nJOIN\n  `bigquery-public-data.stackoverflow.users` AS b\nON\n  lq.owner_user_id = b.id\nJOIN\n  badge_counts AS e\nON\n  b.id = e.id\nWHERE\n  lq.label = 1\nORDER BY\n  lq.body_length DESC\nLIMIT\n  10;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: fhir_synthea\nQuestion: Among all patients, how many individuals remain alive (i.e., with no recorded deceased.dateTime), have a diagnosis of either Diabetes or Hypertension, and are prescribed at least seven distinct active medications?"}, {"role": "assistant", "content": "With INFO AS (\nSELECT \n  MR.patientId, \n  P.last_name,\n  ARRAY_TO_STRING(P.first_name, \" \") AS First_name,\n  Condition.Codes, \n  Condition.Conditions,\n  MR.med_count AS COUNT_NUMBER\nFROM\n  (SELECT \n    id, \n    name[safe_offset(0)].family as last_name, \n    name[safe_offset(0)].given as first_name, \n    TIMESTAMP(deceased.dateTime) AS deceased_datetime \n  FROM `bigquery-public-data.fhir_synthea.patient`) AS P\nJOIN\n  (SELECT  subject.patientId as patientId, \n           COUNT(DISTINCT medication.codeableConcept.coding[safe_offset(0)].code) AS med_count\n   FROM    `bigquery-public-data.fhir_synthea.medication_request`\n   WHERE   status = 'active'\n   GROUP BY 1\n   ) AS MR\nON MR.patientId = P.id \nJOIN\n  (SELECT \n  PatientId, \n  STRING_AGG(DISTINCT condition_desc, \", \") AS Conditions, \n  STRING_AGG(DISTINCT condition_code, \", \") AS Codes\n  FROM(\n    SELECT \n      subject.patientId as PatientId, \n              code.coding[safe_offset(0)].code condition_code,\n              code.coding[safe_offset(0)].display condition_desc\n       FROM `bigquery-public-data.fhir_synthea.condition`\n       wHERE \n         code.coding[safe_offset(0)].display = 'Diabetes'\n         OR \n         code.coding[safe_offset(0)].display = 'Hypertension' \n    )\n  GROUP BY PatientId\n  ) AS Condition\nON MR.patientId = Condition.PatientId\nWHERE med_count >= 7 \nAND P.deceased_datetime is NULL /*only alive patients*/\nGROUP BY patientId, last_name, first_name, Condition.Codes, Condition.Conditions, MR.med_count\nORDER BY last_name\n)\n\nSELECT COUNT(*) FROM INFO"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: the_met\nQuestion: What are the titles, artist names, mediums, and original image URLs of objects with 'Photograph' in their names from the 'Photographs' department, created not by an unknown artist, with an object end date of 1839 or earlier?"}, {"role": "assistant", "content": "SELECT\n  o.artist_display_name,\n  o.title,\n  o.object_end_date,\n  o.medium,\n  i.original_image_url\nFROM (\n  SELECT\n    object_id,\n    title,\n    artist_display_name,\n    object_end_date,\n    medium\n  FROM\n    `bigquery-public-data.the_met.objects`\n  WHERE\n    department = \"Photographs\"\n    AND object_name LIKE \"%Photograph%\"\n    AND artist_display_name != \"Unknown\"\n    AND object_end_date <= 1839\n) o\nINNER JOIN (\n  SELECT\n    original_image_url,\n    object_id\n  FROM\n    `bigquery-public-data.the_met.images`\n) i\nON\n  o.object_id = i.object_id\nORDER BY\n  o.object_end_date\n;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: the_met\nQuestion: What are the top three most frequently associated labels with artworks from each historical period in The Met's collection, only considering labels linked to 500 or more artworks? Provide me with the period, label, and the associated count."}, {"role": "assistant", "content": "SELECT period, description, c FROM (\n  SELECT \na.period, \nb.description, \ncount(*) c, \nrow_number() over (partition by period order by count(*) desc) seqnum \n  FROM `bigquery-public-data.the_met.objects` a\n  JOIN (\n    SELECT \n        label.description as description, \n        object_id \n    FROM `bigquery-public-data.the_met.vision_api_data`, UNNEST(labelAnnotations) label\n  ) b\n  ON a.object_id = b.object_id\n  WHERE a.period is not null\n  group by 1,2\n)\nWHERE seqnum <= 3\nAND c >= 500 # only include labels that have 50 or more pieces associated with it\nORDER BY period, c desc;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: the_met\nQuestion: Retrieve the object id, title, and the formatted metadata date (as a string in 'YYYY-MM-DD' format) for objects in the \"The Libraries\" department where the cropConfidence is greater than 0.5, the object's title contains the word \"book\"."}, {"role": "assistant", "content": "SELECT \n  a.object_id,\n  a.title,\n  FORMAT_TIMESTAMP('%Y-%m-%d', a.metadata_date) AS formatted_metadata_date\nFROM `bigquery-public-data.the_met.objects` a\nJOIN (\n  SELECT object_id,\n         cropHints.confidence AS cropConfidence\n  FROM `bigquery-public-data.the_met.vision_api_data`, \n       UNNEST(cropHintsAnnotation.cropHints) cropHints\n) b\nON a.object_id = b.object_id\nWHERE a.department = \"The Libraries\"\nAND b.cropConfidence > 0.5\nAND a.title LIKE \"%book%\""}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: eclipse_megamovie\nQuestion: Find the user with the highest total clicks across all records from all available photo collections."}, {"role": "assistant", "content": "SELECT user\nFROM (\nSelect user\n      From `bigquery-public-data.eclipse_megamovie.photos_v_0_1`\n      UNION ALL\n      Select user\n      From`bigquery-public-data.eclipse_megamovie.photos_v_0_2`\n      UNION ALL\n      Select user\n      From`bigquery-public-data.eclipse_megamovie.photos_v_0_3`\n) \nGROUP BY user \nHAVING COUNT (user)=( \nSELECT MAX(mycount) \nFROM ( \nSELECT user, COUNT(user) mycount \nFROM (\nSelect user\n      From `bigquery-public-data.eclipse_megamovie.photos_v_0_1`\n      UNION ALL\n      Select user\n      From`bigquery-public-data.eclipse_megamovie.photos_v_0_2`\n      UNION ALL\n      Select user\n      From`bigquery-public-data.eclipse_megamovie.photos_v_0_3`\n)\nGROUP BY user))\nORDER BY COUNT(user) \nLIMIT 1"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: epa_historical_air_quality\nQuestion: Please calculate the monthly average levels of PM10, PM2.5 FRM, PM2.5 non-FRM, volatile organic emissions, SO2 (scaled by a factor of 10), and Lead (scaled by a factor of 100) air pollutants in California for the year 2020."}, {"role": "assistant", "content": "SELECT\n  pm10.month AS month,\n  pm10.avg AS pm10,\n  pm25_frm.avg AS pm25_frm,\n  pm25_nonfrm.avg AS pm25_nonfrm,\n  co.avg AS co,\n  so2.avg AS so2,\n  lead.avg AS lead\nFROM\n  (SELECT AVG(arithmetic_mean) AS avg, \n          EXTRACT(YEAR FROM date_local) AS year, \n          EXTRACT(MONTH FROM date_local) AS month\n   FROM `bigquery-public-data.epa_historical_air_quality.pm10_daily_summary`\n   WHERE state_name = 'California' AND EXTRACT(YEAR FROM date_local) = 2020\n   GROUP BY year, month) AS pm10\nJOIN\n  (SELECT AVG(arithmetic_mean) AS avg, \n          EXTRACT(YEAR FROM date_local) AS year, \n          EXTRACT(MONTH FROM date_local) AS month\n   FROM `bigquery-public-data.epa_historical_air_quality.pm25_frm_daily_summary`\n   WHERE state_name = 'California' AND EXTRACT(YEAR FROM date_local) = 2020\n   GROUP BY year, month) AS pm25_frm\nON pm10.year = pm25_frm.year AND pm10.month = pm25_frm.month\nJOIN\n  (SELECT AVG(arithmetic_mean) AS avg, \n          EXTRACT(YEAR FROM date_local) AS year, \n          EXTRACT(MONTH FROM date_local) AS month\n   FROM `bigquery-public-data.epa_historical_air_quality.pm25_nonfrm_daily_summary`\n   WHERE state_name = 'California' AND EXTRACT(YEAR FROM date_local) = 2020\n   GROUP BY year, month) AS pm25_nonfrm\nON pm10.year = pm25_nonfrm.year AND pm10.month = pm25_nonfrm.month\nJOIN\n  (SELECT AVG(arithmetic_mean) * 100 AS avg, \n          EXTRACT(YEAR FROM date_local) AS year, \n          EXTRACT(MONTH FROM date_local) AS month\n   FROM `bigquery-public-data.epa_historical_air_quality.lead_daily_summary`\n   WHERE state_name = 'California' AND EXTRACT(YEAR FROM date_local) = 2020\n   GROUP BY year, month) AS lead\nON pm10.year = lead.year AND pm10.month = lead.month\nJOIN\n  (SELECT AVG(arithmetic_mean) AS avg, \n          EXTRACT(YEAR FROM date_local) AS year, \n          EXTRACT(MONTH FROM date_local) AS month\n   FROM `bigquery-public-data.epa_historical_air_quality.voc_daily_summary`\n   WHERE state_name = 'California' AND EXTRACT(YEAR FROM date_local) = 2020\n   GROUP BY year, month) AS co\nON pm10.year = co.year AND pm10.month = co.month\nJOIN\n  (SELECT AVG(arithmetic_mean) * 10 AS avg, \n          EXTRACT(YEAR FROM date_local) AS year, \n          EXTRACT(MONTH FROM date_local) AS month\n   FROM `bigquery-public-data.epa_historical_air_quality.so2_daily_summary`\n   WHERE state_name = 'California' AND EXTRACT(YEAR FROM date_local) = 2020\n   GROUP BY year, month) AS so2\nON pm10.year = so2.year AND pm10.month = so2.month\nORDER BY\n  month;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: IDC\nQuestion: How large are the DICOM image files with SEG or RTSTRUCT modalities and the SOP Class UID \"1.2.840.10008.5.1.4.1.1.66.4\", when grouped by collection, study, and series IDs, if they have no references to other series, images, or sources? Can you also provide a viewer URL formatted as \"https://viewer.imaging.datacommons.cancer.gov/viewer/\" followed by the study ID, and list these sizes in kilobytes, sorted from largest to smallest?"}, {"role": "assistant", "content": "WITH seg_rtstruct AS (\n  SELECT\n    \"collection_id\",\n    \"StudyInstanceUID\",\n    \"SeriesInstanceUID\",\n    CONCAT('https://viewer.imaging.datacommons.cancer.gov/viewer/', \"StudyInstanceUID\") AS \"viewer_url\",\n    \"instance_size\"\n  FROM\n    \"IDC\".\"IDC_V17\".\"DICOM_ALL\"\n  WHERE\n    \"Modality\" IN ('SEG', 'RTSTRUCT')\n    AND \"SOPClassUID\" = '1.2.840.10008.5.1.4.1.1.66.4'\n    AND ARRAY_SIZE(\"ReferencedSeriesSequence\") = 0\n    AND ARRAY_SIZE(\"ReferencedImageSequence\") = 0\n    AND ARRAY_SIZE(\"SourceImageSequence\") = 0\n)\n\nSELECT\n  seg_rtstruct.\"collection_id\",\n  seg_rtstruct.\"SeriesInstanceUID\",\n  seg_rtstruct.\"StudyInstanceUID\",\n  seg_rtstruct.\"viewer_url\",\n  SUM(seg_rtstruct.\"instance_size\") / 1024 AS \"collection_size_KB\"\nFROM\n  seg_rtstruct\nGROUP BY\n  seg_rtstruct.\"collection_id\",\n  seg_rtstruct.\"SeriesInstanceUID\",\n  seg_rtstruct.\"StudyInstanceUID\",\n  seg_rtstruct.\"viewer_url\"\nORDER BY\n  \"collection_size_KB\" DESC;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: IDC\nQuestion: In publicly accessible DICOM data where the Modality is 'SEG' and the SOPClassUID is '1.2.840.10008.5.1.4.1.1.66.4', and each segmentation references its original SOPInstanceUID, which five segmentation categories (by 'SegmentedPropertyCategory.CodeMeaning') occur most frequently?"}, {"role": "assistant", "content": "WITH\n  sampled_sops AS (\n    SELECT\n      \"collection_id\",\n      \"SeriesDescription\",\n      \"SeriesInstanceUID\",\n      \"SOPInstanceUID\" AS \"seg_SOPInstanceUID\",\n      COALESCE(\n        \"ReferencedSeriesSequence\"[0].\"ReferencedInstanceSequence\"[0].\"ReferencedSOPInstanceUID\",\n        \"ReferencedImageSequence\"[0].\"ReferencedSOPInstanceUID\",\n        \"SourceImageSequence\"[0].\"ReferencedSOPInstanceUID\"\n      ) AS \"referenced_sop\"\n    FROM\n      \"IDC\".\"IDC_V17\".\"DICOM_ALL\"\n    WHERE\n      \"Modality\" = 'SEG'\n      AND \"SOPClassUID\" = '1.2.840.10008.5.1.4.1.1.66.4'\n      AND \"access\" = 'Public'\n  ),\n  segmentations_data AS (\n    SELECT\n      dicom_all.\"collection_id\",\n      dicom_all.\"PatientID\",\n      dicom_all.\"SOPInstanceUID\",\n      REPLACE(segmentations.\"SegmentedPropertyCategory\":CodeMeaning::STRING, '\"', '') AS \"segmentation_category\",\n      REPLACE(segmentations.\"SegmentedPropertyType\":CodeMeaning::STRING, '\"', '') AS \"segmentation_type\"\n    FROM\n      sampled_sops\n    JOIN\n      \"IDC\".\"IDC_V17\".\"DICOM_ALL\" AS dicom_all\n    ON\n      sampled_sops.\"referenced_sop\" = dicom_all.\"SOPInstanceUID\"\n    JOIN\n      \"IDC\".\"IDC_V17\".\"SEGMENTATIONS\" AS segmentations\n    ON\n      segmentations.\"SOPInstanceUID\" = sampled_sops.\"seg_SOPInstanceUID\"\n  )\nSELECT\n  \"segmentation_category\",\n  COUNT(*) AS \"count_\"\nFROM\n  segmentations_data\nGROUP BY\n  \"segmentation_category\"\nORDER BY\n  \"count_\" DESC\nLIMIT 5;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: IDC\nQuestion: From the union of the specified MR series with SeriesInstanceUID 1.3.6.1.4.1.14519.5.2.1.3671.4754.105976129314091491952445656147 and all associated segmentation instances, which modality has the greatest number of SOP instances in total, and how many are there?"}, {"role": "assistant", "content": "WITH union_mr_seg AS (\n  SELECT\n    \"dicom_all_mr\".\"SOPInstanceUID\",\n    '' AS \"segPropertyTypeCodeMeaning\", \n    '' AS \"segPropertyCategoryCodeMeaning\"\n  FROM\n    \"IDC\".\"IDC_V17\".\"DICOM_ALL\" AS \"dicom_all_mr\"\n  WHERE\n    \"dicom_all_mr\".\"SeriesInstanceUID\" IN ('1.3.6.1.4.1.14519.5.2.1.3671.4754.105976129314091491952445656147')\n    \n  UNION ALL\n\n  SELECT\n    \"dicom_all_seg\".\"SOPInstanceUID\",\n    \"segmentations\".\"SegmentedPropertyType\":\"CodeMeaning\" AS \"segPropertyTypeCodeMeaning\",\n    \"segmentations\".\"SegmentedPropertyCategory\":\"CodeMeaning\" AS \"segPropertyCategoryCodeMeaning\"\n  FROM\n    \"IDC\".\"IDC_V17\".\"DICOM_ALL\" AS \"dicom_all_seg\"\n  JOIN\n    \"IDC\".\"IDC_V17\".\"SEGMENTATIONS\" AS \"segmentations\"\n  ON\n    \"dicom_all_seg\".\"SOPInstanceUID\" = \"segmentations\".\"SOPInstanceUID\"\n)\n\nSELECT\n  \"dc_all\".\"Modality\",\n  COUNT(*) AS \"count_\"\nFROM \n  \"IDC\".\"IDC_V17\".\"DICOM_ALL\" AS \"dc_all\"\nINNER JOIN\n  union_mr_seg\nON \n  \"dc_all\".\"SOPInstanceUID\" = union_mr_seg.\"SOPInstanceUID\"\nGROUP BY\n  \"dc_all\".\"Modality\"\nORDER BY\n  \"count_\" DESC\nLIMIT 1;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: IDC\nQuestion: In the \"qin_prostate_repeatability\" collection, please provide the distinct StudyInstanceUIDs for studies that include T2-weighted axial MR imaging and also contain anatomical structure segmentations labeled as \"Peripheral zone.\""}, {"role": "assistant", "content": "WITH\n-- Studies that have MR volumes\n\"mr_studies\" AS (\n  SELECT\n    \"dicom_all_mr\".\"StudyInstanceUID\"\n  FROM\n    \"IDC\".\"IDC_V17\".\"DICOM_ALL\" AS \"dicom_all_mr\"\n  WHERE\n    \"Modality\" = 'MR'\n    AND \"collection_id\" = 'qin_prostate_repeatability'\n    AND CONTAINS(\"SeriesDescription\", 'T2 Weighted Axial')\n),\n\n\"seg_studies\" AS (\n  SELECT\n    \"dicom_all_seg\".\"StudyInstanceUID\"\n  FROM\n    \"IDC\".\"IDC_V17\".\"DICOM_ALL\" AS \"dicom_all_seg\"\n  JOIN\n    \"IDC\".\"IDC_V17\".\"SEGMENTATIONS\" AS \"segmentations\"\n  ON\n    \"dicom_all_seg\".\"SOPInstanceUID\" = \"segmentations\".\"SOPInstanceUID\"\n  WHERE\n    \"collection_id\" = 'qin_prostate_repeatability'\n    AND CONTAINS(\"segmentations\".\"SegmentedPropertyType\":\"CodeMeaning\", 'Peripheral zone')\n    AND \"segmentations\".\"SegmentedPropertyCategory\":\"CodeMeaning\" = 'Anatomical Structure'\n)\n\nSELECT DISTINCT\n  \"mr_studies\".\"StudyInstanceUID\"\nFROM\n  \"mr_studies\"\nJOIN\n  \"seg_studies\"\nON\n  \"mr_studies\".\"StudyInstanceUID\" = \"seg_studies\".\"StudyInstanceUID\";"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: IDC\nQuestion: Can you list all unique pairs of embedding medium and staining substance code meanings, along with the number of occurrences for each pair, based on distinct embedding medium and staining substance codes from the 'SM' modality in the DICOM dataset's un-nested specimen preparation sequences, ensuring that the codes are from the SCT coding scheme?"}, {"role": "assistant", "content": "WITH\n  SpecimenPreparationSequence_unnested AS (\n    SELECT\n      d.\"SOPInstanceUID\",\n      concept_name_code_sequence.value:\"CodeMeaning\"::STRING AS \"cnc_cm\",\n      concept_name_code_sequence.value:\"CodingSchemeDesignator\"::STRING AS \"cnc_csd\",\n      concept_name_code_sequence.value:\"CodeValue\"::STRING AS \"cnc_val\",\n      concept_code_sequence.value:\"CodeMeaning\"::STRING AS \"ccs_cm\",\n      concept_code_sequence.value:\"CodingSchemeDesignator\"::STRING AS \"ccs_csd\",\n      concept_code_sequence.value:\"CodeValue\"::STRING AS \"ccs_val\"\n    FROM\n      \"IDC\".\"IDC_V17\".\"DICOM_ALL\" AS d,\n      LATERAL FLATTEN(input => d.\"SpecimenDescriptionSequence\") AS spec_desc,\n      LATERAL FLATTEN(input => spec_desc.value:\"SpecimenPreparationSequence\") AS prep_seq,\n      LATERAL FLATTEN(input => prep_seq.value:\"SpecimenPreparationStepContentItemSequence\") AS prep_step,\n      LATERAL FLATTEN(input => prep_step.value:\"ConceptNameCodeSequence\") AS concept_name_code_sequence,\n      LATERAL FLATTEN(input => prep_step.value:\"ConceptCodeSequence\") AS concept_code_sequence\n  ),\n  slide_embedding AS (\n    SELECT\n      \"SOPInstanceUID\",\n      ARRAY_AGG(DISTINCT(CONCAT(\"ccs_cm\", ':', \"ccs_csd\", ':', \"ccs_val\"))) AS \"embeddingMedium_code_str\"\n    FROM\n      SpecimenPreparationSequence_unnested\n    WHERE\n      \"cnc_csd\" = 'SCT' AND \"cnc_val\" = '430863003' -- CodeMeaning is 'Embedding medium'\n    GROUP BY\n      \"SOPInstanceUID\"\n  ),\n  slide_staining AS (\n    SELECT\n      \"SOPInstanceUID\",\n      ARRAY_AGG(DISTINCT(CONCAT(\"ccs_cm\", ':', \"ccs_csd\", ':', \"ccs_val\"))) AS \"staining_usingSubstance_code_str\"\n    FROM\n      SpecimenPreparationSequence_unnested\n    WHERE\n      \"cnc_csd\" = 'SCT' AND \"cnc_val\" = '424361007' -- CodeMeaning is 'Using substance'\n    GROUP BY\n      \"SOPInstanceUID\"\n  ),\n  embedding_data AS (\n    SELECT\n      d.\"SOPInstanceUID\",\n      d.\"instance_size\",\n      e.\"embeddingMedium_code_str\",\n      s.\"staining_usingSubstance_code_str\"\n    FROM\n      \"IDC\".\"IDC_V17\".\"DICOM_ALL\" AS d\n    LEFT JOIN\n      slide_embedding AS e ON d.\"SOPInstanceUID\" = e.\"SOPInstanceUID\"\n    LEFT JOIN\n      slide_staining AS s ON d.\"SOPInstanceUID\" = s.\"SOPInstanceUID\"\n    WHERE\n      d.\"Modality\" = 'SM'\n  )\nSELECT\n  SPLIT_PART(embeddingMedium_CodeMeaning_flat.VALUE::STRING, ':', 1) AS \"embeddingMedium_CodeMeaning\",\n  SPLIT_PART(staining_usingSubstance_CodeMeaning_flat.VALUE::STRING, ':', 1) AS \"staining_usingSubstance_CodeMeaning\",\n  COUNT(*) AS \"count_\"\nFROM\n  embedding_data\n  , LATERAL FLATTEN(input => embedding_data.\"embeddingMedium_code_str\") AS embeddingMedium_CodeMeaning_flat\n  , LATERAL FLATTEN(input => embedding_data.\"staining_usingSubstance_code_str\") AS staining_usingSubstance_CodeMeaning_flat\nGROUP BY\n  SPLIT_PART(embeddingMedium_CodeMeaning_flat.VALUE::STRING, ':', 1),\n  SPLIT_PART(staining_usingSubstance_CodeMeaning_flat.VALUE::STRING, ':', 1);"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: IDC\nQuestion: Using the 'nlst' collection's CT images, calculate and compare two separate metrics: 1) The average series size in MiB for the top 3 patients with the highest slice interval difference tolerance (defined as the difference between the maximum and minimum unique slice intervals across all their series), and 2) The average series size in MiB for the top 3 patients with the highest exposure difference (defined as the difference between the maximum and minimum unique exposure values across all their series). For each patient, calculate the series size by summing the instance sizes of all images in that series and converting to MiB. Return the results as two separate groups labeled \"Top 3 by Slice Interval\" and \"Top 3 by Max Exposure\" with their respective average series sizes."}, {"role": "assistant", "content": "WITH\n  nonLocalizerRawData AS (\n    SELECT\n      \"SeriesInstanceUID\",\n      \"StudyInstanceUID\",\n      \"PatientID\",\n      TRY_CAST(\"Exposure\"::STRING AS FLOAT) AS \"Exposure\",  -- \u76f4\u63a5\u4ece bid \u83b7\u53d6 Exposure\n      TRY_CAST(axes.VALUE::STRING AS FLOAT) AS \"zImagePosition\",\n      LEAD(TRY_CAST(axes.VALUE::STRING AS FLOAT)) OVER (\n        PARTITION BY \"SeriesInstanceUID\" \n        ORDER BY TRY_CAST(axes.VALUE::STRING AS FLOAT)\n      ) - TRY_CAST(axes.VALUE::STRING AS FLOAT) AS \"slice_interval\",\n      \"instance_size\" AS \"instanceSize\"\n    FROM\n      \"IDC\".\"IDC_V17\".\"DICOM_ALL\" AS \"bid\",\n      LATERAL FLATTEN(input => \"bid\".\"ImagePositionPatient\") AS axes  -- \u4f7f\u7528 LATERAL FLATTEN \u5c55\u5f00\u6570\u7ec4\n    WHERE\n      \"collection_id\" = 'nlst' \n      AND \"Modality\" = 'CT' \n  ),\n  geometryChecks AS (\n    SELECT\n      \"SeriesInstanceUID\",\n      \"StudyInstanceUID\",\n      \"PatientID\",\n      ARRAY_AGG(DISTINCT \"slice_interval\") AS \"sliceIntervalDifferences\",\n      ARRAY_AGG(DISTINCT \"Exposure\") AS \"distinctExposures\",\n      SUM(\"instanceSize\") / 1024 / 1024 AS \"seriesSizeInMB\"\n    FROM\n      nonLocalizerRawData\n    GROUP BY\n      \"SeriesInstanceUID\", \n      \"StudyInstanceUID\",\n      \"PatientID\"\n  ),\n  patientMetrics AS (\n    SELECT\n      \"PatientID\",\n      MAX(TRY_CAST(sid.VALUE::STRING AS FLOAT)) AS \"maxSliceIntervalDifference\",\n      MIN(TRY_CAST(sid.VALUE::STRING AS FLOAT)) AS \"minSliceIntervalDifference\",\n      MAX(TRY_CAST(sid.VALUE::STRING AS FLOAT)) - MIN(TRY_CAST(sid.VALUE::STRING AS FLOAT)) AS \"sliceIntervalDifferenceTolerance\",\n      MAX(TRY_CAST(de.VALUE::STRING AS FLOAT)) AS \"maxExposure\",\n      MIN(TRY_CAST(de.VALUE::STRING AS FLOAT)) AS \"minExposure\",\n      MAX(TRY_CAST(de.VALUE::STRING AS FLOAT)) - MIN(TRY_CAST(de.VALUE::STRING AS FLOAT)) AS \"maxExposureDifference\",\n      \"seriesSizeInMB\"\n    FROM\n      geometryChecks,\n      LATERAL FLATTEN(input => \"sliceIntervalDifferences\") AS sid,  -- \u5c55\u5f00 sliceIntervalDifferences\n      LATERAL FLATTEN(input => \"distinctExposures\") AS de  -- \u5c55\u5f00 distinctExposures\n    WHERE\n      sid.VALUE IS NOT NULL\n      AND de.VALUE IS NOT NULL\n    GROUP BY\n      \"PatientID\",\n      \"seriesSizeInMB\"\n  ),\n  top3BySliceInterval AS (\n    SELECT\n      \"PatientID\",\n      \"seriesSizeInMB\"\n    FROM\n      patientMetrics\n    ORDER BY\n      \"sliceIntervalDifferenceTolerance\" DESC\n    LIMIT 3\n  ),\n  top3ByMaxExposure AS (\n    SELECT\n      \"PatientID\",\n      \"seriesSizeInMB\"\n    FROM\n      patientMetrics\n    ORDER BY\n      \"maxExposureDifference\" DESC\n    LIMIT 3\n  )\nSELECT\n  'Top 3 by Slice Interval' AS \"MetricGroup\",\n  AVG(\"seriesSizeInMB\") AS \"AverageSeriesSizeInMB\"\nFROM\n  top3BySliceInterval\nUNION ALL\nSELECT\n  'Top 3 by Max Exposure' AS \"MetricGroup\",\n  AVG(\"seriesSizeInMB\") AS \"AverageSeriesSizeInMB\"\nFROM\n  top3ByMaxExposure;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: IOWA_LIQUOR_SALES\nQuestion: In the Iowa Liquor Sales dataset, starting from January 1, 2022 through the last fully completed month, which two liquor categories, each contributing an average of at least 1% to the monthly sales volume over at least 24 months of available data, have the lowest Pearson correlation coefficient when comparing their monthly percentages of total liquor sales across those months, and what are their names?"}, {"role": "assistant", "content": "WITH\nMonthlyTotals AS\n(\n  SELECT\n    TO_CHAR(\"date\", 'YYYY-MM') AS \"month\",\n    SUM(\"volume_sold_gallons\") AS \"total_monthly_volume\"\n  FROM\n    IOWA_LIQUOR_SALES.IOWA_LIQUOR_SALES.\"SALES\"\n  WHERE\n    \"date\" >= '2022-01-01' \n    AND TO_CHAR(\"date\", 'YYYY-MM') < TO_CHAR(CURRENT_DATE(), 'YYYY-MM')\n  GROUP BY\n    TO_CHAR(\"date\", 'YYYY-MM')\n),\n\nMonthCategory AS\n(\n  SELECT\n    TO_CHAR(\"date\", 'YYYY-MM') AS \"month\",\n    \"category\",\n    \"category_name\",\n    SUM(\"volume_sold_gallons\") AS \"category_monthly_volume\",\n    CASE \n      WHEN \"total_monthly_volume\" != 0 THEN (SUM(\"volume_sold_gallons\") / \"total_monthly_volume\") * 100\n      ELSE NULL\n    END AS \"category_pct_of_month_volume\"\n  FROM\n    IOWA_LIQUOR_SALES.IOWA_LIQUOR_SALES.\"SALES\" AS Sales\n  LEFT JOIN\n    MonthlyTotals ON TO_CHAR(Sales.\"date\", 'YYYY-MM') = MonthlyTotals.\"month\"\n  WHERE\n    Sales.\"date\" >= '2022-01-01' \n    AND TO_CHAR(Sales.\"date\", 'YYYY-MM') < TO_CHAR(CURRENT_DATE(), 'YYYY-MM')\n  GROUP BY\n    TO_CHAR(Sales.\"date\", 'YYYY-MM'), \"category\", \"category_name\", \"total_monthly_volume\"\n),\n\nmiddle_info AS \n(\n  SELECT\n    Category1.\"category\" AS \"category1\",\n    Category1.\"category_name\" AS \"category_name1\",\n    Category2.\"category\" AS \"category2\",\n    Category2.\"category_name\" AS \"category_name2\",\n    COUNT(DISTINCT Category1.\"month\") AS \"num_months\",\n    CORR(Category1.\"category_pct_of_month_volume\", Category2.\"category_pct_of_month_volume\") AS \"category_corr_across_months\",\n    AVG(Category1.\"category_pct_of_month_volume\") AS \"category1_avg_pct_of_month_volume\",\n    AVG(Category2.\"category_pct_of_month_volume\") AS \"category2_avg_pct_of_month_volume\"\n  FROM\n    MonthCategory Category1\n  INNER JOIN\n    MonthCategory Category2 \n    ON Category1.\"month\" = Category2.\"month\"\n  GROUP BY\n    Category1.\"category\", Category1.\"category_name\", Category2.\"category\", Category2.\"category_name\"\n  HAVING\n    \"num_months\" >= 24\n    AND \"category1_avg_pct_of_month_volume\" >= 1\n    AND \"category2_avg_pct_of_month_volume\" >= 1\n)\n\nSELECT \n  \"category_name1\", \n  \"category_name2\"\nFROM \n  middle_info\nORDER BY \n  \"category_corr_across_months\"\nLIMIT 1;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: iowa_liquor_sales\nQuestion: Identify the top 10 liquor categories in Iowa in 2021 by calculating, for each category, the average of the per-liter retail prices across all sales transactions in that category during 2021. For these top categories, provide their average per-liter retail prices calculated in the same manner for the years 2019, 2020, and 2021."}, {"role": "assistant", "content": "WITH price_2020 AS (\n  SELECT \n    category_name AS category, \n    AVG(state_bottle_retail / (bottle_volume_ml / 1000)) AS avg_price_liter_2020\n  FROM \n    `bigquery-public-data.iowa_liquor_sales.sales`\n  WHERE \n    bottle_volume_ml > 0 \n    AND EXTRACT(YEAR FROM date) = 2020\n  GROUP BY \n    category\n),\nprice_2019 AS (\n  SELECT \n    category_name AS category, \n    AVG(state_bottle_retail / (bottle_volume_ml / 1000)) AS avg_price_liter_2019\n  FROM \n    `bigquery-public-data.iowa_liquor_sales.sales`\n  WHERE \n    bottle_volume_ml > 0 \n    AND EXTRACT(YEAR FROM date) = 2019\n  GROUP BY \n    category\n),\nprice_2021 AS (\n  SELECT \n    category_name AS category, \n    AVG(state_bottle_retail / (bottle_volume_ml / 1000)) AS avg_price_liter_2021\n  FROM \n    `bigquery-public-data.iowa_liquor_sales.sales`\n  WHERE \n    bottle_volume_ml > 0 \n    AND EXTRACT(YEAR FROM date) = 2021\n  GROUP BY \n    category\n)\nSELECT \n  price_2021.category, \n  price_2019.avg_price_liter_2019, \n  price_2020.avg_price_liter_2020, \n  price_2021.avg_price_liter_2021\nFROM \n  price_2021\nLEFT JOIN \n  price_2019 ON price_2021.category = price_2019.category\nLEFT JOIN \n  price_2020 ON price_2021.category = price_2020.category\nORDER BY \n  price_2021.avg_price_liter_2021 DESC\nLIMIT \n  10;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: iowa_liquor_sales\nQuestion: What are the top 5 items with the highest year-over-year growth percentage in total sales revenue for the year 2023?"}, {"role": "assistant", "content": "WITH AnnualSales AS (\n  SELECT\n    item_description,\n    EXTRACT(YEAR FROM date) AS year,\n    SUM(sale_dollars) AS total_sales_revenue,\n    COUNT(DISTINCT invoice_and_item_number) AS unique_purchases\n  FROM\n    `bigquery-public-data.iowa_liquor_sales.sales`\n  WHERE\n    EXTRACT(YEAR FROM date) IN (2022, 2023)\n    AND item_description IS NOT NULL\n    AND sale_dollars IS NOT NULL\n  GROUP BY\n    item_description, year\n),\nYoYGrowth AS (\n  SELECT\n    curr.item_description,\n    curr.year,\n    curr.total_sales_revenue,\n    curr.unique_purchases,\n    LAG(curr.total_sales_revenue) OVER(PARTITION BY curr.item_description ORDER BY curr.year) AS prev_year_sales_revenue,\n    (curr.total_sales_revenue - LAG(curr.total_sales_revenue) OVER(PARTITION BY curr.item_description ORDER BY curr.year)) / LAG(curr.total_sales_revenue) OVER(PARTITION BY curr.item_description ORDER BY curr.year) * 100 AS yoy_growth_percentage\n  FROM\n    AnnualSales curr\n),\ntotal_info AS (\nSELECT\n  item_description,\n  year,\n  total_sales_revenue,\n  unique_purchases,\n  prev_year_sales_revenue,\n  yoy_growth_percentage\nFROM\n  YoYGrowth\nWHERE\n  year = 2023\n  AND prev_year_sales_revenue IS NOT NULL -- Exclude rows where there's no previous year data to calculate YoY growth\nORDER BY\n  year, total_sales_revenue \nDESC\n)\n\nSELECT item_description\nFROM total_info\norder by yoy_growth_percentage\nDESC\nLIMIT 5"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: iowa_liquor_sales_plus\nQuestion: Please show the monthly per capita Bourbon Whiskey sales during 2022 in Dubuque County for the zip code that ranks third in total Bourbon Whiskey sales, using only the population aged 21 and older."}, {"role": "assistant", "content": "WITH DUBUQUE_LIQUOR_CTE AS (\nSELECT\n  CASE\n      WHEN UPPER(category_name) LIKE 'BUTTERSCOTCH SCHNAPPS' THEN 'All Other' --Edge case is not a scotch\n      WHEN UPPER(category_name) LIKE '%WHISKIES' \n            AND UPPER(category_name) NOT LIKE '%RYE%'\n            AND UPPER(category_name) NOT LIKE '%BOURBON%'\n            AND UPPER(category_name) NOT LIKE '%SCOTCH%'     THEN 'Other Whiskey'\n      WHEN UPPER(category_name) LIKE '%RYE%'                 THEN 'Rye Whiskey'\n      WHEN UPPER(category_name) LIKE '%BOURBON%'             THEN 'Bourbon Whiskey'\n      WHEN UPPER(category_name) LIKE '%SCOTCH%'              THEN 'Scotch Whiskey'\n      ELSE 'All Other'\n  END                              AS category_group,\n  EXTRACT(MONTH FROM date)         AS month,    -- At the time of this query, there is only data until month 6.\n  LEFT(CAST(zip_code AS string),5) AS zip_code, -- Casting to string necessary because zip_code has a mix of int & str types.\n  ROUND(SUM(sale_dollars), 2)      AS sale_dollars_sum,\n\nFROM \n  bigquery-public-data.iowa_liquor_sales.sales\n\nWHERE\n  UPPER(county)               = 'DUBUQUE'\n  AND EXTRACT(YEAR FROM date) = 2022\n\nGROUP BY\n  category_group,\n  month,\n  zip_code\n  \nORDER BY \n  category_group,\n  month,\n  zip_code\n),\n\nDUBUQUE_POPULATION_CTE AS (\nSELECT\n  zipcode,\n  SUM(population) AS population_sum\nFROM bigquery-public-data.census_bureau_usa.population_by_zip_2010\nWHERE \n  minimum_age >= 21\nGROUP BY \n  zipcode\n),\nMONTH_INFO AS (\nSELECT \n  l.month,\n  l.zip_code,\n  l.sale_dollars_sum,\n  ROUND(sale_dollars_sum/p.population_sum, 2) AS dollars_per_capita\nFROM \n  DUBUQUE_LIQUOR_CTE AS l\n  LEFT JOIN \n  DUBUQUE_POPULATION_CTE AS p\n  ON l.zip_code = p.zipcode\nWHERE\n  category_group = 'Bourbon Whiskey'\nGROUP BY \n  category_group,\n  zip_code,\n  month,\n  sale_dollars_sum,\n  zipcode,\n  population_sum\nORDER BY\n  zip_code,\n  month\n),\nzip_code_sales AS (\n    SELECT\n        zip_code,\n        SUM(sale_dollars_sum) AS total_sale_dollars_sum\n    FROM MONTH_INFO\n    GROUP BY zip_code\n),\nranked_zip_codes AS (\n    SELECT\n        zip_code,\n        total_sale_dollars_sum,\n        ROW_NUMBER() OVER (ORDER BY total_sale_dollars_sum DESC) AS rank\n    FROM zip_code_sales\n)\nSELECT\n    t.month,\n    t.zip_code,\n    t.dollars_per_capita\nFROM MONTH_INFO t\nJOIN ranked_zip_codes r\nON t.zip_code = r.zip_code\nWHERE r.rank = 3\nORDER BY t.month;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: nppes\nQuestion: Among healthcare providers whose practice location is in Mountain View, CA, and who have a specified specialization in the field healthcare provider taxonomy, identify the top 10 most common specializations based on the count of distinct NPIs. Then determine which of those top 10 has a count of distinct NPIs closest to the average count across those 10 specializations."}, {"role": "assistant", "content": "WITH specialist_counts AS (\n  SELECT\n    healthcare_provider_taxonomy_1_specialization,\n    COUNT(DISTINCT npi) AS number_specialist\n  FROM\n    `bigquery-public-data.nppes.npi_optimized`\n  WHERE\n    provider_business_practice_location_address_city_name = \"MOUNTAIN VIEW\"\n    AND provider_business_practice_location_address_state_name = \"CA\"\n    AND healthcare_provider_taxonomy_1_specialization > \"\"\n  GROUP BY\n    healthcare_provider_taxonomy_1_specialization\n),\ntop_10_specialists AS (\n  SELECT\n    healthcare_provider_taxonomy_1_specialization,\n    number_specialist\n  FROM\n    specialist_counts\n  ORDER BY\n    number_specialist DESC\n  LIMIT 10\n),\naverage_value AS (\n  SELECT\n    AVG(number_specialist) AS average_specialist\n  FROM\n    top_10_specialists\n),\nclosest_to_average AS (\n  SELECT\n    healthcare_provider_taxonomy_1_specialization,\n    number_specialist,\n    ABS(number_specialist - (SELECT average_specialist FROM average_value)) AS difference\n  FROM\n    top_10_specialists\n)\nSELECT\n  healthcare_provider_taxonomy_1_specialization\nFROM\n  closest_to_average\nORDER BY\n  difference\nLIMIT 1;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: usa_names\nQuestion: Can you tell me the name of the most popular female baby in Wyoming for the year 2021, based on the proportion of female babies given that name compared to the total number of female babies given the same name across all states?"}, {"role": "assistant", "content": "SELECT\n  a.name AS name\nFROM\n  `bigquery-public-data.usa_names.usa_1910_current` a\nJOIN (\n  SELECT\n    name,\n    gender,\n    year,\n    SUM(number) AS total_number\n  FROM\n    `bigquery-public-data.usa_names.usa_1910_current`\n  GROUP BY\n    name,\n    gender,\n    year) b\nON\n  a.name = b.name\n  AND a.gender = b.gender\n  AND a.year = b.year\nWHERE \n    a.gender = 'F' AND\n    a.state = 'WY' AND\n    a.year = 2021\nORDER BY (a.number / b.total_number) DESC\nLIMIT 1"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: TCGA\nQuestion: What are the RNA expression levels of the genes MDM2, TP53, CDKN1A, and CCNE1, along with associated clinical information, in bladder cancer patients with CDKN2A mutations in the 'TCGA-BLCA' project?  Use clinical data from the Genomic Data Commons Release 39, data about somatic mutations derived from the hg19 human genome reference in Feb 2017."}, {"role": "assistant", "content": "SELECT\n  genex.\"case_barcode\" AS \"case_barcode\",\n  genex.\"sample_barcode\" AS \"sample_barcode\",\n  genex.\"aliquot_barcode\" AS \"aliquot_barcode\",\n  genex.\"HGNC_gene_symbol\" AS \"HGNC_gene_symbol\",\n  clinical_info.\"Variant_Type\" AS \"Variant_Type\",\n  genex.\"gene_id\" AS \"gene_id\",\n  genex.\"normalized_count\" AS \"normalized_count\",\n  genex.\"project_short_name\" AS \"project_short_name\",\n  clinical_info.\"demo__gender\" AS \"gender\",\n  clinical_info.\"demo__vital_status\" AS \"vital_status\",\n  clinical_info.\"demo__days_to_death\" AS \"days_to_death\"\nFROM ( \n  SELECT\n    case_list.\"Variant_Type\" AS \"Variant_Type\",\n    case_list.\"case_barcode\" AS \"case_barcode\",\n    clinical.\"demo__gender\",\n    clinical.\"demo__vital_status\",\n    clinical.\"demo__days_to_death\"\n  FROM\n    (SELECT\n      mutation.\"case_barcode\",\n      mutation.\"Variant_Type\"\n    FROM\n      \"TCGA\".\"TCGA_VERSIONED\".\"SOMATIC_MUTATION_HG19_DCC_2017_02\" AS mutation\n    WHERE\n      mutation.\"Hugo_Symbol\" = 'CDKN2A'\n      AND mutation.\"project_short_name\" = 'TCGA-BLCA'\n    GROUP BY\n      mutation.\"case_barcode\",\n      mutation.\"Variant_Type\"\n    ORDER BY\n      mutation.\"case_barcode\"\n    ) AS case_list /* end case_list */\n  INNER JOIN\n    \"TCGA\".\"TCGA_VERSIONED\".\"CLINICAL_GDC_R39\" AS clinical\n  ON\n    case_list.\"case_barcode\" = clinical.\"submitter_id\" /* end clinical annotation */ ) AS clinical_info\nINNER JOIN\n  \"TCGA\".\"TCGA_VERSIONED\".\"RNASEQ_HG19_GDC_2017_02\" AS genex\nON\n  genex.\"case_barcode\" = clinical_info.\"case_barcode\"\nWHERE\n  genex.\"HGNC_gene_symbol\" IN ('MDM2', 'TP53', 'CDKN1A','CCNE1')\nORDER BY\n  \"case_barcode\",\n  \"HGNC_gene_symbol\";"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: CPTAC_PDC\nQuestion: Use CPTAC proteomics and RNAseq data for Clear Cell Renal Cell Carcinoma to select 'Primary Tumor' and 'Solid Tissue Normal' samples. Join the datasets on sample submitter IDs and gene symbols. Calculate the correlation between protein abundance (log2 ratio) and gene expression levels (log-transformed+1 FPKM) for each gene and sample type. Filter out correlations with an absolute value greater than 0.5, and compute the average correlation for each sample type."}, {"role": "assistant", "content": "WITH \nquant AS (\n    SELECT \n        meta.sample_submitter_id, \n        meta.sample_type, \n        quant.case_id, \n        quant.aliquot_id, \n        quant.gene_symbol, \n        CAST(quant.protein_abundance_log2ratio AS FLOAT64) AS protein_abundance_log2ratio \n    FROM \n        `isb-cgc-bq.CPTAC.quant_proteome_CPTAC_CCRCC_discovery_study_pdc_current` AS quant\n    JOIN \n        `isb-cgc-bq.PDC_metadata.aliquot_to_case_mapping_current` AS meta\n        ON quant.case_id = meta.case_id\n        AND quant.aliquot_id = meta.aliquot_id\n        AND meta.sample_type IN ('Primary Tumor', 'Solid Tissue Normal')\n),\ngexp AS (\n    SELECT DISTINCT \n        meta.sample_submitter_id, \n        meta.sample_type, \n        rnaseq.gene_name, \n        LOG(rnaseq.fpkm_unstranded + 1) AS HTSeq__FPKM   -- Confirm the correct column name here\n    FROM \n        `isb-cgc-bq.CPTAC.RNAseq_hg38_gdc_current` AS rnaseq\n    JOIN \n        `isb-cgc-bq.PDC_metadata.aliquot_to_case_mapping_current` AS meta\n        ON meta.sample_submitter_id = rnaseq.sample_barcode\n),\ncorrelation AS (\n    SELECT \n        quant.gene_symbol, \n        gexp.sample_type, \n        COUNT(*) AS n, \n        CORR(protein_abundance_log2ratio, HTSeq__FPKM) AS corr  -- Confirm the correct column name here\n    FROM \n        quant \n    JOIN \n        gexp \n        ON quant.sample_submitter_id = gexp.sample_submitter_id\n        AND gexp.gene_name = quant.gene_symbol\n        AND gexp.sample_type = quant.sample_type\n    GROUP BY \n        quant.gene_symbol, gexp.sample_type\n),\npval AS (\n    SELECT  \n        gene_symbol, \n        sample_type, \n        n, \n        corr\n    FROM \n        correlation\n    WHERE \n        ABS(corr) <= 0.5\n)\nSELECT sample_type, AVG(corr)\nFROM pval\nGROUP BY sample_type;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: TCGA_MITELMAN\nQuestion: Identify the case barcodes from the TCGA-LAML study with the highest weighted average copy number in cytoband 15q11 on chromosome 15, using segment data and cytoband overlaps from TCGA's genomic and Mitelman databases."}, {"role": "assistant", "content": "WITH copy AS (\n  SELECT \n    \"case_barcode\", \n    \"chromosome\", \n    \"start_pos\", \n    \"end_pos\", \n    MAX(\"copy_number\") AS \"copy_number\"\n  FROM \n    \"TCGA_MITELMAN\".\"TCGA_VERSIONED\".\"COPY_NUMBER_SEGMENT_ALLELIC_HG38_GDC_R23\"\n  WHERE \n    \"project_short_name\" = 'TCGA-LAML'\n  GROUP BY \n    \"case_barcode\", \n    \"chromosome\", \n    \"start_pos\", \n    \"end_pos\"\n),\ntotal_cases AS (\n  SELECT COUNT(DISTINCT \"case_barcode\") AS \"total\"\n  FROM copy\n),\ncytob AS (\n  SELECT \n    \"chromosome\", \n    \"cytoband_name\", \n    \"hg38_start\", \n    \"hg38_stop\"\n  FROM \n    \"TCGA_MITELMAN\".\"PROD\".\"CYTOBANDS_HG38\"\n),\njoined AS (\n  SELECT \n    cytob.\"chromosome\", \n    cytob.\"cytoband_name\", \n    cytob.\"hg38_start\", \n    cytob.\"hg38_stop\", \n    copy.\"case_barcode\",\n    (ABS(cytob.\"hg38_stop\" - cytob.\"hg38_start\") + ABS(copy.\"end_pos\" - copy.\"start_pos\") \n      - ABS(cytob.\"hg38_stop\" - copy.\"end_pos\") - ABS(cytob.\"hg38_start\" - copy.\"start_pos\")) / 2.0 AS \"overlap\", \n    copy.\"copy_number\"\n  FROM \n    copy\n  LEFT JOIN \n    cytob\n  ON \n    cytob.\"chromosome\" = copy.\"chromosome\"\n  WHERE \n    (cytob.\"hg38_start\" >= copy.\"start_pos\" AND copy.\"end_pos\" >= cytob.\"hg38_start\")\n    OR (copy.\"start_pos\" >= cytob.\"hg38_start\" AND copy.\"start_pos\" <= cytob.\"hg38_stop\")\n),\nINFO AS (\n  SELECT \n    \"chromosome\", \n    \"cytoband_name\", \n    \"hg38_start\", \n    \"hg38_stop\", \n    \"case_barcode\",\n    ROUND(SUM(\"overlap\" * \"copy_number\") / SUM(\"overlap\")) AS \"copy_number\"\n  FROM \n    joined\n  GROUP BY \n    \"chromosome\", \"cytoband_name\", \"hg38_start\", \"hg38_stop\", \"case_barcode\"\n)\n\nSELECT \n  \"case_barcode\"\nFROM \n  INFO\nWHERE \n  \"chromosome\" = 'chr15' \n  AND \"cytoband_name\" = '15q11'\nORDER BY \n  \"copy_number\" DESC\nLIMIT 1;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: TCGA_HG19_DATA_V0\nQuestion: Assess whether different genetic variants affect the log10-transformed TP53 expression levels in TCGA-BRCA samples using sequencing and mutation data. Provide the total number of samples, the number of mutation types, the mean square between groups, the mean square within groups, and the F-statistic.\n\nExternal Knowledge: TCGA_F_Score.md"}, {"role": "assistant", "content": "WITH\ncohortExpr AS (\n  SELECT\n    \"sample_barcode\",\n    LOG(10, \"normalized_count\") AS \"expr\"\n  FROM\n    \"TCGA_HG19_DATA_V0\".\"TCGA_HG19_DATA_V0\".\"RNASEQ_GENE_EXPRESSION_UNC_RSEM\"\n  WHERE\n    \"project_short_name\" = 'TCGA-BRCA'\n    AND \"HGNC_gene_symbol\" = 'TP53'\n    AND \"normalized_count\" IS NOT NULL\n    AND \"normalized_count\" > 0\n),\ncohortVar AS (\n  SELECT\n    \"Variant_Type\",\n    \"sample_barcode_tumor\" AS \"sample_barcode\"\n  FROM\n    \"TCGA_HG19_DATA_V0\".\"TCGA_HG19_DATA_V0\".\"SOMATIC_MUTATION_MC3\"\n  WHERE\n    \"SYMBOL\" = 'TP53'\n),\ncohort AS (\n  SELECT\n    e.\"sample_barcode\" AS \"sample_barcode\",\n    v.\"Variant_Type\" AS \"group_name\",\n    e.\"expr\"\n  FROM\n    cohortExpr e\n  JOIN\n    cohortVar v\n  ON\n    e.\"sample_barcode\" = v.\"sample_barcode\"\n),\ngrandMeanTable AS (\n  SELECT\n    AVG(\"expr\") AS \"grand_mean\"\n  FROM\n    cohort\n),\ngroupMeansTable AS (\n  SELECT\n    AVG(\"expr\") AS \"group_mean\",\n    \"group_name\",\n    COUNT(\"sample_barcode\") AS \"n\"\n  FROM\n    cohort\n  GROUP BY\n    \"group_name\"\n),\nssBetween AS (\n  SELECT\n    g.\"group_name\",\n    g.\"group_mean\",\n    gm.\"grand_mean\",\n    g.\"n\",\n    g.\"n\" * POW(g.\"group_mean\" - gm.\"grand_mean\", 2) AS \"n_diff_sq\"\n  FROM\n    groupMeansTable g\n  CROSS JOIN\n    grandMeanTable gm\n),\nssWithin AS (\n  SELECT\n    c.\"group_name\" AS \"group_name\",\n    c.\"expr\",\n    b.\"group_mean\",\n    b.\"n\" AS \"n\",\n    POW(c.\"expr\" - b.\"group_mean\", 2) AS \"s2\"\n  FROM\n    cohort c\n  JOIN\n    ssBetween b\n  ON\n    c.\"group_name\" = b.\"group_name\"\n),\nnumerator AS (\n  SELECT\n    SUM(\"n_diff_sq\") / (COUNT(\"group_name\") - 1) AS \"mean_sq_between\"\n  FROM\n    ssBetween\n),\ndenominator AS (\n  SELECT\n    COUNT(DISTINCT \"group_name\") AS \"k\",\n    COUNT(\"group_name\") AS \"n\",\n    SUM(\"s2\") / (COUNT(\"group_name\") - COUNT(DISTINCT \"group_name\")) AS \"mean_sq_within\"\n  FROM\n    ssWithin\n)\n\nSELECT\n  \"n\",\n  \"k\",\n  \"mean_sq_between\",\n  \"mean_sq_within\",\n  \"mean_sq_between\" / \"mean_sq_within\" AS \"F\"\nFROM\n  numerator,\n  denominator;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: TCGA_HG38_DATA_V0\nQuestion: In the TCGA-BRCA cohort of patients who are 80 years old or younger at diagnosis and have a pathological stage of Stage I, Stage II, or Stage IIA, calculate the t-statistic derived from the Pearson correlation between the log10-transformed average RNA-Seq expression levels (using HTSeq__Counts + 1) of the gene SNORA31 and the average microRNA-Seq expression levels of all unique microRNAs, only considering pairs with more than 25 samples and where the absolute Pearson correlation coefficient is between 0.3 and 1.0"}, {"role": "assistant", "content": "WITH cohort AS (\n    SELECT \"case_barcode\"\n    FROM \"TCGA_HG38_DATA_V0\".\"TCGA_BIOCLIN_V0\".\"CLINICAL\"\n    WHERE \"project_short_name\" = 'TCGA-BRCA'\n        AND \"age_at_diagnosis\" <= 80\n        AND \"pathologic_stage\" IN ('Stage I', 'Stage II', 'Stage IIA')\n),\ntable1 AS (\n    SELECT\n        \"symbol\",\n        \"data\" AS \"rnkdata\",\n        \"ParticipantBarcode\"\n    FROM (\n        SELECT\n            \"gene_name\" AS \"symbol\", \n            AVG(LOG(10, \"HTSeq__Counts\" + 1)) AS \"data\",\n            \"case_barcode\" AS \"ParticipantBarcode\"\n        FROM \"TCGA_HG38_DATA_V0\".\"TCGA_HG38_DATA_V0\".\"RNASEQ_GENE_EXPRESSION\"\n        WHERE \"case_barcode\" IN (SELECT \"case_barcode\" FROM cohort)\n            AND \"gene_name\" = 'SNORA31'\n            AND \"HTSeq__Counts\" IS NOT NULL\n        GROUP BY\n            \"ParticipantBarcode\", \"symbol\"\n    )\n),\ntable2 AS (\n    SELECT\n        \"symbol\",\n        \"data\" AS \"rnkdata\",\n        \"ParticipantBarcode\"\n    FROM (\n        SELECT\n            \"mirna_id\" AS \"symbol\", \n            AVG(\"reads_per_million_miRNA_mapped\") AS \"data\",\n            \"case_barcode\" AS \"ParticipantBarcode\"\n        FROM \"TCGA_HG38_DATA_V0\".\"TCGA_HG38_DATA_V0\".\"MIRNASEQ_EXPRESSION\"\n        WHERE \"case_barcode\" IN (SELECT \"case_barcode\" FROM cohort)\n            AND \"mirna_id\" IS NOT NULL\n            AND \"reads_per_million_miRNA_mapped\" IS NOT NULL\n        GROUP BY\n            \"ParticipantBarcode\", \"symbol\"\n    )\n),\nsumm_table AS (\n    SELECT \n        n1.\"symbol\" AS \"symbol1\",\n        n2.\"symbol\" AS \"symbol2\",\n        COUNT(n1.\"ParticipantBarcode\") AS \"n\",\n        CORR(n1.\"rnkdata\", n2.\"rnkdata\") AS \"correlation\"\n    FROM\n        table1 AS n1\n    INNER JOIN\n        table2 AS n2\n    ON\n        n1.\"ParticipantBarcode\" = n2.\"ParticipantBarcode\"\n    GROUP BY\n        \"symbol1\", \"symbol2\"\n)\n\nSELECT \n    \"symbol1\", \n    \"symbol2\", \n    ABS(\"correlation\") * SQRT(( \"n\" - 2 ) / (1 - \"correlation\" * \"correlation\")) AS \"t\"\nFROM \n    summ_table\nWHERE \n    \"n\" > 25 \n    AND ABS(\"correlation\") >= 0.3 \n    AND ABS(\"correlation\") < 1.0;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: PANCANCER_ATLAS_1\nQuestion: Calculate, for each histology type specified in the 'icd_o_3_histology' field (excluding those enclosed in square brackets), the average of the per-patient average log10(normalized_count + 1) expression levels of the IGF2 gene among LGG patients with valid IGF2 expression data. Match gene expression and clinical data using the ParticipantBarcode field."}, {"role": "assistant", "content": "WITH\n    table1 AS (\n        SELECT \n            \"Symbol\" AS \"symbol\", \n            AVG(LOG(10, \"normalized_count\" + 1)) AS \"data\", \n            \"ParticipantBarcode\"\n        FROM \n            PANCANCER_ATLAS_1.PANCANCER_ATLAS_FILTERED.EBPP_ADJUSTPANCAN_ILLUMINAHISEQ_RNASEQV2_GENEXP_FILTERED\n        WHERE \n            \"Study\" = 'LGG' \n            AND \"Symbol\" = 'IGF2' \n            AND \"normalized_count\" IS NOT NULL\n        GROUP BY \n            \"ParticipantBarcode\", \"symbol\"\n    ),\n    table2 AS (\n        SELECT\n            \"symbol\",\n            \"avgdata\" AS \"data\",\n            \"ParticipantBarcode\"\n        FROM (\n            SELECT\n                'icd_o_3_histology' AS \"symbol\", \n                \"icd_o_3_histology\" AS \"avgdata\",\n                \"bcr_patient_barcode\" AS \"ParticipantBarcode\"\n            FROM \n                PANCANCER_ATLAS_1.PANCANCER_ATLAS_FILTERED.CLINICAL_PANCAN_PATIENT_WITH_FOLLOWUP_FILTERED\n            WHERE \n                \"acronym\" = 'LGG' \n                AND \"icd_o_3_histology\" IS NOT NULL  \n                AND NOT REGEXP_LIKE(\"icd_o_3_histology\", '^(\\\\[.*\\\\]$)')\n        )\n    ),\n    table_data AS (\n        SELECT \n            n1.\"data\" AS \"data1\",\n            n2.\"data\" AS \"data2\",\n            n1.\"ParticipantBarcode\"\n        FROM \n            table1 AS n1\n        INNER JOIN \n            table2 AS n2\n        ON \n            n1.\"ParticipantBarcode\" = n2.\"ParticipantBarcode\"\n    ) \n\nSELECT \n    \"data2\" AS \"Histology_Type\", \n    AVG(\"data1\") AS \"Average_Log_Expression\"\nFROM \n    table_data\nGROUP BY \n    \"data2\";"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: PANCANCER_ATLAS_1\nQuestion: Which top five histological types of breast cancer (BRCA) in the PanCancer Atlas exhibit the highest percentage of CDH1 gene mutations?"}, {"role": "assistant", "content": "WITH\n    table1 AS (\n        SELECT\n            \"histological_type\" AS \"data1\",\n            \"bcr_patient_barcode\" AS \"ParticipantBarcode\"\n        FROM \n            \"PANCANCER_ATLAS_1\".\"PANCANCER_ATLAS_FILTERED\".\"CLINICAL_PANCAN_PATIENT_WITH_FOLLOWUP_FILTERED\"\n        WHERE \n            \"acronym\" = 'BRCA' \n            AND \"histological_type\" IS NOT NULL      \n    ),\n    table2 AS (\n        SELECT\n            \"Hugo_Symbol\" AS \"symbol\", \n            \"ParticipantBarcode\"\n        FROM \n            \"PANCANCER_ATLAS_1\".\"PANCANCER_ATLAS_FILTERED\".\"MC3_MAF_V5_ONE_PER_TUMOR_SAMPLE\"\n        WHERE \n            \"Study\" = 'BRCA' \n            AND \"Hugo_Symbol\" = 'CDH1'\n            AND \"FILTER\" = 'PASS'  \n        GROUP BY\n            \"ParticipantBarcode\", \"symbol\"\n    ),\n    summ_table AS (\n        SELECT \n            n1.\"data1\",\n            CASE \n                WHEN n2.\"ParticipantBarcode\" IS NULL THEN 'NO' \n                ELSE 'YES' \n            END AS \"data2\",\n            COUNT(*) AS \"Nij\"\n        FROM\n            table1 AS n1\n        LEFT JOIN\n            table2 AS n2 \n            ON n1.\"ParticipantBarcode\" = n2.\"ParticipantBarcode\"\n        GROUP BY\n            n1.\"data1\", \"data2\"\n    ),\n    percentages AS (\n        SELECT\n            \"data1\",\n            SUM(CASE WHEN \"data2\" = 'YES' THEN \"Nij\" ELSE 0 END) AS \"mutation_count\",\n            SUM(\"Nij\") AS \"total\",\n            SUM(CASE WHEN \"data2\" = 'YES' THEN \"Nij\" ELSE 0 END) / SUM(\"Nij\") AS \"mutation_percentage\"\n        FROM \n            summ_table\n        GROUP BY \n            \"data1\"\n    )\nSELECT \n    \"data1\" AS \"Histological_Type\"\nFROM \n    percentages\nORDER BY \n    \"mutation_percentage\" DESC\nLIMIT 5;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: PANCANCER_ATLAS_1\nQuestion: Calculate the chi-square value to assess the association between histological types and the presence of CDH1 gene mutations in BRCA patients using data from the PanCancer Atlas. Focus on patients with known histological types and consider only reliable mutation entries.  Exclude any histological types or mutation statuses with marginal totals less than or equal to 10. Match clinical and mutation data using ParticipantBarcode"}, {"role": "assistant", "content": "WITH\n    table1 AS (\n        SELECT\n            \"symbol\",\n            \"avgdata\" AS \"data\",\n            \"ParticipantBarcode\"\n        FROM (\n            SELECT\n                'histological_type' AS \"symbol\", \n                \"histological_type\" AS \"avgdata\",\n                \"bcr_patient_barcode\" AS \"ParticipantBarcode\"\n            FROM \n                \"PANCANCER_ATLAS_1\".\"PANCANCER_ATLAS_FILTERED\".\"CLINICAL_PANCAN_PATIENT_WITH_FOLLOWUP_FILTERED\"\n            WHERE \n                \"acronym\" = 'BRCA' \n                AND \"histological_type\" IS NOT NULL      \n        )\n    ),\n    table2 AS (\n        SELECT\n            \"symbol\",\n            \"ParticipantBarcode\"\n        FROM (\n            SELECT\n                \"Hugo_Symbol\" AS \"symbol\", \n                \"ParticipantBarcode\" AS \"ParticipantBarcode\"\n            FROM \n                \"PANCANCER_ATLAS_1\".\"PANCANCER_ATLAS_FILTERED\".\"MC3_MAF_V5_ONE_PER_TUMOR_SAMPLE\"\n            WHERE \n                \"Study\" = 'BRCA' \n                AND \"Hugo_Symbol\" = 'CDH1'\n                AND \"FILTER\" = 'PASS'  \n            GROUP BY\n                \"ParticipantBarcode\", \"symbol\"\n        )\n    ),\n    summ_table AS (\n        SELECT \n            n1.\"data\" AS \"data1\",\n            CASE \n                WHEN n2.\"ParticipantBarcode\" IS NULL THEN 'NO' \n                ELSE 'YES' \n            END AS \"data2\",\n            COUNT(*) AS \"Nij\"\n        FROM\n            table1 AS n1\n        LEFT JOIN\n            table2 AS n2 \n            ON n1.\"ParticipantBarcode\" = n2.\"ParticipantBarcode\"\n        GROUP BY\n            n1.\"data\", \"data2\"\n    ),\n    expected_table AS (\n        SELECT \n            \"data1\", \n            \"data2\"\n        FROM (     \n            SELECT \n                \"data1\", \n                SUM(\"Nij\") AS \"Ni\"   \n            FROM \n                summ_table\n            GROUP BY \n                \"data1\"\n        ) AS Ni_table\n        CROSS JOIN ( \n            SELECT \n                \"data2\", \n                SUM(\"Nij\") AS \"Nj\"\n            FROM \n                summ_table\n            GROUP BY \n                \"data2\"\n        ) AS Nj_table\n        WHERE \n            Ni_table.\"Ni\" > 10 \n            AND Nj_table.\"Nj\" > 10\n    ),\n    contingency_table AS (\n        SELECT\n            T1.\"data1\",\n            T1.\"data2\",\n            COALESCE(T2.\"Nij\", 0) AS \"Nij\",\n            (SUM(T2.\"Nij\") OVER (PARTITION BY T1.\"data1\")) * \n            (SUM(T2.\"Nij\") OVER (PARTITION BY T1.\"data2\")) / \n            SUM(T2.\"Nij\") OVER () AS \"E_nij\"\n        FROM\n            expected_table AS T1\n        LEFT JOIN\n            summ_table AS T2\n        ON \n            T1.\"data1\" = T2.\"data1\" \n            AND T1.\"data2\" = T2.\"data2\"\n    )\nSELECT\n    SUM( ( \"Nij\" - \"E_nij\" ) * ( \"Nij\" - \"E_nij\" ) / \"E_nij\" ) AS \"Chi2\"\nFROM \n    contingency_table;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: pancancer_atlas_2\nQuestion: Calculate the net difference between the number of pancreatic adenocarcinoma (PAAD) patients in TCGA's dataset who are confirmed to have mutations in both KRAS and TP53 genes, and those without mutations in either gene. Utilize patient clinical and follow-up data alongside genomic mutation details from TCGA\u2019s cancer genomics database, focusing specifically on PAAD studies where the mutations have passed quality filters."}, {"role": "assistant", "content": "WITH\nbarcodes AS (\n   SELECT bcr_patient_barcode AS ParticipantBarcode\n   FROM `isb-cgc-bq.pancancer_atlas.Filtered_clinical_PANCAN_patient_with_followup`\n   WHERE acronym = 'PAAD'\n)\n,table1 AS (\nSELECT\n   t1.ParticipantBarcode,\n   IF( t2.ParticipantBarcode is null, 'NO', 'YES') as data\nFROM\n   barcodes AS t1\nLEFT JOIN\n   (\n   SELECT\n      ParticipantBarcode AS ParticipantBarcode\n   FROM `isb-cgc-bq.pancancer_atlas.Filtered_MC3_MAF_V5_one_per_tumor_sample`\n   WHERE Study = 'PAAD' AND Hugo_Symbol = 'KRAS'\n         AND FILTER = 'PASS'\n   GROUP BY ParticipantBarcode\n   ) AS t2\nON t1.ParticipantBarcode = t2.ParticipantBarcode\n)\n,table2 AS (\nSELECT\n   t1.ParticipantBarcode,\n   IF( t2.ParticipantBarcode is null, 'NO', 'YES') as data\nFROM\n   barcodes AS t1\nLEFT JOIN\n   (\n   SELECT\n      ParticipantBarcode AS ParticipantBarcode\n   FROM `isb-cgc-bq.pancancer_atlas.Filtered_MC3_MAF_V5_one_per_tumor_sample`\n   WHERE Study = 'PAAD' AND Hugo_Symbol = 'TP53'\n         AND FILTER = 'PASS'\n   GROUP BY ParticipantBarcode\n   ) AS t2\nON t1.ParticipantBarcode = t2.ParticipantBarcode\n),\n\nINFO AS (\nSELECT\n   n1.data as data1,\n   n2.data as data2,\n   COUNT(*) as Nij\nFROM\n   table1 AS n1\nINNER JOIN\n   table2 AS n2\nON\n   n1.ParticipantBarcode = n2.ParticipantBarcode\nGROUP BY\n  data1, data2\n)\n\nSELECT \n(SELECT Nij FROM INFO WHERE data1=\"YES\" AND data2=\"YES\")\n-\n(SELECT Nij FROM INFO WHERE data1=\"NO\" AND data2=\"NO\")"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: pancancer_atlas_2\nQuestion: Using TCGA dataset, calculate the chi-squared statistic to evaluate the association between KRAS and TP53 gene mutations in patients diagnosed with pancreatic adenocarcinoma (PAAD). Incorporate clinical follow-up data and high-quality mutation annotations to accurately determine the frequency of patients with co-occurring KRAS and TP53 mutations compared to those with each mutation occurring independently. Ensure that patient records are meticulously matched based on unique identifiers to maintain data integrity. This analysis aims to identify and quantify potential correlations between KRAS and TP53 genetic alterations within the PAAD patient population."}, {"role": "assistant", "content": "WITH\nbarcodes AS (\n   SELECT bcr_patient_barcode AS ParticipantBarcode\n   FROM isb-cgc-bq.pancancer_atlas.Filtered_clinical_PANCAN_patient_with_followup\n   WHERE acronym = 'PAAD'\n),\ntable1 AS (\nSELECT\n   t1.ParticipantBarcode,\n   IF(t2.ParticipantBarcode IS NULL, 'NO', 'YES') AS data\nFROM\n   barcodes AS t1\nLEFT JOIN\n   (\n   SELECT\n      ParticipantBarcode AS ParticipantBarcode\n   FROM isb-cgc-bq.pancancer_atlas.Filtered_MC3_MAF_V5_one_per_tumor_sample\n   WHERE Study = 'PAAD' AND Hugo_Symbol = 'KRAS'\n         AND FILTER = 'PASS'\n   GROUP BY ParticipantBarcode\n   ) AS t2\nON t1.ParticipantBarcode = t2.ParticipantBarcode\n),\ntable2 AS (\nSELECT\n   t1.ParticipantBarcode,\n   IF(t2.ParticipantBarcode IS NULL, 'NO', 'YES') AS data\nFROM\n   barcodes AS t1\nLEFT JOIN\n   (\n   SELECT\n      ParticipantBarcode AS ParticipantBarcode\n   FROM isb-cgc-bq.pancancer_atlas.Filtered_MC3_MAF_V5_one_per_tumor_sample\n   WHERE Study = 'PAAD' AND Hugo_Symbol = 'TP53'\n         AND FILTER = 'PASS'\n   GROUP BY ParticipantBarcode\n   ) AS t2\nON t1.ParticipantBarcode = t2.ParticipantBarcode\n),\nsumm_table AS (\nSELECT\n   n1.data AS data1,\n   n2.data AS data2,\n   COUNT(*) AS Nij\nFROM\n   table1 AS n1\nINNER JOIN\n   table2 AS n2\nON\n   n1.ParticipantBarcode = n2.ParticipantBarcode\nGROUP BY\n  data1, data2\n),\ncontingency_table AS (\nSELECT\n  MAX(IF((data1 = 'YES') AND (data2 = 'YES'), Nij, 0)) AS a,\n  MAX(IF((data1 = 'YES') AND (data2 = 'NO'), Nij, 0)) AS b,\n  MAX(IF((data1 = 'NO') AND (data2 = 'YES'), Nij, 0)) AS c,\n  MAX(IF((data1 = 'NO') AND (data2 = 'NO'), Nij, 0)) AS d,\n  (MAX(IF((data1 = 'YES') AND (data2 = 'YES'), Nij, 0)) + MAX(IF((data1 = 'YES') AND (data2 = 'NO'), Nij, 0))) AS row1_total,\n  (MAX(IF((data1 = 'NO') AND (data2 = 'YES'), Nij, 0)) + MAX(IF((data1 = 'NO') AND (data2 = 'NO'), Nij, 0))) AS row2_total,\n  (MAX(IF((data1 = 'YES') AND (data2 = 'YES'), Nij, 0)) + MAX(IF((data1 = 'NO') AND (data2 = 'YES'), Nij, 0))) AS col1_total,\n  (MAX(IF((data1 = 'YES') AND (data2 = 'NO'), Nij, 0)) + MAX(IF((data1 = 'NO') AND (data2 = 'NO'), Nij, 0))) AS col2_total,\n  SUM(Nij) AS grand_total\nFROM summ_table\n)\nSELECT\n  POWER((a - (row1_total * col1_total) / grand_total), 2) / ((row1_total * col1_total) / grand_total) +\n  POWER((b - (row1_total * col2_total) / grand_total), 2) / ((row1_total * col2_total) / grand_total) +\n  POWER((c - (row2_total * col1_total) / grand_total), 2) / ((row2_total * col1_total) / grand_total) +\n  POWER((d - (row2_total * col2_total) / grand_total), 2) / ((row2_total * col2_total) / grand_total) AS chi_square_statistic\nFROM contingency_table\nWHERE a IS NOT NULL AND b IS NOT NULL AND c IS NOT NULL AND d IS NOT NULL;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: TCGA_MITELMAN\nQuestion: Using segment-level copy number data from the copy_number_segment_allelic_hg38_gdc_r23 dataset restricted to 'TCGA-KIRC' samples, merge these segments with the cytogenetic band definitions in 'CytoBands_hg38' to identify each sample\u2019s maximum copy number per cytoband. Classify these maximum copy numbers into amplifications (>3), gains (=3), homozygous deletions (=0), heterozygous deletions (=1), or normal (=2), then calculate the frequency of each subtype out of the total number of distinct cases, and finally present these frequencies as percentages sorted by chromosome and cytoband.\n\nExternal Knowledge: Comprehensive_Guide_to_Copy_Number_Variations_in_Cancer_Genomics.md"}, {"role": "assistant", "content": "WITH copy AS (\n  SELECT \n    \"case_barcode\", \n    \"chromosome\", \n    \"start_pos\", \n    \"end_pos\", \n    MAX(\"copy_number\") AS \"copy_number\"\n  FROM \n    \"TCGA_MITELMAN\".\"TCGA_VERSIONED\".\"COPY_NUMBER_SEGMENT_ALLELIC_HG38_GDC_R23\" \n  WHERE  \n    \"project_short_name\" = 'TCGA-KIRC'\n  GROUP BY \n    \"case_barcode\", \n    \"chromosome\", \n    \"start_pos\", \n    \"end_pos\"\n),\ntotal_cases AS (\n  SELECT COUNT(DISTINCT \"case_barcode\") AS \"total\"\n  FROM copy \n),\ncytob AS (\n  SELECT \n    \"chromosome\", \n    \"cytoband_name\", \n    \"hg38_start\", \n    \"hg38_stop\"\n  FROM \n    \"TCGA_MITELMAN\".\"PROD\".\"CYTOBANDS_HG38\"\n),\njoined AS (\n  SELECT \n    cytob.\"chromosome\", \n    cytob.\"cytoband_name\", \n    cytob.\"hg38_start\", \n    cytob.\"hg38_stop\",\n    copy.\"case_barcode\",\n    copy.\"copy_number\"  \n  FROM \n    copy\n  LEFT JOIN cytob\n    ON cytob.\"chromosome\" = copy.\"chromosome\" \n  WHERE \n    (cytob.\"hg38_start\" >= copy.\"start_pos\" AND copy.\"end_pos\" >= cytob.\"hg38_start\")\n    OR (copy.\"start_pos\" >= cytob.\"hg38_start\" AND copy.\"start_pos\" <= cytob.\"hg38_stop\")\n),\ncbands AS (\n  SELECT \n    \"chromosome\", \n    \"cytoband_name\", \n    \"hg38_start\", \n    \"hg38_stop\", \n    \"case_barcode\",\n    MAX(\"copy_number\") AS \"copy_number\"\n  FROM \n    joined\n  GROUP BY \n    \"chromosome\", \n    \"cytoband_name\", \n    \"hg38_start\", \n    \"hg38_stop\", \n    \"case_barcode\"\n),\naberrations AS (\n  SELECT\n    \"chromosome\",\n    \"cytoband_name\",\n    -- Amplifications: more than two copies for diploid > 4\n    SUM( CASE WHEN \"copy_number\" > 3 THEN 1 ELSE 0 END ) AS \"total_amp\",\n    -- Gains: at most two extra copies\n    SUM( CASE WHEN \"copy_number\" = 3 THEN 1 ELSE 0 END ) AS \"total_gain\",\n    -- Homozygous deletions, or complete deletions\n    SUM( CASE WHEN \"copy_number\" = 0 THEN 1 ELSE 0 END ) AS \"total_homodel\",\n    -- Heterozygous deletions, 1 copy lost\n    SUM( CASE WHEN \"copy_number\" = 1 THEN 1 ELSE 0 END ) AS \"total_heterodel\",\n    -- Normal for Diploid = 2\n    SUM( CASE WHEN \"copy_number\" = 2 THEN 1 ELSE 0 END ) AS \"total_normal\"\n  FROM \n    cbands\n  GROUP BY \n    \"chromosome\", \n    \"cytoband_name\"\n)\nSELECT \n  aberrations.\"chromosome\", \n  aberrations.\"cytoband_name\",\n  total_cases.\"total\",  \n  100 * aberrations.\"total_amp\" / total_cases.\"total\" AS \"freq_amp\", \n  100 * aberrations.\"total_gain\" / total_cases.\"total\" AS \"freq_gain\",\n  100 * aberrations.\"total_homodel\" / total_cases.\"total\" AS \"freq_homodel\", \n  100 * aberrations.\"total_heterodel\" / total_cases.\"total\" AS \"freq_heterodel\", \n  100 * aberrations.\"total_normal\" / total_cases.\"total\" AS \"freq_normal\"  \nFROM \n  aberrations, \n  total_cases\nORDER BY \n  aberrations.\"chromosome\", \n  aberrations.\"cytoband_name\";"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: austin\nQuestion: Can you provide the number of distinct active and closed bike share stations for each year 2013 and 2014?"}, {"role": "assistant", "content": "SELECT\n    t.year,\n    CASE \n        WHEN t.year = 2013 THEN (\n                                  SELECT \n                                    COUNT(DISTINCT station_id)\n                                  FROM \n                                    `bigquery-public-data.austin_bikeshare.bikeshare_trips` t\n                                  INNER JOIN \n                                    `bigquery-public-data.austin_bikeshare.bikeshare_stations` s\n                                  ON \n                                    t.start_station_id = s.station_id\n                                  WHERE \n                                    s.status = 'active' AND EXTRACT(YEAR FROM start_time) = 2013\n                                 ) \n        WHEN t.year = 2014 THEN (\n                                  SELECT \n                                    COUNT(DISTINCT station_id)\n                                  FROM \n                                    `bigquery-public-data.austin_bikeshare.bikeshare_trips` t\n                                  INNER JOIN \n                                    `bigquery-public-data.austin_bikeshare.bikeshare_stations` s\n                                  ON \n                                    t.start_station_id = s.station_id\n                                  WHERE \n                                    s.status = 'active' AND EXTRACT(YEAR FROM start_time) = 2014\n                                 )\n    END\n    AS number_status_active,\n    CASE \n        WHEN t.year = 2013 THEN (\n                                  SELECT \n                                   COUNT(DISTINCT station_id)\n                                  FROM \n                                  `bigquery-public-data.austin_bikeshare.bikeshare_trips` t\n                                  INNER JOIN \n                                  `bigquery-public-data.austin_bikeshare.bikeshare_stations` s\n                                  ON \n                                   t.start_station_id = s.station_id\n                                  WHERE \n                                   s.status = 'closed' AND EXTRACT(YEAR FROM start_time) = 2013\n                                 ) \n        WHEN t.year = 2014 THEN (\n                                  SELECT \n                                  COUNT(DISTINCT station_id)\n                                  FROM \n                                    `bigquery-public-data.austin_bikeshare.bikeshare_trips` t\n                                  INNER JOIN \n                                    `bigquery-public-data.austin_bikeshare.bikeshare_stations` s\n                                  ON \n                                    t.start_station_id = s.station_id\n                                  WHERE \n                                    s.status = 'closed' AND EXTRACT(YEAR FROM start_time) = 2014\n                                 )\n    END\n    AS number_status_closed\nFROM\n    (\n      SELECT \n         EXTRACT(YEAR FROM start_time) AS year,\n         start_station_id\n      FROM\n         `bigquery-public-data.austin_bikeshare.bikeshare_trips`\n    ) \n    AS t\nINNER JOIN\n    `bigquery-public-data.austin_bikeshare.bikeshare_stations` s\nON\n    t.start_station_id = s.station_id\nWHERE\n    t.year BETWEEN 2013 AND 2014\nGROUP BY\n    t.year\nORDER BY\n    t.year"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: austin\nQuestion: What is the highest number of electric bike rides lasting more than 10 minutes taken by subscribers with 'Student Membership' in a single day, excluding rides starting or ending at 'Mobile Station' or 'Repair Shop'?"}, {"role": "assistant", "content": "SELECT\n  COUNT(1) AS num_rides\nFROM\n  `bigquery-public-data.austin_bikeshare.bikeshare_trips` \nWHERE \nstart_station_name \n    NOT IN ('Mobile Station', 'Repair Shop')\nAND\nend_station_name \n    NOT IN ('Mobile Station', 'Repair Shop')\nAND \nsubscriber_type = 'Student Membership'\nAND\nbike_type = 'electric'\nAND\nduration_minutes > 10\nGROUP BY \n    EXTRACT(YEAR from start_time), \n    EXTRACT(MONTH from start_time), \n    EXTRACT(DAY from start_time)\nORDER BY num_rides DESC\nLIMIT 1"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: austin\nQuestion: Can you tell me the numeric value of the active council district in Austin which has the highest number of bike trips that start and end within the same district, but not at the same station?"}, {"role": "assistant", "content": "SELECT \n  district\nFROM (\n  SELECT\n    S.starting_district AS district,\n    T.start_station_id,\n    T.end_station_id\n  FROM\n    `bigquery-public-data.austin_bikeshare.bikeshare_trips` AS T\n  INNER JOIN (\n    SELECT\n      station_id,\n      council_district AS starting_district\n    FROM\n      `bigquery-public-data.austin_bikeshare.bikeshare_stations`\n    WHERE\n      status = \"active\"\n  ) AS S ON T.start_station_id = S.station_id\n  WHERE\n    S.starting_district IN (\n      SELECT council_district\n      FROM `bigquery-public-data.austin_bikeshare.bikeshare_stations`\n      WHERE\n        status = \"active\" AND\n        station_id = SAFE_CAST(T.end_station_id AS INT64)\n    )\n    AND T.start_station_id != SAFE_CAST(T.end_station_id AS INT64)\n) \nGROUP BY district\nORDER BY COUNT(*) DESC\nLIMIT 1;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: austin\nQuestion: What is the date with the second highest Z-score for daily counts of 'PUBLIC INTOXICATION' incidents in Austin for the year 2016? List the date in the format of '2016-xx-xx'."}, {"role": "assistant", "content": "WITH incident_stats AS (\n  SELECT \n    COUNT(descript) AS total_pub_intox\n  FROM \n    `bigquery-public-data.austin_incidents.incidents_2016` \n  WHERE \n    descript = 'PUBLIC INTOXICATION' \n  GROUP BY \n    date\n),\naverage_and_stddev AS (\n  SELECT \n    AVG(total_pub_intox) AS avg, \n    STDDEV(total_pub_intox) AS stddev \n  FROM \n    incident_stats\n),\ndaily_z_scores AS (\n  SELECT \n    date, \n    COUNT(descript) AS total_pub_intox, \n    ROUND((COUNT(descript) - a.avg) / a.stddev, 2) AS z_score\n  FROM \n    `bigquery-public-data.austin_incidents.incidents_2016`,\n    (SELECT avg, stddev FROM average_and_stddev) AS a\n  WHERE \n    descript = 'PUBLIC INTOXICATION'\n  GROUP BY \n    date, avg, stddev\n)\n\nSELECT \n  date\nFROM \n  daily_z_scores\nORDER BY \n  z_score DESC\nLIMIT 1\nOFFSET 1"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: bbc\nQuestion: Can you provide a breakdown of the total number of articles into different categories and the percentage of those articles that mention \"education\" within each category from the BBC News?"}, {"role": "assistant", "content": "SELECT \n  category,\n  COUNT(*) AS number_total_by_category,  \n  CASE \n    WHEN category = 'tech' THEN \n          (SELECT count(*)\n                FROM `bigquery-public-data.bbc_news.fulltext`\n                WHERE (LOWER(body) LIKE '%education%') AND category = 'tech') * 100 /\n                (SELECT count(*)\n                FROM `bigquery-public-data.bbc_news.fulltext`\n                WHERE category = 'tech')\n    WHEN category = 'sport' THEN \n          (SELECT count(*)\n                FROM `bigquery-public-data.bbc_news.fulltext`\n                WHERE (LOWER(body) LIKE '%education%') AND category = 'sport') * 100 /\n                (SELECT count(*)\n                FROM `bigquery-public-data.bbc_news.fulltext`\n                WHERE category = 'sport')\n    WHEN category = 'business' THEN \n          (SELECT count(*)\n                FROM `bigquery-public-data.bbc_news.fulltext`\n                WHERE (LOWER(body) LIKE '%education%') AND category = 'business') * 100 /\n                (SELECT count(*)\n                FROM `bigquery-public-data.bbc_news.fulltext`\n                WHERE category = 'business')\n    WHEN category = 'politics' THEN \n          (SELECT count(*)\n                FROM `bigquery-public-data.bbc_news.fulltext`\n                WHERE (LOWER(body) LIKE '%education%') AND category = 'politics') * 100 /\n                (SELECT count(*)\n                FROM `bigquery-public-data.bbc_news.fulltext`\n                WHERE category = 'politics')\n    WHEN category = 'entertainment' THEN \n          (SELECT count(*)\n                FROM `bigquery-public-data.bbc_news.fulltext`\n                WHERE (LOWER(body) LIKE '%education%') AND category = 'entertainment') * 100 /\n                (SELECT count(*)\n                FROM `bigquery-public-data.bbc_news.fulltext`\n                WHERE category = 'entertainment')\n  END AS percent_education\nFROM `bigquery-public-data.bbc_news.fulltext`\nGROUP BY\n  category;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: dimensions_ai_covid19\nQuestion: Retrieve the venue titles of publications that have a `date_inserted` from the year 2021 onwards and are associated with a grid whose address city is 'Qianjiang'. For each publication, prioritize the venue title by selecting the journal title first if it exists; if not, then the proceedings title; if that's also unavailable, then the book title; and finally, if none of those are available, the book series title."}, {"role": "assistant", "content": "SELECT\n   COALESCE(p.journal.title, p.proceedings_title.preferred, p.book_title.preferred, p.book_series_title.preferred) AS venue,\nFROM\n   `bigquery-public-data.dimensions_ai_covid19.publications` p\nLEFT JOIN\n   UNNEST(research_orgs) AS research_orgs_grids\nLEFT JOIN\n   `bigquery-public-data.dimensions_ai_covid19.grid` grid\nON\n   grid.id=research_orgs_grids\nWHERE\n   EXTRACT(YEAR FROM date_inserted) >= 2021\n   AND\n   grid.address.city = 'Qianjiang'"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: ebi_chembl\nQuestion: Using data from ChEMBL Release 23, retrieve all distinct molecules associated with the company 'SanofiAventis,' listing the trade name and the most recent approval date for each molecule. Make sure to keep only the latest approval date per molecule and ensure the company field precisely matches 'SanofiAventis' without relying on other fields."}, {"role": "assistant", "content": "SELECT *\n  FROM (\n  SELECT\n  molregno,\n  comp.company,\n  prod.trade_name,\n  prod.approval_date,\n  ROW_NUMBER() OVER(PARTITION BY molregno ORDER BY PARSE_DATE('%Y-%m-%d', prod.approval_date) DESC) rn\n  FROM bigquery-public-data.ebi_chembl.compound_records_23 AS cmpd_rec\n  JOIN bigquery-public-data.ebi_chembl.molecule_synonyms_23 AS ms USING (molregno)\n  JOIN bigquery-public-data.ebi_chembl.research_companies_23 AS comp USING (res_stem_id)\n  JOIN bigquery-public-data.ebi_chembl.formulations_23 AS form USING (molregno)\n  JOIN bigquery-public-data.ebi_chembl.products_23 AS prod USING (product_id)\n  ) as subq\n WHERE rn = 1 AND company = 'SanofiAventis'"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: ebi_chembl\nQuestion: Find pairs of different molecules tested in the same assay and standard type, where both have 10\u201315 heavy atoms, fewer than 5 activities in that assay, fewer than 2 duplicate activities, non-null standard values, and pChEMBL values over 10. For each pair, report the maximum heavy atom count, the latest publication date (calculated based on the document's rank within the same journal and year, and map it to a synthetic month and day), the highest document ID, classify the change in standard values as 'increase', 'decrease', or 'no-change' based on their values and relations, and generate UUIDs from their activity IDs and canonical SMILES.\n\nExternal Knowledge: chembl.md"}, {"role": "assistant", "content": "select \n  -- *, \n  greatest(heavy_atoms_1, heavy_atoms_2) as heavy_atoms_greatest,\n  greatest(publication_date_1, publication_date_2) as publication_date_greatest,\n  greatest(doc_id_1, doc_id_2) as doc_id_greatest,\n  case \n    when \n      standard_value_1 > standard_value_2 and \n      standard_relation_1 not in ('<', '<<') and \n      standard_relation_2 not in ('>', '>>')\n    then 'decrease'\n    when\n      standard_value_1 < standard_value_2 and \n      standard_relation_1 not in ('>', '>>') and \n      standard_relation_2 not in ('<', '<<') \n    then 'increase'\n    when\n      standard_value_1 = standard_value_2 and \n      standard_relation_1 in ('=', '~') and \n      standard_relation_2 in ('=', '~') \n    then 'no-change'\n    else null\n  end as standard_change,\n  to_hex(md5(to_json_string(struct(activity_id_1, activity_id_2)))) as mmp_delta_uuid,\n  to_hex(md5(to_json_string(struct(canonical_smiles_1, canonical_smiles_2, 5)))) as mmp_search_uuid\nfrom (\n  select \n    act.assay_id,\n    act.standard_type,\n    act.activity_id as activity_id_1,\n    cast(act.standard_value as numeric) as standard_value_1,\n    act.standard_relation as standard_relation_1,\n    cast(act.pchembl_value as numeric) as pchembl_value_1,\n    count(*) over (partition by act.assay_id) as count_activities_1,\n    count(*) over (partition by act.assay_id, act.molregno) as duplicate_activities_1,\n    act.molregno as molregno_1,\n    com.canonical_smiles as canonical_smiles_1,\n    cast(cmp.heavy_atoms as int64) as heavy_atoms_1,\n    cast(d.doc_id as int64) as doc_id_1,\n    date(\n      coalesce(cast(d.year as int64), 1970), \n      coalesce(cast(floor(percent_rank() over (\n        partition by d.journal, d.year order by SAFE_CAST(d.first_page as int64)) * 11) as int64) + 1, 1),\n      coalesce(mod(cast(floor(percent_rank() over (\n        partition by d.journal, d.year order by SAFE_CAST(d.first_page as int64)) * 308) as int64), 28) + 1, 1)) as publication_date_1\n  FROM `bigquery-public-data.ebi_chembl.activities_29` act\n  join `bigquery-public-data.ebi_chembl.compound_structures_29` com using (molregno)\n  join `bigquery-public-data.ebi_chembl.compound_properties_29` cmp using (molregno)\n  left join `bigquery-public-data.ebi_chembl.docs_29` d using (doc_id)\n  where standard_type in (select distinct standard_type from`bigquery-public-data.ebi_chembl.activities_29` where pchembl_value is not null)\n  ) a1\njoin (\n  select \n    act.assay_id,\n    act.standard_type,\n    act.activity_id as activity_id_2,\n    cast(act.standard_value as numeric) as standard_value_2,\n    act.standard_relation as standard_relation_2,\n    cast(act.pchembl_value as numeric) as pchembl_value_2,\n    count(*) over (partition by act.assay_id) as count_activities_2,\n    count(*) over (partition by act.assay_id, act.molregno) as duplicate_activities_2, \n    act.molregno as molregno_2,\n    com.canonical_smiles as canonical_smiles_2, \n    cast(cmp.heavy_atoms as int64) as heavy_atoms_2,\n    cast(d.doc_id as int64) as doc_id_2,\n    date(\n      coalesce(cast(d.year as int64), 1970), \n      coalesce(cast(floor(percent_rank() over (\n        partition by d.journal, d.year order by SAFE_CAST(d.first_page as int64)) * 11) as int64) + 1, 1),\n      coalesce(mod(cast(floor(percent_rank() over (\n        partition by d.journal, d.year order by SAFE_CAST(d.first_page as int64)) * 308) as int64), 28) + 1, 1)) as publication_date_2\n  FROM `bigquery-public-data.ebi_chembl.activities_29` act\n  join `bigquery-public-data.ebi_chembl.compound_structures_29` com using (molregno)\n  join `bigquery-public-data.ebi_chembl.compound_properties_29` cmp using (molregno)\n  left join `bigquery-public-data.ebi_chembl.docs_29` d using (doc_id)\n  where standard_type in (select distinct standard_type from`bigquery-public-data.ebi_chembl.activities_29` where pchembl_value is not null)\n  ) a2 using (assay_id, standard_type)\nwhere \n  a1.molregno_1 != a2.molregno_2 and\n  a1.count_activities_1 < 5 and \n  a2.count_activities_2 < 5 and \n  a1.heavy_atoms_1 between 10 and 15 and\n  a2.heavy_atoms_2 between 10 and 15 and\n  a1.standard_value_1 is not null and \n  a2.standard_value_2 is not null and\n  a1.duplicate_activities_1 < 2 and\n  a2.duplicate_activities_2 < 2 and\n  a1.pchembl_value_1 > 10 and\n  a2.pchembl_value_2 > 10"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: fda\nQuestion: Could you provide me with the zip code of the location that has the highest number of bank institutions in Florida?"}, {"role": "assistant", "content": "with _fips AS\n    (\n        SELECT\n            state_fips_code\n        FROM\n            `bigquery-public-data.census_utility.fips_codes_states`\n        WHERE\n            state_name = \"Florida\"\n    )\n\n    ,_zip AS\n    (\n        SELECT\n            z.zip_code,\n            z.zip_code_geom,\n        FROM\n            `bigquery-public-data.geo_us_boundaries.zip_codes` z, _fips u\n        WHERE\n            z.state_fips_code = u.state_fips_code\n    )\n\n    ,locations AS\n    (\n        SELECT\n            COUNT(i.institution_name) AS count_locations,\n            l.zip_code\n        FROM\n            `bigquery-public-data.fdic_banks.institutions` i\n        JOIN\n            `bigquery-public-data.fdic_banks.locations` l \n        USING (fdic_certificate_number)\n        WHERE\n            l.state IS NOT NULL\n        AND \n            l.state_name IS NOT NULL\n        GROUP BY 2\n    )\n\n    SELECT\n        z.zip_code\n    FROM\n        _zip z\n    JOIN\n        locations l \n    USING (zip_code)\n    GROUP BY\n        z.zip_code\n    ORDER BY\n        SUM(l.count_locations) DESC\n    LIMIT 1;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: GOOGLE_ADS\nQuestion: Please retrieve the page URLs, first shown time, last shown time, removal reason, violation category, and the lower and upper bounds of times shown for the five most recently removed ads in the Croatia region (region code 'HR'), where the times shown availability date is null, the times shown lower bound exceeds 10,000, the times shown upper bound is below 25,000, and the ads used at least one non-unused audience selection approach among demographics, geographic location, contextual signals, customer lists, or topics of interest, ordering the resulting ads by their last shown time in descending order."}, {"role": "assistant", "content": "SELECT\n    \"creative_page_url\",\n    TO_TIMESTAMP(GET(\"region_stat\".value, 'first_shown')) AS \"first_shown\",\n    TO_TIMESTAMP(GET(\"region_stat\".value, 'last_shown')) AS \"last_shown\",\n    REPLACE(REPLACE(\"disapproval\"[0].\"removal_reason\", '\"\"', '\"'), '\"', '') AS \"removal_reason\", \n    REPLACE(REPLACE(\"disapproval\"[0].\"violation_category\", '\"\"', '\"'), '\"', '') AS \"violation_category\",\n    GET(\"region_stat\".value, 'times_shown_lower_bound') AS \"times_shown_lower\",\n    GET(\"region_stat\".value, 'times_shown_upper_bound') AS \"times_shown_upper\"\nFROM\n    \"GOOGLE_ADS\".\"GOOGLE_ADS_TRANSPARENCY_CENTER\".\"REMOVED_CREATIVE_STATS\",\n    LATERAL FLATTEN(input => \"region_stats\") AS \"region_stat\"\nWHERE\n    GET(\"region_stat\".value, 'region_code') = 'HR' \n    AND GET(\"region_stat\".value, 'times_shown_availability_date') IS NULL \n    AND GET(\"region_stat\".value, 'times_shown_lower_bound') > 10000 \n    AND GET(\"region_stat\".value, 'times_shown_upper_bound') < 25000\n    AND (\n        GET(\"audience_selection_approach_info\", 'demographic_info') != 'CRITERIA_UNUSED' \n        OR GET(\"audience_selection_approach_info\", 'geo_location') != 'CRITERIA_UNUSED' \n        OR GET(\"audience_selection_approach_info\", 'contextual_signals') != 'CRITERIA_UNUSED' \n        OR GET(\"audience_selection_approach_info\", 'customer_lists') != 'CRITERIA_UNUSED' \n        OR GET(\"audience_selection_approach_info\", 'topics_of_interest') != 'CRITERIA_UNUSED'\n    )\nORDER BY\n    \"last_shown\" DESC\nLIMIT 5;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: IDC\nQuestion: Could you provide a clean, structured dataset from dicom_all table that only includes SM images marked as VOLUME from the TCGA-LUAD and TCGA-LUSC collections, excluding any slides with compression type \u201cother,\u201d where the specimen preparation step explicitly has \u201cEmbedding medium\u201d set to \u201cTissue freezing medium,\u201d and ensuring that the tissue type is only \u201cnormal\u201d or \u201ctumor\u201d and the cancer subtype is reported accordingly?\n\nExternal Knowledge: dicom_dataset_selection.md"}, {"role": "assistant", "content": "WITH\n  sm_images AS (\n    SELECT\n      \"SeriesInstanceUID\" AS \"digital_slide_id\", \n      \"StudyInstanceUID\" AS \"case_id\",\n      \"ContainerIdentifier\" AS \"physical_slide_id\",\n      \"PatientID\" AS \"patient_id\",\n      \"TotalPixelMatrixColumns\" AS \"width\", \n      \"TotalPixelMatrixRows\" AS \"height\",\n      \"collection_id\",\n      \"crdc_instance_uuid\",\n      \"gcs_url\", \n      CAST(\n        \"SharedFunctionalGroupsSequence\"[0].\"PixelMeasuresSequence\"[0].\"PixelSpacing\"[0] AS FLOAT\n      ) AS \"pixel_spacing\", \n      CASE \"TransferSyntaxUID\"\n          WHEN '1.2.840.10008.1.2.4.50' THEN 'jpeg'\n          WHEN '1.2.840.10008.1.2.4.91' THEN 'jpeg2000'\n          ELSE 'other'\n      END AS \"compression\"\n    FROM\n      IDC.IDC_V17.DICOM_ALL\n    WHERE\n      \"Modality\" = 'SM' \n      AND \"ImageType\"[2] = 'VOLUME'\n  ),\n\n  tissue_types AS (\n    SELECT DISTINCT *\n    FROM (\n      SELECT\n        \"SeriesInstanceUID\" AS \"digital_slide_id\",\n        CASE \"steps_unnested2\".value:\"CodeValue\"::STRING\n            WHEN '17621005' THEN 'normal' -- meaning: 'Normal' (i.e., non-neoplastic)\n            WHEN '86049000' THEN 'tumor'  -- meaning: 'Neoplasm, Primary'\n            ELSE 'other'                 -- meaning: 'Neoplasm, Metastatic'\n        END AS \"tissue_type\"\n      FROM\n        IDC.IDC_V17.DICOM_ALL\n        CROSS JOIN\n          LATERAL FLATTEN(input => \"SpecimenDescriptionSequence\"[0].\"PrimaryAnatomicStructureSequence\") AS \"steps_unnested1\"\n        CROSS JOIN\n          LATERAL FLATTEN(input => \"steps_unnested1\".value:\"PrimaryAnatomicStructureModifierSequence\") AS \"steps_unnested2\"\n    )\n  ),\n\n  specimen_preparation_sequence_items AS (\n    SELECT DISTINCT *\n    FROM (\n      SELECT\n        \"SeriesInstanceUID\" AS \"digital_slide_id\",\n        \"steps_unnested2\".value:\"ConceptNameCodeSequence\"[0].\"CodeMeaning\"::STRING AS \"item_name\",\n        \"steps_unnested2\".value:\"ConceptCodeSequence\"[0].\"CodeMeaning\"::STRING AS \"item_value\"\n      FROM\n        IDC.IDC_V17.DICOM_ALL\n        CROSS JOIN\n          LATERAL FLATTEN(input => \"SpecimenDescriptionSequence\"[0].\"SpecimenPreparationSequence\") AS \"steps_unnested1\"\n        CROSS JOIN\n          LATERAL FLATTEN(input => \"steps_unnested1\".value:\"SpecimenPreparationStepContentItemSequence\") AS \"steps_unnested2\"\n    )\n  )\n\nSELECT\n  a.*,\n  b.\"tissue_type\",\n  REPLACE(REPLACE(a.\"collection_id\", 'tcga_luad', 'luad'), 'tcga_lusc', 'lscc') AS \"cancer_subtype\"\nFROM \n  sm_images AS a\n  JOIN tissue_types AS b \n    ON b.\"digital_slide_id\" = a.\"digital_slide_id\"\n  JOIN specimen_preparation_sequence_items AS c \n    ON c.\"digital_slide_id\" = a.\"digital_slide_id\"\nWHERE\n  (a.\"collection_id\" = 'tcga_luad' OR a.\"collection_id\" = 'tcga_lusc')\n  AND a.\"compression\" != 'other'\n  AND (b.\"tissue_type\" = 'normal' OR b.\"tissue_type\" = 'tumor')\n  AND (c.\"item_name\" = 'Embedding medium' AND c.\"item_value\" = 'Tissue freezing medium')\nORDER BY \n  a.\"crdc_instance_uuid\";"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: IDC\nQuestion: In the dicom_pivot table, how many unique StudyInstanceUID values exactly match the SegmentedPropertyTypeCodeSequence of \"15825003\" (case-insensitive) and also have a collection_id of either \"Community\" or \"nsclc_radiomics\"?"}, {"role": "assistant", "content": "SELECT\n  COUNT(*) AS \"total_count\"\nFROM\n  IDC.IDC_V17.DICOM_PIVOT AS \"dicom_pivot\"\nWHERE\n  \"StudyInstanceUID\" IN (\n    SELECT\n      \"StudyInstanceUID\"\n    FROM\n      IDC.IDC_V17.DICOM_PIVOT AS \"dicom_pivot\"\n    WHERE\n      \"StudyInstanceUID\" IN (\n        SELECT\n          \"StudyInstanceUID\"\n        FROM\n          IDC.IDC_V17.DICOM_PIVOT AS \"dicom_pivot\"\n        WHERE\n          LOWER(\"dicom_pivot\".\"SegmentedPropertyTypeCodeSequence\") LIKE LOWER('15825003')\n        GROUP BY\n          \"StudyInstanceUID\"\n        INTERSECT\n        SELECT\n          \"StudyInstanceUID\"\n        FROM\n          IDC.IDC_V17.DICOM_PIVOT AS \"dicom_pivot\"\n        WHERE\n          \"dicom_pivot\".\"collection_id\" IN ('Community', 'nsclc_radiomics')\n        GROUP BY\n          \"StudyInstanceUID\"\n      )\n    GROUP BY\n      \"StudyInstanceUID\"\n  );"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: IDC\nQuestion: How many unique StudyInstanceUIDs are there from the DWI, T2 Weighted Axial, Apparent Diffusion Coefficient series, and T2 Weighted Axial Segmentations in the 'qin_prostate_repeatability' collection?"}, {"role": "assistant", "content": "WITH relevant_series AS (\n  SELECT \n    DISTINCT \"StudyInstanceUID\"\n  FROM \n    IDC.IDC_V17.DICOM_ALL\n  WHERE \n    \"collection_id\" = 'qin_prostate_repeatability'\n    AND \"SeriesDescription\" IN (\n      'DWI',\n      'T2 Weighted Axial',\n      'Apparent Diffusion Coefficient',\n      'T2 Weighted Axial Segmentations',\n      'Apparent Diffusion Coefficient Segmentations'\n    )    \n),\nt2_seg_lesion_series AS (\n  SELECT \n    DISTINCT \"StudyInstanceUID\"\n  FROM \n    IDC.IDC_V17.DICOM_ALL\n  CROSS JOIN LATERAL FLATTEN(input => \"SegmentSequence\") AS segSeq\n  WHERE \n    \"collection_id\" = 'qin_prostate_repeatability'\n    AND \"SeriesDescription\" = 'T2 Weighted Axial Segmentations'\n)\n\nSELECT \n    COUNT(DISTINCT \"StudyInstanceUID\") AS \"total_count\"\nFROM (\n  SELECT \n    \"StudyInstanceUID\" \n  FROM relevant_series\n  UNION ALL\n  SELECT \n    \"StudyInstanceUID\"\n  FROM t2_seg_lesion_series\n);"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: IDC\nQuestion: Identify the top five CT scan series by size (in MiB), including their SeriesInstanceUID, series number, patient ID, and series size. These series must be from the CT modality and not part of the 'nlst' collection. Exclude any series where the ImageType is classified as 'LOCALIZER' or where the TransferSyntaxUID is either '1.2.840.10008.1.2.4.70' or '1.2.840.10008.1.2.4.51' (i.e., JPEG compressed). The selected series must have consistent slice intervals, exposure levels, image orientation (with only one unique ImageOrientationPatient value), pixel spacing, image positions (both z-axis and xy positions), and pixel dimensions (rows and columns). Ensure that the number of images matches the number of unique z-axis positions, indicating no duplicate slices. Additionally, the z-axis component of the cross product of the x and y direction cosines from ImageOrientationPatient must have an absolute value between 0.99 and 1.01, ensuring alignment with the expected imaging plane. Finally, order the results by series size in descending order and limit the output to the top five series satisfying these conditions."}, {"role": "assistant", "content": "WITH\n  -- Create a common table expression (CTE) named localizerAndJpegCompressedSeries\n  localizerAndJpegCompressedSeries AS (\n    SELECT \n      \"SeriesInstanceUID\"\n    FROM \n      IDC.IDC_V17.\"DICOM_ALL\" AS bid\n    WHERE \n      \"ImageType\" = 'LOCALIZER' OR\n      \"TransferSyntaxUID\" IN ('1.2.840.10008.1.2.4.70', '1.2.840.10008.1.2.4.51')\n  ),\n  \n  -- Create a common table expression (CTE) for x_vector calculation (first three elements)\n  imageOrientation AS (\n    SELECT\n      \"SeriesInstanceUID\",\n      ARRAY_AGG(CAST(part.value AS FLOAT)) AS \"x_vector\"\n    FROM \n      IDC.IDC_V17.\"DICOM_ALL\" AS bid,\n      LATERAL FLATTEN(input => bid.\"ImageOrientationPatient\") AS part\n    WHERE\n      part.index BETWEEN 0 AND 2\n    GROUP BY \"SeriesInstanceUID\"\n  ),\n  \n  -- Create a common table expression (CTE) for y_vector calculation (next three elements)\n  imageOrientationY AS (\n    SELECT\n      \"SeriesInstanceUID\",\n      ARRAY_AGG(CAST(part.value AS FLOAT)) AS \"y_vector\"\n    FROM \n      IDC.IDC_V17.\"DICOM_ALL\" AS bid,\n      LATERAL FLATTEN(input => bid.\"ImageOrientationPatient\") AS part\n    WHERE\n      part.index BETWEEN 3 AND 5\n    GROUP BY \"SeriesInstanceUID\"\n  ),\n  \n  -- Create a common table expression (CTE) named nonLocalizerRawData\n  nonLocalizerRawData AS (\n    SELECT\n      bid.\"SeriesInstanceUID\",  -- Added table alias bid\n      bid.\"StudyInstanceUID\",\n      bid.\"PatientID\",\n      bid.\"SOPInstanceUID\",\n      bid.\"SliceThickness\",\n      bid.\"ImageType\",\n      bid.\"TransferSyntaxUID\",\n      bid.\"SeriesNumber\",\n      bid.\"aws_bucket\",\n      bid.\"crdc_series_uuid\",\n      CAST(bid.\"Exposure\" AS FLOAT) AS \"Exposure\",  -- Use CAST directly\n      CAST(ipp.value AS FLOAT) AS \"zImagePosition\", -- Use CAST directly\n      CONCAT(ipp2.value, '/', ipp3.value) AS \"xyImagePosition\",\n      LEAD(CAST(ipp.value AS FLOAT)) OVER (PARTITION BY bid.\"SeriesInstanceUID\" ORDER BY CAST(ipp.value AS FLOAT)) - CAST(ipp.value AS FLOAT) AS \"slice_interval\",\n      ARRAY_TO_STRING(bid.\"ImageOrientationPatient\", '/') AS \"iop\",\n      bid.\"PixelSpacing\",\n      bid.\"Rows\" AS \"pixelRows\",\n      bid.\"Columns\" AS \"pixelColumns\",\n      bid.\"instance_size\" AS \"instanceSize\"\n    FROM\n      IDC.IDC_V17.\"DICOM_ALL\" AS bid\n    LEFT JOIN LATERAL FLATTEN(input => bid.\"ImagePositionPatient\") AS ipp\n    LEFT JOIN LATERAL FLATTEN(input => bid.\"ImagePositionPatient\") AS ipp2\n    LEFT JOIN LATERAL FLATTEN(input => bid.\"ImagePositionPatient\") AS ipp3\n    WHERE\n      bid.\"collection_id\" != 'nlst'\n      AND bid.\"Modality\" = 'CT'\n      AND ipp.index = 2\n      AND ipp2.index = 0\n      AND ipp3.index = 1\n      AND bid.\"SeriesInstanceUID\" NOT IN (SELECT \"SeriesInstanceUID\" FROM localizerAndJpegCompressedSeries)\n  ),\n  \n  -- Cross product calculation\n  crossProduct AS (\n    SELECT\n      nld.\"SOPInstanceUID\",  -- Added table alias nld\n      nld.\"SeriesInstanceUID\",  -- Added table alias nld\n      OBJECT_CONSTRUCT(\n        'x', (\"x_vector\"[1] * \"y_vector\"[2] - \"x_vector\"[2] * \"y_vector\"[1]),\n        'y', (\"x_vector\"[2] * \"y_vector\"[0] - \"x_vector\"[0] * \"y_vector\"[2]),\n        'z', (\"x_vector\"[0] * \"y_vector\"[1] - \"x_vector\"[1] * \"y_vector\"[0])\n      ) AS \"xyCrossProduct\"\n    FROM \n      nonLocalizerRawData AS nld  -- Added alias for nonLocalizerRawData\n    JOIN imageOrientation AS io ON nld.\"SeriesInstanceUID\" = io.\"SeriesInstanceUID\"\n    JOIN imageOrientationY AS ioy ON nld.\"SeriesInstanceUID\" = ioy.\"SeriesInstanceUID\"\n  ),\n  \n  -- Cross product elements extraction and row numbering\n  crossProductElements AS (\n    SELECT\n      cp.\"SOPInstanceUID\",  \n      cp.\"SeriesInstanceUID\",  \n      elem.value,\n      ROW_NUMBER() OVER (PARTITION BY cp.\"SOPInstanceUID\", cp.\"SeriesInstanceUID\" ORDER BY elem.value) AS rn\n    FROM \n      crossProduct AS cp  \n    -- Use LATERAL FLATTEN to explode the cross product object into individual 'x', 'y', and 'z'\n    JOIN LATERAL FLATTEN(input => ARRAY_CONSTRUCT(\n          cp.\"xyCrossProduct\"['x'],\n          cp.\"xyCrossProduct\"['y'],\n          cp.\"xyCrossProduct\"['z']\n    )) AS elem -- Simplified 'elem.value' reference here\n  ),\n  \n  -- Dot product calculation\n  dotProduct AS (\n    SELECT\n      cpe.\"SOPInstanceUID\",  \n      cpe.\"SeriesInstanceUID\",  \n      SUM(\n        CASE \n          WHEN cpe.rn = 1 THEN cpe.value * 0  -- x * 0\n          WHEN cpe.rn = 2 THEN cpe.value * 0  -- y * 0\n          WHEN cpe.rn = 3 THEN cpe.value * 1  -- z * 1\n        END\n      ) AS \"xyDotProduct\"\n    FROM \n      crossProductElements AS cpe\n    GROUP BY \n      cpe.\"SOPInstanceUID\",  \n      cpe.\"SeriesInstanceUID\"\n  ),\n  \n  -- Geometry checks for series consistency\n  geometryChecks AS (\n    SELECT\n      gc.\"SeriesInstanceUID\",  -- Added table alias gc\n      gc.\"SeriesNumber\",\n      gc.\"aws_bucket\",\n      gc.\"crdc_series_uuid\",\n      gc.\"StudyInstanceUID\",\n      gc.\"PatientID\",\n      ARRAY_AGG(DISTINCT gc.\"slice_interval\") AS \"sliceIntervalDifferences\",\n      ARRAY_AGG(DISTINCT gc.\"Exposure\") AS \"distinctExposures\",\n      COUNT(DISTINCT gc.\"iop\") AS \"iopCount\",\n      COUNT(DISTINCT gc.\"PixelSpacing\") AS \"pixelSpacingCount\",\n      COUNT(DISTINCT gc.\"zImagePosition\") AS \"positionCount\",\n      COUNT(DISTINCT gc.\"xyImagePosition\") AS \"xyPositionCount\",\n      COUNT(DISTINCT gc.\"SOPInstanceUID\") AS \"sopInstanceCount\",\n      COUNT(DISTINCT gc.\"SliceThickness\") AS \"sliceThicknessCount\",\n      COUNT(DISTINCT gc.\"Exposure\") AS \"exposureCount\",\n      COUNT(DISTINCT gc.\"pixelRows\") AS \"pixelRowCount\",\n      COUNT(DISTINCT gc.\"pixelColumns\") AS \"pixelColumnCount\",\n      dp.\"xyDotProduct\",  -- Added xyDotProduct from dotProduct\n      SUM(gc.\"instanceSize\") / 1024 / 1024 AS \"seriesSizeInMiB\"\n    FROM \n      nonLocalizerRawData AS gc  -- Added table alias gc\n    JOIN dotProduct AS dp ON gc.\"SeriesInstanceUID\" = dp.\"SeriesInstanceUID\" \n    AND gc.\"SOPInstanceUID\" = dp.\"SOPInstanceUID\"\n    GROUP BY\n      gc.\"SeriesInstanceUID\", \n      gc.\"SeriesNumber\",\n      gc.\"aws_bucket\",\n      gc.\"crdc_series_uuid\",\n      gc.\"StudyInstanceUID\",\n      gc.\"PatientID\",\n      dp.\"xyDotProduct\"  -- Include xyDotProduct in GROUP BY\n    HAVING\n      COUNT(DISTINCT gc.\"iop\") = 1 \n      AND COUNT(DISTINCT gc.\"PixelSpacing\") = 1  \n      AND COUNT(DISTINCT gc.\"SOPInstanceUID\") = COUNT(DISTINCT gc.\"zImagePosition\") \n      AND COUNT(DISTINCT gc.\"xyImagePosition\") = 1\n      AND COUNT(DISTINCT gc.\"pixelRows\") = 1 \n      AND COUNT(DISTINCT gc.\"pixelColumns\") = 1 \n      AND ABS(dp.\"xyDotProduct\") BETWEEN 0.99 AND 1.01\n  )\n\nSELECT\n  geometryChecks.\"SeriesInstanceUID\",  -- Added table alias\n  geometryChecks.\"SeriesNumber\",  -- Added table alias\n  geometryChecks.\"PatientID\",  -- Added table alias\n  geometryChecks.\"seriesSizeInMiB\"\nFROM\n  geometryChecks\nORDER BY\n  geometryChecks.\"seriesSizeInMiB\" DESC\nLIMIT 5;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: fda\nQuestion: Which Colorado zip code has the highest concentration of bank locations per block group, based on the overlap between zip codes and block groups?\n\nExternal Knowledge: overlap_ratio.md"}, {"role": "assistant", "content": "WITH _fips AS (\n    SELECT\n        state_fips_code\n    FROM\n        `bigquery-public-data.census_utility.fips_codes_states`\n    WHERE\n        state_name = \"Colorado\"\n),\n\n_bg AS (\n    SELECT\n        b.geo_id,\n        b.blockgroup_geom,\n        ST_AREA(b.blockgroup_geom) AS bg_size\n    FROM\n        `bigquery-public-data.geo_census_blockgroups.us_blockgroups_national` b\n    JOIN\n        _fips u ON b.state_fips_code = u.state_fips_code\n),\n\n_zip AS (\n    SELECT\n        z.zip_code,\n        z.zip_code_geom\n    FROM\n        `bigquery-public-data.geo_us_boundaries.zip_codes` z\n    JOIN\n        _fips u ON z.state_fips_code = u.state_fips_code\n),\n\nbq_zip_overlap AS (\n    SELECT\n        b.geo_id,\n        z.zip_code,\n        ST_AREA(ST_INTERSECTION(b.blockgroup_geom, z.zip_code_geom)) / b.bg_size AS overlap_size,\n        b.blockgroup_geom\n    FROM\n        _zip z\n    JOIN\n        _bg b ON ST_INTERSECTS(b.blockgroup_geom, z.zip_code_geom)\n),\n\nlocations AS (\n    SELECT\n        SUM(overlap_size * count_locations) AS locations_per_bg,\n        l.zip_code\n    FROM (\n        SELECT\n            COUNT(CONCAT(institution_name, \" : \", branch_name)) AS count_locations,\n            zip_code\n        FROM\n            `bigquery-public-data.fdic_banks.locations`\n        WHERE\n            state IS NOT NULL\n            AND state_name IS NOT NULL\n        GROUP BY\n            zip_code\n    ) l\n    JOIN\n        bq_zip_overlap ON l.zip_code = bq_zip_overlap.zip_code\n    GROUP BY\n        l.zip_code\n)\n\nSELECT\n    l.zip_code\nFROM\n    locations l\nGROUP BY\n    l.zip_code\nORDER BY\n    MAX(locations_per_bg) DESC\nLIMIT 1;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: world_bank\nQuestion: What are the top three debt indicators for Russia based on the highest debt values?"}, {"role": "assistant", "content": "WITH russia_Data as (\nSELECT distinct \n  id.country_name,\n  id.value, --format in DataStudio\n  id.indicator_name\nFROM (\n  SELECT\n    country_code,\n    region\n  FROM\n    bigquery-public-data.world_bank_intl_debt.country_summary\n  WHERE\n    region != \"\" ) cs --aggregated countries do not have a region\nINNER JOIN (\n  SELECT\n    country_code,\n    country_name,\n    value, \n    indicator_name\n  FROM\n    bigquery-public-data.world_bank_intl_debt.international_debt\n  WHERE true\n    and country_code = 'RUS'  \n     ) id\nON\n  cs.country_code = id.country_code\nWHERE value is not null\nORDER BY\n  id.value DESC\n)\nSELECT \n    indicator_name\nFROM russia_data\nLIMIT 3;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: world_bank\nQuestion: Which high-income country had the highest average crude birth rate respectively in each region, and what are their corresponding average birth rate, during the 1980s?"}, {"role": "assistant", "content": "WITH country_data AS ( \n  SELECT \n    country_code, \n    short_name AS country,\n    region, \n    income_group \n  FROM \n    bigquery-public-data.world_bank_wdi.country_summary\n)\n, birth_rate_data AS (\n  SELECT \n    data.country_code, \n    country_data.country,\n    country_data.region,\n    AVG(value) AS avg_birth_rate\n  FROM \n    bigquery-public-data.world_bank_wdi.indicators_data data \n  LEFT JOIN \n    country_data \n  ON \n    data.country_code = country_data.country_code\n  WHERE \n    indicator_code = \"SP.DYN.CBRT.IN\" -- Birth Rate\n    AND EXTRACT(YEAR FROM PARSE_DATE('%Y', CAST(year AS STRING))) BETWEEN 1980 AND 1989 -- 1980s\n    AND country_data.income_group = \"High income\" -- High-income group\n  GROUP BY \n    data.country_code, \n    country_data.country,\n    country_data.region\n)\n, ranked_birth_rates AS (\n  SELECT\n    region,\n    country,\n    avg_birth_rate,\n    RANK() OVER(PARTITION BY region ORDER BY avg_birth_rate DESC) AS rank\n  FROM\n    birth_rate_data\n)\nSELECT \n  region, \n  country, \n  avg_birth_rate\nFROM \n  ranked_birth_rates\nWHERE \n  rank = 1\nORDER BY \n  region;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: london\nQuestion: Could you provide the annual percentage shares, rounded to two decimal places, of the top 5 minor crime categories from 2008 in London's total crimes, with each year displayed in one row?"}, {"role": "assistant", "content": "WITH top5_categories AS (\n  SELECT minor_category\n  FROM `bigquery-public-data.london_crime.crime_by_lsoa`\n  WHERE year = 2008\n  GROUP BY minor_category\n  ORDER BY SUM(value) DESC\n  LIMIT 5\n),\n\ntotal_crimes_per_year AS (\n  SELECT \n    year, \n    SUM(value) AS total_crimes_year\n  FROM `bigquery-public-data.london_crime.crime_by_lsoa`\n  GROUP BY year\n),\n\ntop5_crimes_per_year AS (\n  SELECT\n    year,\n    minor_category,\n    SUM(value) AS total_crimes_category_year\n  FROM `bigquery-public-data.london_crime.crime_by_lsoa`\n  WHERE minor_category IN (SELECT minor_category FROM top5_categories)\n  GROUP BY year, minor_category\n)\n\nSELECT\n  t.year,\n  ROUND(SUM(CASE WHEN t.minor_category = (SELECT minor_category FROM top5_categories LIMIT 1 OFFSET 0) THEN t.total_crimes_category_year ELSE 0 END) / y.total_crimes_year * 100, 2) AS `Category 1`,\n  ROUND(SUM(CASE WHEN t.minor_category = (SELECT minor_category FROM top5_categories LIMIT 1 OFFSET 1) THEN t.total_crimes_category_year ELSE 0 END) / y.total_crimes_year * 100, 2) AS `Category 2`,\n  ROUND(SUM(CASE WHEN t.minor_category = (SELECT minor_category FROM top5_categories LIMIT 1 OFFSET 2) THEN t.total_crimes_category_year ELSE 0 END) / y.total_crimes_year * 100, 2) AS `Category 3`,\n  ROUND(SUM(CASE WHEN t.minor_category = (SELECT minor_category FROM top5_categories LIMIT 1 OFFSET 3) THEN t.total_crimes_category_year ELSE 0 END) / y.total_crimes_year * 100, 2) AS `Category 4`,\n  ROUND(SUM(CASE WHEN t.minor_category = (SELECT minor_category FROM top5_categories LIMIT 1 OFFSET 4) THEN t.total_crimes_category_year ELSE 0 END) / y.total_crimes_year * 100, 2) AS `Category 5`\nFROM\n  top5_crimes_per_year t\nJOIN\n  total_crimes_per_year y ON t.year = y.year\nGROUP BY\n  t.year, y.total_crimes_year\nORDER BY\n  t.year;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: london\nQuestion: Could you provide the total number of 'Other Theft' incidents within the 'Theft and Handling' category for each year in the Westminster borough?"}, {"role": "assistant", "content": "WITH borough_data AS (\n    SELECT \n        year, \n        month, \n        borough, \n        major_category, \n        minor_category, \n        SUM(value) AS total,\n    CASE \n        WHEN \n            major_category = 'Theft and Handling' \n        THEN \n            'Theft and Handling'\n        ELSE \n            'Other' \n    END AS major_division,\n    CASE \n        WHEN \n            minor_category = 'Other Theft' THEN minor_category\n        ELSE \n            'Other'\n    END AS minor_division,\n    FROM \n        bigquery-public-data.london_crime.crime_by_lsoa\n    GROUP BY 1,2,3,4,5\n    ORDER BY 1,2\n)\n\nSELECT year, SUM(total) AS year_total\nFROM borough_data\nWHERE \n    borough = 'Westminster'\nAND\n    major_division != 'Other'\nAND \n    minor_division != 'Other'\nGROUP BY year, major_division, minor_division\nORDER BY year;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: london\nQuestion: Please provide a list of the top three major crime categories in the borough of Barking and Dagenham, along with the number of incidents in each category."}, {"role": "assistant", "content": "WITH ranked_crimes AS (\n    SELECT\n        borough,\n        major_category,\n        RANK() OVER(PARTITION BY borough ORDER BY SUM(value) DESC) AS rank_per_borough,\n        SUM(value) AS no_of_incidents\n    FROM\n        `bigquery-public-data.london_crime.crime_by_lsoa`\n    GROUP BY\n        borough,\n        major_category\n)\n\nSELECT\n    borough,\n    major_category,\n    rank_per_borough,\n    no_of_incidents\nFROM\n    ranked_crimes\nWHERE\n    rank_per_borough <= 3\nAND \n    borough = 'Barking and Dagenham'\nORDER BY\n    borough,\n    rank_per_borough;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: world_bank\nQuestion: List the top 10 countries with respect to the total amount of long-term external debt in descending order, excluding those without a specified region."}, {"role": "assistant", "content": "SELECT DISTINCT\n  id.country_name,\n  --cs.region,\n  id.value AS debt,\n  --id.indicator_code\nFROM (\n  SELECT\n    country_code,\n    region\n  FROM\n    `bigquery-public-data.world_bank_intl_debt.country_summary`\n  WHERE\n    region != \"\" ) cs\nINNER JOIN (\n  SELECT\n    country_code,\n    country_name,\n    value,\n    indicator_code\n  FROM\n    `bigquery-public-data.world_bank_intl_debt.international_debt`\n  WHERE\n    indicator_code = \"DT.AMT.DLXF.CD\") id\n\nON\n  cs.country_code = id.country_code\nORDER BY\n  id.value DESC\n  LIMIT 10"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: world_bank\nQuestion: How many debt indicators for Russia have a value of 0, excluding NULL values?"}, {"role": "assistant", "content": "WITH russia_Data AS (\n  SELECT DISTINCT \n    id.country_name,\n    id.value, -- Format in DataStudio\n    id.indicator_name\n  FROM (\n    SELECT\n      country_code,\n      region\n    FROM\n      bigquery-public-data.world_bank_intl_debt.country_summary\n    WHERE\n      region != \"\" -- Aggregated countries do not have a region\n  ) cs -- Aggregated countries do not have a region\n  INNER JOIN (\n    SELECT\n      country_code,\n      country_name,\n      value, \n      indicator_name\n    FROM\n      bigquery-public-data.world_bank_intl_debt.international_debt\n    WHERE\n      country_code = 'RUS'\n  ) id\n  ON\n    cs.country_code = id.country_code\n  WHERE value IS NOT NULL\n)\n-- Count the number of indicators with a value of 0 for Russia\nSELECT \n  COUNT(*) AS number_of_indicators_with_zero\nFROM \n  russia_Data\nWHERE \n  value = 0;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: world_bank\nQuestion: Which region has the highest median GDP (constant 2015 US$) value?"}, {"role": "assistant", "content": "WITH country_data AS (\n  -- CTE for country descriptive data\n  SELECT \n    country_code, \n    short_name AS country,\n    region, \n    income_group \n  FROM \n    `bigquery-public-data.world_bank_wdi.country_summary`\n),\n\ngdp_data AS (\n  -- Filter data to only include GDP values\n  SELECT \n    data.country_code, \n    country,\n    region,\n    value AS gdp_value\n  FROM \n    `bigquery-public-data.world_bank_wdi.indicators_data` data\n  LEFT JOIN country_data\n    ON data.country_code = country_data.country_code\n  WHERE indicator_code = \"NY.GDP.MKTP.KD\" -- GDP Indicator\n    AND country_data.region IS NOT NULL\n    AND country_data.income_group IS NOT NULL\n),\n\ncal_median_gdp AS (\n  -- Calculate the median GDP value for each region\n  SELECT \n    region,\n    APPROX_QUANTILES(gdp_value, 2)[OFFSET(1)] AS median_gdp\n  FROM gdp_data\n  GROUP BY region\n)\n-- Select the regions with their median GDP values\nSELECT \n  region\nFROM \n  cal_median_gdp\nORDER BY median_gdp DESC\nLIMIT 1;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: irs_990\nQuestion: Which three years in 2012-2017 have the smallest absolute difference between median revenue and median functional expenses for organizations filing IRS 990 forms? Please output three years and respective differences."}, {"role": "assistant", "content": "WITH RankedData AS (\n    SELECT\n        CONCAT(\"20\", _TABLE_SUFFIX) AS year_filed,\n        totrevenue,\n        totfuncexpns,\n        ROW_NUMBER() OVER (PARTITION BY CONCAT(\"20\", _TABLE_SUFFIX) ORDER BY totrevenue) \n        AS revenue_rank,\n        ROW_NUMBER() OVER (PARTITION BY CONCAT(\"20\", _TABLE_SUFFIX) ORDER BY totfuncexpns) \n        AS expense_rank,\n        COUNT(*) OVER (PARTITION BY CONCAT(\"20\", _TABLE_SUFFIX)) AS total_count\n    FROM \n        `bigquery-public-data.irs_990.irs_990_20*`\n),\n\nYearlyMedians AS (\n    SELECT\n        year_filed,\n        IF(MOD(total_count, 2) = 1, \n           MAX(CASE WHEN revenue_rank = (total_count + 1) / 2 THEN totrevenue END),\n           AVG(CASE WHEN revenue_rank IN ((total_count / 2), (total_count / 2) + 1) THEN totrevenue END)\n        ) AS median_revenue,\n        IF(MOD(total_count, 2) = 1, \n           MAX(CASE WHEN expense_rank = (total_count + 1) / 2 THEN totfuncexpns END),\n           AVG(CASE WHEN expense_rank IN ((total_count / 2), (total_count / 2) + 1) THEN totfuncexpns END)\n        ) AS median_expense\n    FROM\n        RankedData\n    GROUP BY\n        year_filed, total_count\n),\n\nDifferenceCalculations AS (\n    SELECT\n        year_filed,\n        median_revenue,\n        median_expense,\n        ABS(median_revenue - median_expense) AS difference\n    FROM\n        YearlyMedians\n)\n\nSELECT\n    year_filed,\n    difference\nFROM\n    DifferenceCalculations\nWHERE\n    year_filed BETWEEN '2012' AND '2017'\nORDER BY\n    difference ASC\nLIMIT 3;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: ecommerce\nQuestion: After removing any duplicate records from the rev_transactions dataset, identify each channel grouping that has transactions from more than one country. For each such channel grouping, find the country with the highest total number of transactions and report both the country name and the sum of transactions for that channel grouping."}, {"role": "assistant", "content": "WITH tmp AS (\n  SELECT DISTINCT *\n  FROM `data-to-insights.ecommerce.rev_transactions`\n  -- Removing duplicated values\n),\ntmp1 AS (\n  SELECT \n    tmp.channelGrouping,\n    tmp.geoNetwork_country,\n    SUM(tmp.totals_transactions) AS tt\n  FROM tmp\n  GROUP BY 1, 2\n),\ntmp2 AS (\n  SELECT \n    channelGrouping,\n    geoNetwork_country,\n    SUM(tt) AS TotalTransaction,\n    COUNT(DISTINCT geoNetwork_country) OVER (PARTITION BY channelGrouping) AS CountryCount\n  FROM tmp1\n  GROUP BY channelGrouping, geoNetwork_country\n),\ntmp3 AS (\n  SELECT\n    channelGrouping,\n    geoNetwork_country AS Country,\n    TotalTransaction,\n    RANK() OVER (PARTITION BY channelGrouping ORDER BY TotalTransaction DESC) AS rnk\n  FROM tmp2\n  WHERE CountryCount > 1\n)\nSELECT\n  channelGrouping,\n  Country,\n  TotalTransaction\nFROM tmp3\nWHERE rnk = 1;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: ecommerce\nQuestion: Calculate the conversion rate from unique visitors to purchasers by using data exclusively from the `web_analytics` table in the `data-to-insights.ecommerce` dataset. A visitor is defined as a unique `fullVisitorId` present in the table, while a purchaser is a visitor who has at least one transaction recorded (`totals.transactions` is not null). The conversion rate is computed by dividing the number of unique purchasers by the total number of unique visitors. Additionally, calculate the average number of transactions per purchaser, considering only those visitors who have made at least one transaction."}, {"role": "assistant", "content": "WITH visitors AS (\n  SELECT\n    COUNT(DISTINCT fullVisitorId) AS total_visitors\n  FROM \n    `data-to-insights.ecommerce.web_analytics`\n),\n\npurchasers AS (\n  SELECT\n    COUNT(DISTINCT fullVisitorId) AS total_purchasers\n  FROM \n    `data-to-insights.ecommerce.web_analytics`\n  WHERE \n    totals.transactions IS NOT NULL\n),\n\ntransactions AS (\n  SELECT\n    COUNT(*) AS total_transactions,\n    AVG(totals.transactions) AS avg_transactions_per_purchaser\n  FROM \n    `data-to-insights.ecommerce.web_analytics`\n  WHERE \n    totals.transactions IS NOT NULL\n)\n\nSELECT\n  p.total_purchasers / v.total_visitors AS conversion_rate,\n  a.avg_transactions_per_purchaser AS avg_transactions_per_purchaser\nFROM\n  visitors v,\n  purchasers p,\n  transactions a;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: META_KAGGLE\nQuestion: Identify the pair of Kaggle users involved in ForumMessageVotes such that one user has given the other the greatest distinct number of upvotes, then also display how many upvotes that recipient returned. Present the usernames of both users, the total distinct upvotes one received from the other, and the upvotes they gave back, sorting by the highest received count and then by the highest given count, and show only the top result."}, {"role": "assistant", "content": "WITH UserPairUpvotes AS (\n  SELECT\n    ToUsers.\"UserName\" AS \"ToUserName\",\n    FromUsers.\"UserName\" AS \"FromUserName\",\n    COUNT(DISTINCT \"ForumMessageVotes\".\"Id\") AS \"UpvoteCount\"\n  FROM META_KAGGLE.META_KAGGLE.FORUMMESSAGEVOTES AS \"ForumMessageVotes\"\n  INNER JOIN META_KAGGLE.META_KAGGLE.USERS AS FromUsers\n    ON FromUsers.\"Id\" = \"ForumMessageVotes\".\"FromUserId\"\n  INNER JOIN META_KAGGLE.META_KAGGLE.USERS AS ToUsers\n    ON ToUsers.\"Id\" = \"ForumMessageVotes\".\"ToUserId\"\n  GROUP BY\n    ToUsers.\"UserName\",\n    FromUsers.\"UserName\"\n),\nTopPairs AS (\n  SELECT\n    \"ToUserName\",\n    \"FromUserName\",\n    \"UpvoteCount\",\n    ROW_NUMBER() OVER (ORDER BY \"UpvoteCount\" DESC) AS \"Rank\"\n  FROM UserPairUpvotes\n),\nReciprocalUpvotes AS (\n  SELECT\n    t.\"ToUserName\",\n    t.\"FromUserName\",\n    t.\"UpvoteCount\" AS \"UpvotesReceived\",\n    COALESCE(u.\"UpvoteCount\", 0) AS \"UpvotesGiven\"\n  FROM TopPairs t\n  LEFT JOIN UserPairUpvotes u\n    ON t.\"ToUserName\" = u.\"FromUserName\" AND t.\"FromUserName\" = u.\"ToUserName\"\n  WHERE t.\"Rank\" = 1\n)\nSELECT\n  \"ToUserName\" AS \"UpvotedUserName\",\n  \"FromUserName\" AS \"UpvotingUserName\",\n  \"UpvotesReceived\" AS \"UpvotesReceivedByUpvotedUser\",\n  \"UpvotesGiven\" AS \"UpvotesGivenByUpvotedUser\"\nFROM ReciprocalUpvotes\nORDER BY \"UpvotesReceived\" DESC, \"UpvotesGiven\" DESC;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: DEATH\nQuestion: Please provide, for each age from 12 through 18 (inclusive), the total number of deaths and the number of deaths among individuals identified as Black (based on race descriptions containing the word \u2018black\u2019), specifically for deaths associated with ICD-10 codes whose descriptions include the word \u2018vehicle\u2019 and for deaths associated with ICD-10 codes whose descriptions include the word \u2018firearm.\u2019 Use the EntityAxisConditions table to determine which ICD-10 codes were involved in each death, rather than joining ICD-10 code information directly on the death records."}, {"role": "assistant", "content": "WITH BlackRace AS (\n    SELECT CAST(\"Code\" AS INT) AS CODE\n    FROM DEATH.DEATH.RACE\n    WHERE LOWER(\"Description\") LIKE '%black%'\n)\nSELECT \n    v.\"Age\", \n    v.\"Total\" AS \"Vehicle_Total\", \n    v.\"Black\" AS \"Vehicle_Black\",\n    g.\"Total\" AS \"Gun_Total\", \n    g.\"Black\" AS \"Gun_Black\"\nFROM (\n    SELECT \n        \"Age\", \n        COUNT(*) AS \"Total\", \n        COUNT_IF(\"Race\" IN (SELECT CODE FROM BlackRace)) AS \"Black\"\n    FROM DEATH.DEATH.DEATHRECORDS d\n    JOIN (\n        SELECT \n            DISTINCT e.\"DeathRecordId\" AS \"id\"\n        FROM DEATH.DEATH.ENTITYAXISCONDITIONS e\n        JOIN (\n            SELECT * \n            FROM DEATH.DEATH.ICD10CODE \n            WHERE LOWER(\"Description\") LIKE '%vehicle%'\n        ) c \n        ON e.\"Icd10Code\" = c.\"Code\"\n    ) f\n    ON d.\"Id\" = f.\"id\"\n    WHERE \"Age\" BETWEEN 12 AND 18\n    GROUP BY \"Age\"\n) v  -- Vehicle\n\nJOIN (\n    SELECT \n        \"Age\", \n        COUNT(*) AS \"Total\", \n        COUNT_IF(\"Race\" IN (SELECT CODE FROM BlackRace)) AS \"Black\"\n    FROM DEATH.DEATH.DEATHRECORDS d\n    JOIN (\n        SELECT \n            DISTINCT e.\"DeathRecordId\" AS \"id\"\n        FROM DEATH.DEATH.ENTITYAXISCONDITIONS e\n        JOIN (\n            SELECT \n                \"Code\", \"Description\" \n            FROM DEATH.DEATH.ICD10CODE\n            WHERE \"Description\" LIKE '%firearm%'\n        ) c \n        ON e.\"Icd10Code\" = c.\"Code\"\n    ) f\n    ON d.\"Id\" = f.\"id\"\n    WHERE \"Age\" BETWEEN 12 AND 18\n    GROUP BY \"Age\"\n) g\nON g.\"Age\" = v.\"Age\";"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: ga4\nQuestion: I want to know the preferences of customers who purchased the Google Navy Speckled Tee in December 2020. What other product was purchased with the highest total quantity alongside this item?"}, {"role": "assistant", "content": "WITH\n  Params AS (\n    SELECT 'Google Navy Speckled Tee' AS selected_product\n  ),\n  PurchaseEvents AS (\n    SELECT\n      user_pseudo_id,\n      items\n    FROM\n      `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`\n    WHERE\n      _TABLE_SUFFIX BETWEEN '20201201' AND '20201231'\n      AND event_name = 'purchase'\n  ),\n  ProductABuyers AS (\n    SELECT DISTINCT\n      user_pseudo_id\n    FROM\n      Params,\n      PurchaseEvents,\n      UNNEST(items) AS items\n    WHERE\n      items.item_name = selected_product\n  )\nSELECT\n  items.item_name AS item_name,\n  SUM(items.quantity) AS item_quantity\nFROM\n  Params,\n  PurchaseEvents,\n  UNNEST(items) AS items\nWHERE\n  user_pseudo_id IN (SELECT user_pseudo_id FROM ProductABuyers)\n  AND items.item_name != selected_product\nGROUP BY 1\nORDER BY item_quantity DESC\nLIMIT 1;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: ga4\nQuestion: Tell me the most purchased other products and their quantities by customers who bought the Google Red Speckled Tee each month for the three months starting from November 2020."}, {"role": "assistant", "content": "WITH\nParams AS (\n  SELECT 'Google Red Speckled Tee' AS selected_product\n),\nDateRanges AS (\n  SELECT '20201101' AS start_date, '20201130' AS end_date, '202011' AS period UNION ALL\n  SELECT '20201201', '20201231', '202012' UNION ALL\n  SELECT '20210101', '20210131', '202101'\n),\nPurchaseEvents AS (\n  SELECT\n    period,\n    user_pseudo_id,\n    items\n  FROM\n    DateRanges\n  JOIN\n    `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`\n    ON _TABLE_SUFFIX BETWEEN start_date AND end_date\n  WHERE\n    event_name = 'purchase'\n),\nProductABuyers AS (\n  SELECT DISTINCT\n    period,\n    user_pseudo_id\n  FROM\n    Params,\n    PurchaseEvents,\n    UNNEST(items) AS items\n  WHERE\n    items.item_name = selected_product\n),\nTopProducts AS (\n  SELECT\n    pe.period,\n    items.item_name AS item_name,\n    SUM(items.quantity) AS item_quantity\n  FROM\n    Params,\n    PurchaseEvents pe,\n    UNNEST(items) AS items\n  WHERE\n    user_pseudo_id IN (SELECT user_pseudo_id FROM ProductABuyers pb WHERE pb.period = pe.period)\n    AND items.item_name != selected_product\n  GROUP BY\n    pe.period, items.item_name\n),\nTopProductPerPeriod AS (\n  SELECT\n    period,\n    item_name,\n    item_quantity\n  FROM (\n    SELECT\n      period,\n      item_name,\n      item_quantity,\n      RANK() OVER (PARTITION BY period ORDER BY item_quantity DESC) AS rank\n    FROM\n      TopProducts\n  )\n  WHERE\n    rank = 1\n)\nSELECT\n  period,\n  item_name,\n  item_quantity\nFROM\n  TopProductPerPeriod\nORDER BY\n  period;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: firebase\nQuestion: I'm trying to evaluate which board types were most effective on September 15, 2018. Can you find out the average scores for each board type from the quick play mode completions on that day?"}, {"role": "assistant", "content": "WITH EventData AS (\n    SELECT \n        user_pseudo_id, \n        event_timestamp, \n        param\n    FROM \n        `firebase-public-project.analytics_153293282.events_20180915`,\n        UNNEST(event_params) AS param\n    WHERE \n        event_name = \"level_complete_quickplay\"\n        AND (param.key = \"value\" OR param.key = \"board\")\n),\nProcessedData AS (\n    SELECT \n        user_pseudo_id, \n        event_timestamp, \n        MAX(IF(param.key = \"value\", param.value.int_value, NULL)) AS score,\n        MAX(IF(param.key = \"board\", param.value.string_value, NULL)) AS board_type\n    FROM \n        EventData\n    GROUP BY \n        user_pseudo_id, \n        event_timestamp\n)\nSELECT \n    ANY_VALUE(board_type) AS board, \n    AVG(score) AS average_score\nFROM \n    ProcessedData\nGROUP BY \n    board_type"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: ga4\nQuestion: Can you figure out the average difference in pageviews between users who bought something and those who didn\u2019t in December 2020? Just label anyone who was involved in purchase events as a purchaser."}, {"role": "assistant", "content": "WITH\n  UserInfo AS (\n    SELECT\n      user_pseudo_id,\n      COUNTIF(event_name = 'page_view') AS page_view_count,\n      COUNTIF(event_name IN ('in_app_purchase', 'purchase')) AS purchase_event_count\n    FROM `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`\n    WHERE _TABLE_SUFFIX BETWEEN '20201201' AND '20201231'\n    GROUP BY 1\n  ),\n  Averages AS (\n    SELECT\n      (purchase_event_count > 0) AS purchaser,\n      COUNT(*) AS user_count,\n      SUM(page_view_count) AS total_page_views,\n      SUM(page_view_count) / COUNT(*) AS avg_page_views\n    FROM UserInfo\n    GROUP BY 1\n  )\n\nSELECT\n  MAX(CASE WHEN purchaser THEN avg_page_views ELSE 0 END) -\n  MAX(CASE WHEN NOT purchaser THEN avg_page_views ELSE 0 END) AS avg_page_views_difference\nFROM Averages;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: ga4\nQuestion: Could you provide the total number of page views for each day in November 2020 as well as the average number of page views per user on those days, restricted to users who made at least one purchase in November 2020?"}, {"role": "assistant", "content": "WITH\n  UserInfo AS (\n    SELECT\n      user_pseudo_id,\n      PARSE_DATE('%Y%m%d', event_date) AS event_date,\n      COUNTIF(event_name = 'page_view') AS page_view_count,\n      COUNTIF(event_name = 'purchase') AS purchase_event_count\n    FROM `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`\n    WHERE _TABLE_SUFFIX BETWEEN '20201101' AND '20201130'\n    GROUP BY 1, 2\n  )\nSELECT\n  event_date,\n  SUM(page_view_count) / COUNT(*) AS avg_page_views,\n  SUM(page_view_count)\nFROM UserInfo\nWHERE purchase_event_count > 0\nGROUP BY event_date\nORDER BY event_date;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: ga4\nQuestion: How many distinct users viewed the most frequently visited page during January 2021?"}, {"role": "assistant", "content": "WITH unnested_events AS (\n  SELECT\n    MAX(CASE WHEN event_params.key = 'page_location' THEN event_params.value.string_value END) AS page_location,\n    user_pseudo_id,\n    event_timestamp\n  FROM\n    `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`,\n    UNNEST(event_params) AS event_params\n  WHERE\n    _TABLE_SUFFIX BETWEEN '20210101' AND '20210131'\n    AND event_name = 'page_view'\n  GROUP BY user_pseudo_id,event_timestamp\n),\ntemp AS (\n    SELECT\n    page_location,\n    COUNT(*) AS event_count,\n    COUNT(DISTINCT user_pseudo_id) AS users\n    FROM\n    unnested_events\n    GROUP BY page_location\n    ORDER BY event_count DESC\n)\n\nSELECT users \nFROM\ntemp\nLIMIT 1"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: ga4\nQuestion: On January 2nd, 2021, I want to determine the percentage of times users transition from a product list page (PLP) view to a product detail page (PDP) view within the same session, using only page_view events. Could you calculate how many PLP views eventually led to a PDP view in the same session on that date, and then provide the resulting percentage of PLP-to-PDP transitions?\n\nExternal Knowledge: ga4_page_category.md"}, {"role": "assistant", "content": "WITH base_table AS (\n  SELECT\n    event_name,\n    event_date,\n    event_timestamp,\n    user_pseudo_id,\n    user_id,\n    device,\n    geo,\n    traffic_source,\n    event_params,\n    user_properties\n  FROM\n    `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`\n  WHERE\n    _table_suffix = '20210102'\n  AND event_name IN ('page_view')\n)\n, unnested_events AS (\n-- unnests event parameters to get to relevant keys and values\n  SELECT\n    event_date AS date,\n    event_timestamp AS event_timestamp_microseconds,\n    user_pseudo_id,\n    MAX(CASE WHEN c.key = 'ga_session_id' THEN c.value.int_value END) AS visitID,\n    MAX(CASE WHEN c.key = 'ga_session_number' THEN c.value.int_value END) AS visitNumber,\n    MAX(CASE WHEN c.key = 'page_title' THEN c.value.string_value END) AS page_title,\n    MAX(CASE WHEN c.key = 'page_location' THEN c.value.string_value END) AS page_location\n  FROM \n    base_table,\n    UNNEST (event_params) c\n  GROUP BY 1,2,3\n)\n\n, unnested_events_categorised AS (\n-- categorizing Page Titles into PDPs and PLPs\n  SELECT\n  *,\n  CASE WHEN ARRAY_LENGTH(SPLIT(page_location, '/')) >= 5 \n            AND\n            CONTAINS_SUBSTR(ARRAY_REVERSE(SPLIT(page_location, '/'))[SAFE_OFFSET(0)], '+')\n            AND (LOWER(SPLIT(page_location, '/')[SAFE_OFFSET(4)]) IN \n                                        ('accessories','apparel','brands','campus+collection','drinkware',\n                                          'electronics','google+redesign',\n                                          'lifestyle','nest','new+2015+logo','notebooks+journals',\n                                          'office','shop+by+brand','small+goods','stationery','wearables'\n                                          )\n                  OR\n                  LOWER(SPLIT(page_location, '/')[SAFE_OFFSET(3)]) IN \n                                        ('accessories','apparel','brands','campus+collection','drinkware',\n                                          'electronics','google+redesign',\n                                          'lifestyle','nest','new+2015+logo','notebooks+journals',\n                                          'office','shop+by+brand','small+goods','stationery','wearables'\n                                          )\n            )\n            THEN 'PDP'\n            WHEN NOT(CONTAINS_SUBSTR(ARRAY_REVERSE(SPLIT(page_location, '/'))[SAFE_OFFSET(0)], '+'))\n            AND (LOWER(SPLIT(page_location, '/')[SAFE_OFFSET(4)]) IN \n                                        ('accessories','apparel','brands','campus+collection','drinkware',\n                                          'electronics','google+redesign',\n                                          'lifestyle','nest','new+2015+logo','notebooks+journals',\n                                          'office','shop+by+brand','small+goods','stationery','wearables'\n                                          )\n                  OR \n                  LOWER(SPLIT(page_location, '/')[SAFE_OFFSET(3)]) IN \n                                          ('accessories','apparel','brands','campus+collection','drinkware',\n                                            'electronics','google+redesign',\n                                            'lifestyle','nest','new+2015+logo','notebooks+journals',\n                                            'office','shop+by+brand','small+goods','stationery','wearables'\n                                            )\n            )\n            THEN 'PLP'\n        ELSE page_title\n        END AS page_title_adjusted \n\n  FROM \n    unnested_events\n)\n\n\n, ranked_screens AS (\n  SELECT\n    *,\n    LAG(page_title_adjusted,1) OVER (PARTITION BY  user_pseudo_id, visitID ORDER BY event_timestamp_microseconds ASC) previous_page,\n    LEAD(page_title_adjusted,1) OVER (PARTITION BY  user_pseudo_id, visitID ORDER BY event_timestamp_microseconds ASC)  next_page\n  FROM \n    unnested_events_categorised\n\n)\n\n,PLPtoPDPTransitions AS (\n  SELECT\n    user_pseudo_id,\n    visitID\n  FROM\n    ranked_screens\n  WHERE\n    page_title_adjusted = 'PLP' AND next_page = 'PDP'\n)\n\n,TotalPLPViews AS (\n  SELECT\n    COUNT(*) AS total_plp_views\n  FROM\n    ranked_screens\n  WHERE\n    page_title_adjusted = 'PLP'\n)\n\n,TotalTransitions AS (\n  SELECT\n    COUNT(*) AS total_transitions\n  FROM\n    PLPtoPDPTransitions\n)\n\nSELECT\n  (total_transitions * 100.0) / total_plp_views AS percentage\nFROM\n  TotalTransitions, TotalPLPViews;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: ga4\nQuestion: Can you give me an overview of our website traffic for December 2020? I'm particularly interested in the channel with the fourth highest number of sessions.\n\nExternal Knowledge: ga4_dimensions_and_metrics.md"}, {"role": "assistant", "content": "WITH prep AS (\n  SELECT\n    user_pseudo_id,\n    (SELECT value.int_value FROM UNNEST(event_params) WHERE key = 'ga_session_id') AS session_id,\n    ARRAY_AGG((SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'source') IGNORE NULLS \n              ORDER BY event_timestamp)[SAFE_OFFSET(0)] AS source,\n    ARRAY_AGG((SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'medium') IGNORE NULLS \n              ORDER BY event_timestamp)[SAFE_OFFSET(0)] AS medium,\n    ARRAY_AGG((SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'campaign') IGNORE NULLS \n              ORDER BY event_timestamp)[SAFE_OFFSET(0)] AS campaign\n  FROM\n    `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`\n  WHERE\n    _TABLE_SUFFIX BETWEEN '20201201' AND '20201231'\n  GROUP BY\n    user_pseudo_id,\n    session_id\n)\nSELECT\n  -- session default channel grouping (dimension | the channel group associated with a session) \n  CASE \n    WHEN source = '(direct)' AND (medium IN ('(not set)','(none)')) THEN 'Direct'\n    WHEN REGEXP_CONTAINS(campaign, 'cross-network') THEN 'Cross-network'\n    WHEN (REGEXP_CONTAINS(source,'alibaba|amazon|google shopping|shopify|etsy|ebay|stripe|walmart')\n        OR REGEXP_CONTAINS(campaign, '^(.*(([^a-df-z]|^)shop|shopping).*)$'))\n        AND REGEXP_CONTAINS(medium, '^(.*cp.*|ppc|paid.*)$') THEN 'Paid Shopping'\n    WHEN REGEXP_CONTAINS(source,'baidu|bing|duckduckgo|ecosia|google|yahoo|yandex')\n        AND REGEXP_CONTAINS(medium,'^(.*cp.*|ppc|paid.*)$') THEN 'Paid Search'\n    WHEN REGEXP_CONTAINS(source,'badoo|facebook|fb|instagram|linkedin|pinterest|tiktok|twitter|whatsapp')\n        AND REGEXP_CONTAINS(medium,'^(.*cp.*|ppc|paid.*)$') THEN 'Paid Social'\n    WHEN REGEXP_CONTAINS(source,'dailymotion|disneyplus|netflix|youtube|vimeo|twitch|vimeo|youtube')\n        AND REGEXP_CONTAINS(medium,'^(.*cp.*|ppc|paid.*)$') THEN 'Paid Video'\n    WHEN medium IN ('display', 'banner', 'expandable', 'interstitial', 'cpm') THEN 'Display'\n    WHEN REGEXP_CONTAINS(source,'alibaba|amazon|google shopping|shopify|etsy|ebay|stripe|walmart')\n        OR REGEXP_CONTAINS(campaign, '^(.*(([^a-df-z]|^)shop|shopping).*)$') THEN 'Organic Shopping'\n    WHEN REGEXP_CONTAINS(source,'badoo|facebook|fb|instagram|linkedin|pinterest|tiktok|twitter|whatsapp')\n        OR medium IN ('social','social-network','social-media','sm','social network','social media') THEN 'Organic Social'\n    WHEN REGEXP_CONTAINS(source,'dailymotion|disneyplus|netflix|youtube|vimeo|twitch|vimeo|youtube')\n        OR REGEXP_CONTAINS(medium,'^(.*video.*)$') THEN 'Organic Video'\n    WHEN REGEXP_CONTAINS(source,'baidu|bing|duckduckgo|ecosia|google|yahoo|yandex')\n        OR medium = 'organic' THEN 'Organic Search'\n    WHEN REGEXP_CONTAINS(source,'email|e-mail|e_mail|e mail')\n        OR REGEXP_CONTAINS(medium,'email|e-mail|e_mail|e mail') THEN 'Email'\n    WHEN medium = 'affiliate' THEN 'Affiliates'\n    WHEN medium = 'referral' THEN 'Referral'\n    WHEN medium = 'audio' THEN 'Audio'\n    WHEN medium = 'sms' THEN 'SMS'\n    WHEN medium LIKE '%push'\n        OR REGEXP_CONTAINS(medium,'mobile|notification') THEN 'Mobile Push Notifications'\n    ELSE 'Unassigned' \n  END AS channel_grouping_session\nFROM\n  prep\nGROUP BY\n  channel_grouping_session\nORDER BY\n  COUNT(DISTINCT CONCAT(user_pseudo_id, session_id)) DESC\nLIMIT 1 OFFSET 3"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: ga4\nQuestion: On November 30, 2020, identify the item category with the highest tax rate by dividing tax value in usd by purchase revenue in usd for purchase events, and then retrieve the transaction IDs, total item quantities, and both purchase revenue in usd and purchase revenue for those purchase events in that top-tax-rate category."}, {"role": "assistant", "content": "WITH top_category AS (\n  SELECT\n    product.item_category,\n    SUM(ecommerce.tax_value_in_usd) / SUM(ecommerce.purchase_revenue_in_usd) AS tax_rate\n  FROM\n    bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_20201130,\n    UNNEST(items) AS product\n  WHERE\n    event_name = 'purchase'\n  GROUP BY\n    product.item_category\n  ORDER BY\n    tax_rate DESC\n  LIMIT 1\n)\n\nSELECT\n    ecommerce.transaction_id,\n    SUM(ecommerce.total_item_quantity) AS total_item_quantity,\n    SUM(ecommerce.purchase_revenue_in_usd) AS purchase_revenue_in_usd,\n    SUM(ecommerce.purchase_revenue) AS purchase_revenue\nFROM\n    bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_20201130, \n    UNNEST(items) AS product\nJOIN top_category\nON product.item_category = top_category.item_category\nWHERE\n    event_name = 'purchase'\nGROUP BY\n    ecommerce.transaction_id;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: firebase\nQuestion: Could you determine what percentage of users either did not uninstall our app within seven days or never uninstalled it after installing during August and September 2018?"}, {"role": "assistant", "content": "WITH\n--List of users who installed\nsept_cohort AS (\n  SELECT DISTINCT user_pseudo_id,\n  FORMAT_DATE('%Y-%m-%d', PARSE_DATE('%Y%m%d', event_date)) AS date_first_open,\n  FROM `firebase-public-project.analytics_153293282.events_*`\n  WHERE event_name = 'first_open'\n  AND _TABLE_SUFFIX BETWEEN '20180801' and '20180930'\n),\n--Get the list of users who uninstalled\nuninstallers AS (\n  SELECT DISTINCT user_pseudo_id,\n  FORMAT_DATE('%Y-%m-%d', PARSE_DATE('%Y%m%d', event_date)) AS date_app_remove,\n  FROM `firebase-public-project.analytics_153293282.events_*`\n  WHERE event_name = 'app_remove'\n  AND _TABLE_SUFFIX BETWEEN '20180801' and '20180930'\n),\n--Join the 2 tables and compute for # of days to uninstall\njoined AS (\n  SELECT a.*,\n  b.date_app_remove,\n  DATE_DIFF(DATE(b.date_app_remove), DATE(a.date_first_open), DAY) AS days_to_uninstall\n  FROM sept_cohort a\n  LEFT JOIN uninstallers b\n  ON a.user_pseudo_id = b.user_pseudo_id\n)\n--Compute for the percentage\nSELECT\nCOUNT(DISTINCT\nCASE WHEN days_to_uninstall > 7 OR days_to_uninstall IS NULL THEN user_pseudo_id END) /\nCOUNT(DISTINCT user_pseudo_id)\nAS percent_users_7_days\nFROM joined"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: firebase\nQuestion: Please perform a 7-day retention analysis for users who first session start the app during the week starting on July 2, 2018. For each week from Week 0 (the week of their first session) to Week 4, provide the total number of new users in Week 0 and the number of retained users for each subsequent week. Ensuring that you only count events up to October 2, 2018, and group dates by Monday-based weeks\n\nExternal Knowledge: retention_rate.md"}, {"role": "assistant", "content": "WITH dates AS (\n    SELECT \n        DATE('2018-07-02') AS start_date,\n        DATE('2018-10-02') AS end_date,\n        DATE_ADD(DATE_TRUNC(DATE('2018-10-02'), WEEK(TUESDAY)), INTERVAL -4 WEEK) AS min_date\n),\n\ndate_table AS (\n    SELECT DISTINCT \n        PARSE_DATE('%Y%m%d', `event_date`) AS event_date,\n        user_pseudo_id,\n        CASE \n            WHEN DATE_DIFF(PARSE_DATE('%Y%m%d', `event_date`), DATE(TIMESTAMP_MICROS(user_first_touch_timestamp)), DAY) = 0 \n            THEN 1 \n            ELSE 0 \n        END AS is_new_user\n    FROM \n        `firebase-public-project.analytics_153293282.events_*` \n    WHERE \n        event_name = 'session_start'\n),\n\nnew_user_list AS (\n    SELECT DISTINCT \n        user_pseudo_id,\n        event_date\n    FROM \n        date_table\n    WHERE \n        is_new_user = 1\n),\n\ndays_since_start_table AS (\n    SELECT DISTINCT \n        is_new_user,\n        nu.event_date AS date_cohort,\n        dt.user_pseudo_id,\n        dt.event_date,\n        DATE_DIFF(dt.event_date, nu.event_date, DAY) AS days_since_start\n    FROM \n        date_table dt\n    JOIN \n        new_user_list nu ON dt.user_pseudo_id = nu.user_pseudo_id\n),\n\nweeks_retention AS (\n    SELECT \n        date_cohort,\n        DATE_TRUNC(date_cohort, WEEK(MONDAY)) AS week_cohort,\n        user_pseudo_id,\n        days_since_start,\n        CASE \n            WHEN days_since_start = 0 \n            THEN 0 \n            ELSE CEIL(days_since_start / 7) \n        END AS weeks_since_start\n    FROM \n        days_since_start_table\n),\nRETENTION_INFO AS (\n  SELECT \n      week_cohort,\n      weeks_since_start,\n      COUNT(DISTINCT user_pseudo_id) AS retained_users\n  FROM \n      weeks_retention\n  WHERE \n      week_cohort <= (SELECT min_date FROM dates)\n  GROUP BY \n      week_cohort,\n      weeks_since_start\n  HAVING \n      weeks_since_start <= 4\n  ORDER BY \n      week_cohort,\n      weeks_since_start\n)\n\nSELECT weeks_since_start, retained_users\nFROM RETENTION_INFO\nWHERE week_cohort = DATE('2018-07-02')"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: firebase\nQuestion: Which quickplay event type had the lowest user retention rate during the second week after their initial engagement, for users who first engaged between August 1 and August 15, 2018, as measured by the presence of session_start events??\n\nExternal Knowledge: retention_rate.md"}, {"role": "assistant", "content": "-- Define the date range and calculate the minimum date for filtering results\nWITH dates AS (\n    SELECT \n        DATE('2018-08-01') AS start_date,\n        DATE('2018-08-15') AS end_date\n),\n-- Create a table of active dates for each user within the specified date range\ndates_active_table AS (\n    SELECT\n        user_pseudo_id,\n        PARSE_DATE('%Y%m%d', `event_date`) AS user_active_date\n    FROM \n        `firebase-public-project.analytics_153293282.events_*` \n    WHERE \n        event_name = 'session_start'\n        AND PARSE_DATE('%Y%m%d', `event_date`) BETWEEN (SELECT start_date FROM dates) AND (SELECT end_date FROM dates)\n    GROUP BY \n        user_pseudo_id, user_active_date\n),\n-- Create a table of the earliest quickplay event date for each user within the specified date range\nevent_table AS (\n    SELECT \n        user_pseudo_id,\n        event_name,\n        MIN(PARSE_DATE('%Y%m%d', `event_date`)) AS event_cohort_date\n    FROM \n        `firebase-public-project.analytics_153293282.events_*` \n    WHERE \n        event_name IN ('level_start_quickplay', 'level_end_quickplay', 'level_complete_quickplay', \n                       'level_fail_quickplay', 'level_reset_quickplay', 'level_retry_quickplay')\n        AND PARSE_DATE('%Y%m%d', `event_date`) BETWEEN (SELECT start_date FROM dates) AND (SELECT end_date FROM dates)\n    GROUP BY \n        user_pseudo_id, event_name\n),\n-- Calculate the number of days since each user's initial quickplay event\ndays_since_event_table AS (\n    SELECT\n        events.user_pseudo_id,\n        events.event_name AS event_cohort,\n        events.event_cohort_date,\n        days.user_active_date,\n        DATE_DIFF(days.user_active_date, events.event_cohort_date, DAY) AS days_since_event\n    FROM \n        event_table events\n    LEFT JOIN \n        dates_active_table days ON events.user_pseudo_id = days.user_pseudo_id\n    WHERE \n        events.event_cohort_date <= days.user_active_date\n),\n-- Calculate the weeks since each user's initial quickplay event and count the active days in each week\nweeks_retention AS (\n    SELECT\n        event_cohort,\n        user_pseudo_id,\n        CAST(CASE WHEN days_since_event = 0 THEN 0 ELSE CEIL(days_since_event / 7) END AS INTEGER) AS weeks_since_event,\n        COUNT(DISTINCT days_since_event) AS days_active_since_event -- Count Days Active in Week\n    FROM \n        days_since_event_table\n    GROUP BY \n        event_cohort, user_pseudo_id, weeks_since_event\n),\n-- Aggregate the weekly retention data\naggregated_weekly_retention_table AS (\n    SELECT\n        event_cohort,\n        weeks_since_event,\n        SUM(days_active_since_event) AS weekly_days_active,\n        COUNT(DISTINCT user_pseudo_id) AS retained_users\n    FROM \n        weeks_retention\n    GROUP BY \n        event_cohort, weeks_since_event\n),\nRETENTION_INFO AS (\n-- Select and calculate the weekly retention rate for each event cohort\nSELECT\n    event_cohort,\n    weeks_since_event,\n    weekly_days_active,\n    retained_users,\n    (retained_users / MAX(retained_users) OVER (PARTITION BY event_cohort)) AS retention_rate\nFROM \n    aggregated_weekly_retention_table\nORDER BY \n    event_cohort, weeks_since_event\n)\n\nSELECT event_cohort\nFROM\nRETENTION_INFO\nWHERE weeks_since_event = 2\nORDER BY retention_rate\nLIMIT 1"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: firebase\nQuestion: What is the retention rate for users two weeks after their initial quickplay event, calculated separately for each quickplay event type, within the period from July 2, 2018, to July 16, 2018? Please focus on users who started a session (session_start) during this period.\n\nExternal Knowledge: retention_rate.md"}, {"role": "assistant", "content": "-- Define the date range and calculate the minimum date for filtering results\nWITH dates AS (\n    SELECT \n        DATE('2018-07-02') AS start_date,\n        DATE('2018-07-16') AS end_date\n),\n-- Create a table of active dates for each user within the specified date range\ndates_active_table AS (\n    SELECT\n        user_pseudo_id,\n        PARSE_DATE('%Y%m%d', `event_date`) AS user_active_date\n    FROM \n        `firebase-public-project.analytics_153293282.events_*` \n    WHERE \n        event_name = 'session_start'\n        AND PARSE_DATE('%Y%m%d', `event_date`) BETWEEN (SELECT start_date FROM dates) AND (SELECT end_date FROM dates)\n    GROUP BY \n        user_pseudo_id, user_active_date\n),\n-- Create a table of the earliest quickplay event date for each user within the specified date range\nevent_table AS (\n    SELECT \n        user_pseudo_id,\n        event_name,\n        MIN(PARSE_DATE('%Y%m%d', `event_date`)) AS event_cohort_date\n    FROM \n        `firebase-public-project.analytics_153293282.events_*` \n    WHERE \n        event_name IN ('level_start_quickplay', 'level_end_quickplay', 'level_complete_quickplay', \n                       'level_fail_quickplay', 'level_reset_quickplay', 'level_retry_quickplay')\n        AND PARSE_DATE('%Y%m%d', `event_date`) BETWEEN (SELECT start_date FROM dates) AND (SELECT end_date FROM dates)\n    GROUP BY \n        user_pseudo_id, event_name\n),\n-- Calculate the number of days since each user's initial quickplay event\ndays_since_event_table AS (\n    SELECT\n        events.user_pseudo_id,\n        events.event_name AS event_cohort,\n        events.event_cohort_date,\n        days.user_active_date,\n        DATE_DIFF(days.user_active_date, events.event_cohort_date, DAY) AS days_since_event\n    FROM \n        event_table events\n    LEFT JOIN \n        dates_active_table days ON events.user_pseudo_id = days.user_pseudo_id\n    WHERE \n        events.event_cohort_date <= days.user_active_date\n),\n-- Calculate the weeks since each user's initial quickplay event and count the active days in each week\nweeks_retention AS (\n    SELECT\n        event_cohort,\n        user_pseudo_id,\n        CAST(CASE WHEN days_since_event = 0 THEN 0 ELSE CEIL(days_since_event / 7) END AS INTEGER) AS weeks_since_event,\n        COUNT(DISTINCT days_since_event) AS days_active_since_event -- Count Days Active in Week\n    FROM \n        days_since_event_table\n    GROUP BY \n        event_cohort, user_pseudo_id, weeks_since_event\n),\n-- Aggregate the weekly retention data\naggregated_weekly_retention_table AS (\n    SELECT\n        event_cohort,\n        weeks_since_event,\n        SUM(days_active_since_event) AS weekly_days_active,\n        COUNT(DISTINCT user_pseudo_id) AS retained_users\n    FROM \n        weeks_retention\n    GROUP BY \n        event_cohort, weeks_since_event\n),\nRETENTION_INFO AS (\nSELECT\n    event_cohort,\n    weeks_since_event,\n    weekly_days_active,\n    retained_users,\n    (retained_users / MAX(retained_users) OVER (PARTITION BY event_cohort)) AS retention_rate\nFROM \n    aggregated_weekly_retention_table\nORDER BY \n    event_cohort, weeks_since_event\n)\n\nSELECT event_cohort, retention_rate\nFROM\nRETENTION_INFO\nWHERE weeks_since_event = 2"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: firebase\nQuestion: Could you please help me get the weekly customer retention rate in September 2018 for new customers who first used our app (first_open event) within the first week starting from September 1st, 2018 (timezone in Shanghai)? The retention rates should cover the following weeks 1, 2, and 3 period after the initial use and display them in column format.\n\nExternal Knowledge: retention_rate.md"}, {"role": "assistant", "content": "WITH analytics_data AS (\n  SELECT user_pseudo_id, event_timestamp, event_name, \n    UNIX_MICROS(TIMESTAMP(\"2018-09-01 00:00:00\", \"+8:00\")) AS start_day,\n    3600*1000*1000*24*7 AS one_week_micros\n  FROM `firebase-public-project.analytics_153293282.events_*`\n  WHERE _table_suffix BETWEEN '20180901' AND '20180930'\n)\n\nSELECT\n week_1_cohort / week_0_cohort AS week_1_pct,\n week_2_cohort / week_0_cohort AS week_2_pct,\n week_3_cohort / week_0_cohort AS week_3_pct\nFROM (\n  WITH week_3_users AS (\n    SELECT DISTINCT user_pseudo_id\n    FROM analytics_data\n    WHERE event_timestamp BETWEEN start_day+(3*one_week_micros) AND start_day+(4*one_week_micros)\n  ),\n  week_2_users AS (\n    SELECT DISTINCT user_pseudo_id\n    FROM analytics_data\n    WHERE event_timestamp BETWEEN start_day+(2*one_week_micros) AND start_day+(3*one_week_micros)\n  ),\n  week_1_users AS (\n    SELECT DISTINCT user_pseudo_id\n    FROM analytics_data\n    WHERE event_timestamp BETWEEN start_day+(1*one_week_micros) AND start_day+(2*one_week_micros)\n  ), \n  week_0_users AS (\n    SELECT DISTINCT user_pseudo_id\n    FROM analytics_data\n    WHERE event_name = 'first_open'\n      AND event_timestamp BETWEEN start_day AND start_day+(1*one_week_micros)\n  )\n  SELECT \n    (SELECT count(*) \n     FROM week_0_users) AS week_0_cohort,\n    (SELECT count(*) \n     FROM week_1_users \n     JOIN week_0_users USING (user_pseudo_id)) AS week_1_cohort,\n    (SELECT count(*) \n     FROM week_2_users \n     JOIN week_0_users USING (user_pseudo_id)) AS week_2_cohort,\n    (SELECT count(*) \n     FROM week_3_users \n     JOIN week_0_users USING (user_pseudo_id)) AS week_3_cohort\n)"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: E_commerce\nQuestion: According to the RFM definition document, calculate the average sales per order for each customer within distinct RFM segments, considering only 'delivered' orders. Use the customer unique identifier. Clearly define how to calculate Recency based on the latest purchase timestamp and specify the criteria for classifying RFM segments. The average sales should be computed as the total spend divided by the total number of orders. Please analyze and report the differences in average sales across the RFM segments\n\nExternal Knowledge: RFM.md"}, {"role": "assistant", "content": "WITH RecencyScore AS (\n    SELECT customer_unique_id,\n           MAX(order_purchase_timestamp) AS last_purchase,\n           NTILE(5) OVER (ORDER BY MAX(order_purchase_timestamp) DESC) AS recency\n    FROM orders\n        JOIN customers USING (customer_id)\n    WHERE order_status = 'delivered'\n    GROUP BY customer_unique_id\n),\nFrequencyScore AS (\n    SELECT customer_unique_id,\n           COUNT(order_id) AS total_orders,\n           NTILE(5) OVER (ORDER BY COUNT(order_id) DESC) AS frequency\n    FROM orders\n        JOIN customers USING (customer_id)\n    WHERE order_status = 'delivered'\n    GROUP BY customer_unique_id\n),\nMonetaryScore AS (\n    SELECT customer_unique_id,\n           SUM(price) AS total_spent,\n           NTILE(5) OVER (ORDER BY SUM(price) DESC) AS monetary\n    FROM orders\n        JOIN order_items USING (order_id)\n        JOIN customers USING (customer_id)\n    WHERE order_status = 'delivered'\n    GROUP BY customer_unique_id\n),\n\n-- 2. Assign each customer to a group\nRFM AS (\n    SELECT last_purchase, total_orders, total_spent,\n        CASE\n            WHEN recency = 1 AND frequency + monetary IN (1, 2, 3, 4) THEN \"Champions\"\n            WHEN recency IN (4, 5) AND frequency + monetary IN (1, 2) THEN \"Can't Lose Them\"\n            WHEN recency IN (4, 5) AND frequency + monetary IN (3, 4, 5, 6) THEN \"Hibernating\"\n            WHEN recency IN (4, 5) AND frequency + monetary IN (7, 8, 9, 10) THEN \"Lost\"\n            WHEN recency IN (2, 3) AND frequency + monetary IN (1, 2, 3, 4) THEN \"Loyal Customers\"\n            WHEN recency = 3 AND frequency + monetary IN (5, 6) THEN \"Needs Attention\"\n            WHEN recency = 1 AND frequency + monetary IN (7, 8) THEN \"Recent Users\"\n            WHEN recency = 1 AND frequency + monetary IN (5, 6) OR\n                recency = 2 AND frequency + monetary IN (5, 6, 7, 8) THEN \"Potentital Loyalists\"\n            WHEN recency = 1 AND frequency + monetary IN (9, 10) THEN \"Price Sensitive\"\n            WHEN recency = 2 AND frequency + monetary IN (9, 10) THEN \"Promising\"\n            WHEN recency = 3 AND frequency + monetary IN (7, 8, 9, 10) THEN \"About to Sleep\"\n        END AS RFM_Bucket\n    FROM RecencyScore\n        JOIN FrequencyScore USING (customer_unique_id)\n        JOIN MonetaryScore USING (customer_unique_id)\n)\n\nSELECT RFM_Bucket, \n       AVG(total_spent / total_orders) AS avg_sales_per_customer\nFROM RFM\nGROUP BY RFM_Bucket"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: E_commerce\nQuestion: Could you tell me the number of orders, average payment per order and customer lifespan in weeks of the 3 custumers with the highest average payment per order, where the lifespan is calculated by subtracting the earliest purchase date from the latest purchase date in days, dividing by seven, and if the result is less than seven days, setting it to 1.0?"}, {"role": "assistant", "content": "WITH CustomerData AS (\n    SELECT\n        customer_unique_id,\n        COUNT(DISTINCT orders.order_id) AS order_count,\n        SUM(payment_value) AS total_payment,\n        JULIANDAY(MIN(order_purchase_timestamp)) AS first_order_day,\n        JULIANDAY(MAX(order_purchase_timestamp)) AS last_order_day\n    FROM customers\n        JOIN orders USING (customer_id)\n        JOIN order_payments USING (order_id)\n    GROUP BY customer_unique_id\n)\nSELECT\n    customer_unique_id,\n    order_count AS PF,\n    ROUND(total_payment / order_count, 2) AS AOV,\n    CASE\n        WHEN (last_order_day - first_order_day) < 7 THEN\n            1\n        ELSE\n            (last_order_day - first_order_day) / 7\n        END AS ACL\nFROM CustomerData\nORDER BY AOV DESC\nLIMIT 3"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: Baseball\nQuestion: I would like to know the given names of baseball players who have achieved the highest value of games played, runs, hits, and home runs, with their corresponding score values."}, {"role": "assistant", "content": "WITH player_stats AS (\n    SELECT\n        b.player_id,\n        p.name_given AS player_name,\n        SUM(b.g) AS games_played,\n        SUM(b.r) AS runs,\n        SUM(b.h) AS hits,\n        SUM(b.hr) AS home_runs\n    FROM player p\n    JOIN batting b ON p.player_id = b.player_id\n    GROUP BY b.player_id, p.name_given\n)\n\nSELECT 'Games Played' AS Category, player_name AS Player_Name, games_played AS Batting_Table_Topper\nFROM player_stats\nWHERE games_played = (SELECT MAX(games_played) FROM player_stats)\n\nUNION ALL\n\nSELECT 'Runs' AS Category, player_name AS Player_Name, runs AS Batting_Table_Topper\nFROM player_stats\nWHERE runs = (SELECT MAX(runs) FROM player_stats)\n\nUNION ALL\n\nSELECT 'Hits' AS Category, player_name AS Player_Name, hits AS Batting_Table_Topper\nFROM player_stats\nWHERE hits = (SELECT MAX(hits) FROM player_stats)\n\nUNION ALL\n\nSELECT 'Home Runs' AS Category, player_name AS Player_Name, home_runs AS Batting_Table_Topper\nFROM player_stats\nWHERE home_runs = (SELECT MAX(home_runs) FROM player_stats);"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: California_Traffic_Collision\nQuestion: In which year were the two most common causes of traffic accidents different from those in other years?"}, {"role": "assistant", "content": "WITH AnnualTotals AS (\n    SELECT \n        STRFTIME('%Y', collision_date) AS Year, \n        COUNT(case_id) AS AnnualTotal\n    FROM \n        collisions\n    GROUP BY \n        Year\n),\nCategoryTotals AS (\n    SELECT \n        STRFTIME('%Y', collision_date) AS Year,\n        pcf_violation_category AS Category,\n        COUNT(case_id) AS Subtotal\n    FROM \n        collisions\n    GROUP BY \n        Year, Category\n),\nCategoryPercentages AS (\n    SELECT \n        ct.Year,\n        ct.Category,\n        ROUND((ct.Subtotal * 100.0) / at.AnnualTotal, 1) AS PercentageOfAnnualRoadIncidents\n    FROM \n        CategoryTotals ct\n    JOIN \n        AnnualTotals at ON ct.Year = at.Year\n),\nRankedCategories AS (\n    SELECT\n        Year,\n        Category,\n        PercentageOfAnnualRoadIncidents,\n        ROW_NUMBER() OVER (PARTITION BY Year ORDER BY PercentageOfAnnualRoadIncidents DESC) AS Rank\n    FROM\n        CategoryPercentages\n),\nTopTwoCategories AS (\n    SELECT\n        Year,\n        GROUP_CONCAT(Category, ', ') AS TopCategories\n    FROM\n        RankedCategories\n    WHERE\n        Rank <= 2\n    GROUP BY\n        Year\n),\nUniqueYear AS (\n    SELECT\n        Year\n    FROM\n        TopTwoCategories\n    GROUP BY\n        TopCategories\n    HAVING COUNT(Year) = 1\n),\nresults AS (\nSELECT \n    rc.Year, \n    rc.Category, \n    rc.PercentageOfAnnualRoadIncidents\nFROM \n    UniqueYear u\nJOIN \n    RankedCategories rc ON u.Year = rc.Year\nWHERE \n    rc.Rank <= 2\n)\n\nSELECT distinct Year FROM results"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: WWE\nQuestion: For the NXT title that had the shortest match (excluding titles with \"title change\"), what were the names of the two wrestlers involved?"}, {"role": "assistant", "content": "WITH MatchDetails AS (\n    SELECT\n        b.name AS titles,\n        m.duration AS match_duration,\n        w1.name || ' vs ' || w2.name AS matches,\n        m.win_type AS win_type,\n        l.name AS location,\n        e.name AS event,\n        ROW_NUMBER() OVER (PARTITION BY b.name ORDER BY m.duration ASC) AS rank\n    FROM \n        Belts b\n    INNER JOIN Matches m ON m.title_id = b.id\n    INNER JOIN Wrestlers w1 ON w1.id = m.winner_id\n    INNER JOIN Wrestlers w2 ON w2.id = m.loser_id\n    INNER JOIN Cards c ON c.id = m.card_id\n    INNER JOIN Locations l ON l.id = c.location_id\n    INNER JOIN Events e ON e.id = c.event_id\n    INNER JOIN Promotions p ON p.id = c.promotion_id\n    WHERE\n        p.name = 'NXT'\n        AND m.duration <> ''\n        AND b.name <> ''\n        AND b.name NOT IN (\n            SELECT name \n            FROM Belts \n            WHERE name LIKE '%title change%'\n        )\n),\nRank1 AS (\nSELECT \n    titles,\n    match_duration,\n    matches,\n    win_type,\n    location,\n    event\nFROM \n    MatchDetails\nWHERE \n    rank = 1\n)\nSELECT\n    SUBSTR(matches, 1, INSTR(matches, ' vs ') - 1) AS wrestler1,\n    SUBSTR(matches, INSTR(matches, ' vs ') + 4) AS wrestler2\nFROM\nRank1\nORDER BY match_duration \nLIMIT 1"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: IPL\nQuestion: Retrieve the names of players who scored no less than 100 runs in a match while playing for the team that lost that match."}, {"role": "assistant", "content": "-- Step 1: Calculate players' total runs in each match\nWITH player_runs AS (\n    SELECT \n        bbb.striker AS player_id, \n        bbb.match_id, \n        SUM(bsc.runs_scored) AS total_runs \n    FROM \n        ball_by_ball AS bbb\n    JOIN \n        batsman_scored AS bsc\n    ON \n        bbb.match_id = bsc.match_id \n        AND bbb.over_id = bsc.over_id \n        AND bbb.ball_id = bsc.ball_id \n        AND bbb.innings_no = bsc.innings_no\n    GROUP BY \n        bbb.striker, bbb.match_id\n    HAVING \n        SUM(bsc.runs_scored) >= 100\n),\n\n-- Step 2: Identify losing teams for each match\nlosing_teams AS (\n    SELECT \n        match_id, \n        CASE \n            WHEN match_winner = team_1 THEN team_2 \n            ELSE team_1 \n        END AS loser \n    FROM \n        match\n),\n\n-- Step 3: Combine the above results to get players who scored 100 or more runs in losing teams\nplayers_in_losing_teams AS (\n    SELECT \n        pr.player_id, \n        pr.match_id \n    FROM \n        player_runs AS pr\n    JOIN \n        losing_teams AS lt\n    ON \n        pr.match_id = lt.match_id\n    JOIN \n        player_match AS pm\n    ON \n        pr.player_id = pm.player_id \n        AND pr.match_id = pm.match_id \n        AND lt.loser = pm.team_id\n)\n\n-- Step 4: Select distinct player names from the player table\nSELECT DISTINCT \n    p.player_name \nFROM \n    player AS p\nJOIN \n    players_in_losing_teams AS plt\nON \n    p.player_id = plt.player_id\nORDER BY \n    p.player_name;"}]}
{"messages": [{"role": "user", "content": "Generate a SQL query to answer the following question.\n\nDatabase: IPL\nQuestion: Please help me find the names of top 5 players with the highest average runs per match in season 5, along with their batting averages."}, {"role": "assistant", "content": "WITH runs_scored AS (\n    SELECT \n        bb.striker AS player_id,\n        bb.match_id,\n        bs.runs_scored AS runs\n    FROM \n        ball_by_ball AS bb\n    JOIN \n        batsman_scored AS bs ON bb.match_id = bs.match_id \n            AND bb.over_id = bs.over_id \n            AND bb.ball_id = bs.ball_id \n            AND bb.innings_no = bs.innings_no\n    WHERE \n        bb.match_id IN (SELECT match_id FROM match WHERE season_id = 5)\n),\ntotal_runs AS (\n    SELECT \n        player_id, \n        match_id, \n        SUM(runs) AS total_runs \n    FROM \n        runs_scored \n    GROUP BY \n        player_id, match_id\n),\nbatting_averages AS (\n    SELECT \n        player_id, \n        SUM(total_runs) AS runs, \n        COUNT(match_id) AS num_matches,\n        ROUND(SUM(total_runs) / CAST(COUNT(match_id) AS FLOAT), 3) AS batting_avg\n    FROM \n        total_runs \n    GROUP BY \n        player_id \n    ORDER BY \n        batting_avg DESC \n    LIMIT 5\n)\nSELECT \n    p.player_name,\n    b.batting_avg\nFROM \n    player AS p\nJOIN \n    batting_averages AS b ON p.player_id = b.player_id\nORDER BY \n    b.batting_avg DESC;"}]}
